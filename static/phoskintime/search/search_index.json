{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PhosKinTime Documentation","text":"<p>Welcome to the official documentation for PhosKinTime, an ODE-based modeling toolkit for phosphorylation kinetics and transcriptional time-series analysis. This index page provides an overview of each package and submodule in the project.</p>"},{"location":"#overview","title":"Overview","text":"<p>PhosKinTime integrates:</p> <ul> <li>Parameter estimation (normal and sequential modes)</li> <li>Mechanistic ODE models (distributive, successive, random)</li> <li>Steady-state computation</li> <li>Morris sensitivity analysis</li> <li>Static and interactive visualization</li> <li>Modular design for extensibility</li> </ul> <p>PhosKinTime uses ordinary differential equations (ODEs) to model phosphorylation kinetics and supports multiple mechanistic hypotheses, including: - Distributive Model: Phosphorylation events occur independently. - Successive Model: Phosphorylation events occur sequentially. - Random Model: Phosphorylation events occur in a random manner.</p> <p>The package is designed with modularity in mind. It consists of several key components: - Configuration: Centralized settings (paths, parameter bounds, logging, etc.) are defined in the config module. - Models: Different ODE models (distributive, successive, random) are implemented to simulate phosphorylation. - Parameter Estimation: Multiple routines (sequential and normal estimation) estimate kinetic parameters from experimental data. - Sensitivity Analysis: Morris sensitivity analysis is used to evaluate the influence of each parameter on the model output. - Steady-State Calculation: Functions compute steady-state initial conditions for ODE simulation. - Utilities: Helper functions support file handling, data formatting, report generation, and more. - Visualization: A comprehensive plotting module generates static and interactive plots to visualize model fits, parameter profiles, PCA, t-SNE, and sensitivity indices. - Exporting: The package can export results to Excel and generate HTML reports for easy sharing and documentation.  - CLI Interface: A command-line interface allows users to run the package without needing to modify the code directly.  - Documentation: The package includes extensive documentation to help users understand the functionality and usage of each module. - Testing: The package includes unit tests to ensure the reliability and correctness of the implemented algorithms. - Logging: A logging system is integrated to track the execution flow and capture important events during the analysis. - Error Handling: The package includes error handling mechanisms to manage exceptions and provide informative error messages. - Cross-Platform Compatibility: The package is designed to work on various operating systems, including Windows, macOS, and Linux. - Version Control: The package is version-controlled using Git, allowing users to track changes and collaborate effectively. - Continuous Integration: The package is set up with continuous integration (CI) tools to automate testing and ensure code quality. - Documentation Generation: The package uses tools like Sphinx to generate documentation from docstrings, making it easy to maintain and update the documentation as the code evolves. - Code Quality: The package follows best practices for code quality, including PEP 8 style guidelines, type hints, and docstrings for functions and classes.</p>"},{"location":"#core-packages","title":"Core Packages","text":""},{"location":"#bin","title":"bin/","text":"<p>Entry point for the pipeline. Contains <code>main.py</code>, which orchestrates configuration, data loading, parameter estimation, ODE simulation, visualization, and report generation.</p>"},{"location":"#config","title":"config/","text":"<p>Holds global constants, CLI parsing, and logging setup:</p> <ul> <li><code>constants.py</code>: model settings, time points, directories, scoring weights</li> <li><code>config.py</code>: argument parsing and configuration extraction</li> <li><code>logconf.py</code>: colored console and rotating file logging</li> <li><code>helpers/</code>: utilities for parameter names, state labels, bounds, and clickable paths</li> </ul>"},{"location":"#models","title":"models/","text":"<p>Implements ODE systems for different phosphorylation hypotheses:</p> <ul> <li><code>distmod.py</code>: distributive model</li> <li><code>succmod.py</code>: successive model</li> <li><code>randmod.py</code>: random model with JIT optimization</li> <li><code>weights.py</code>: weighting schemes for parameter estimation</li> </ul>"},{"location":"#paramest","title":"paramest/","text":"<p>Parameter estimation routines:</p> <ul> <li><code>seqest.py</code>: sequential (time-point\u2013wise) fitting</li> <li><code>normest.py</code>: global fit across all time points</li> <li><code>adapest.py</code>: adaptive profile estimation</li> <li><code>toggle.py</code>: selects estimation mode</li> <li><code>core.py</code>: integrates estimation, ODE solve, error metrics, and plotting</li> </ul>"},{"location":"#steady","title":"steady/","text":"<p>Computes steady-state initial conditions for each model:</p> <ul> <li><code>initdist.py</code>, <code>initsucc.py</code>, <code>initrand.py</code></li> </ul>"},{"location":"#sensitivity","title":"sensitivity/","text":"<p>Morris sensitivity analysis:</p> <ul> <li><code>analysis.py</code>: defines problem, sampling, analysis, and sensitivity plots</li> </ul>"},{"location":"#plotting","title":"plotting/","text":"<p>Visualization tools:</p> <ul> <li><code>Plotter</code> class with methods for parallel coordinates, PCA, t-SNE, parameter bar and series plots, model fit, GoF diagnostics, Kullback\u2013Leibler divergence, clusters, and heatmaps</li> </ul>"},{"location":"#utils","title":"utils/","text":"<p>Helper functions:</p> <ul> <li><code>display.py</code>: file and directory management, data loading, result saving, report generation</li> <li><code>tables.py</code>: table creation and export (LaTeX and CSV)</li> </ul>"},{"location":"#optimization-framework-kinopt","title":"Optimization Framework (kinopt)","text":"<p>The kinopt package provides advanced optimization and post-processing:</p>"},{"location":"#kinoptevol","title":"kinopt/evol","text":"<p>Global evolutionary optimization using pymoo (DE, NSGA-II):</p> <ul> <li>Problem formulation, data construction, exporter for Excel and plots</li> </ul>"},{"location":"#kinoptlocal","title":"kinopt/local","text":"<p>Local constrained optimization using SciPy solvers (SLSQP, TRUST-CONSTR) with Numba-accelerated objectives</p>"},{"location":"#kinoptoptimality","title":"kinopt/optimality","text":"<p>Post-optimization analysis: feasibility checks, sensitivity reporting, LaTeX table generation, diagnostic plots</p>"},{"location":"#kinoptpowell","title":"kinopt/powell","text":"<p>Julia-based Powell optimization bridge: runs <code>powell.jl</code>, configures threads, integrates results into post-processing</p>"},{"location":"#kinoptfitanalysis","title":"kinopt/fitanalysis","text":"<p>Additional fit-evaluation utilities for residual and performance analysis</p>"},{"location":"#optimization-framework-tfopt","title":"Optimization Framework (tfopt)","text":""},{"location":"#originally-implemented-by-julius-normann","title":"Originally implemented by Julius Normann.","text":""},{"location":"#this-version-has-been-modified-and-optimized-by-abhinav-mishra","title":"This version has been modified and optimized by Abhinav Mishra.","text":"<p>The tfopt package estimates transcriptional regulation using mRNA and TF time-series data through constrained optimization.</p>"},{"location":"#tfoptevol","title":"tfopt/evol","text":"<p>Global evolutionary optimization using pymoo (NSGA-II, AGEMOEA, SMSEMOA):</p> <ul> <li>Multi-objective loss (fit error, \u03b1 and \u03b2 constraint violations)  </li> <li>Parallel evaluation, Excel export, and HTML/plot reports</li> </ul>"},{"location":"#tfoptlocal","title":"tfopt/local","text":"<p>Local constrained optimization using SciPy solvers (SLSQP):</p> <ul> <li>Fast deterministic optimization under linear constraints  </li> <li>Numba-accelerated objectives, identical output and reports as <code>evol</code></li> </ul>"},{"location":"#tfoptobjfn","title":"tfopt/objfn","text":"<p>Shared objective logic and prediction functions for both backends</p>"},{"location":"#tfoptoptcon","title":"tfopt/optcon","text":"<p>Data construction and constraint generation from TF\u2013mRNA interaction files</p>"},{"location":"#tfoptutils","title":"tfopt/utils","text":"<p>Input parsing, Excel + plot output, and HTML report generation</p>"},{"location":"#features-at-a-glance","title":"Features at a Glance","text":"<ul> <li>\ud83e\uddec Mechanistic ODE Models: Distributive, successive, and random phosphorylation models.</li> <li>\ud83e\uddea Parameter Estimation: Both normal and sequential fitting modes.</li> <li>\ud83e\udde0 Sensitivity Analysis: Morris method to analyze model response to parameters.</li> <li>\ud83e\uddf0 Steady-State Calculations: Compute initial conditions for all model types.</li> <li>\ud83d\udcca Visualization Tools: Model fit plots, PCA/t-SNE visualizations, and HTML reports.</li> <li>\ud83d\udd01 Modular Design: Easy to extend and customize each component.</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#option-1-pip-virtualenv-debianubuntufedora","title":"Option 1: pip + virtualenv (Debian/Ubuntu/Fedora)","text":""},{"location":"#for-debianubuntu","title":"For Debian/Ubuntu","text":"<pre><code>sudo apt update &amp;&amp; sudo apt install -y python3 python3-pip python3-venv git\n</code></pre>"},{"location":"#for-fedora","title":"For Fedora","text":"<pre><code>sudo dnf install -y python3 python3-pip python3-virtualenv git\n</code></pre>"},{"location":"#setup","title":"Setup","text":"<pre><code>git clone git@github.com:bibymaths/phoskintime.git\ncd phoskintime\n\n# Create and activate a virtual environment\npython3 -m venv venv\nsource venv/bin/activate\n\n# Install dependencies\npip install --upgrade pip\npip install -r requirements.txt\n</code></pre>"},{"location":"#option-2-poetry-pyprojecttoml","title":"Option 2: Poetry + <code>pyproject.toml</code>","text":""},{"location":"#install-poetry-all-platforms","title":"Install Poetry (all platforms)","text":"<pre><code>curl -sSL https://install.python-poetry.org | python3 -# Or: pip install poetry\n</code></pre>"},{"location":"#modules","title":"Modules","text":"<ul> <li><code>bin/</code>: Entry point (<code>main.py</code>) to run the full pipeline.</li> <li><code>config/</code>: Constants, CLI parsing, and logging setup.</li> <li><code>models/</code>: Distributive, successive, and random ODE systems.</li> <li><code>paramest/</code>: Estimation logic (normal, sequential, adaptive).</li> <li><code>steady/</code>: Model-specific steady-state calculators.</li> <li><code>sensitivity/</code>: Morris sensitivity analysis.</li> <li><code>utils/</code>: IO, table generation, and result handling.</li> <li><code>plotting/</code>: Visualizations for model fits, sensitivity, PCA, and more.</li> </ul>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<p>This project originated as part of my master's thesis work at Theoretical Biophysics group (now, Klipp-Linding Lab), Humboldt Universit\u00e4t zu Berlin.</p> <ul> <li>Conceptual framework and mathematical modeling were developed under the supervision of Prof. Dr. Dr. H.C. Edda Klipp.</li> <li>Experimental datasets were provided by the (Retd. Prof.) Dr. Rune Linding.</li> <li>The subpackage <code>tfopt</code> is an optimized and efficient derivative of original work by my colleague Julius Normann, adapted with permission.</li> </ul> <p>I am especially grateful to Ivo Maintz for his generous technical support, enabling seamless experimentation with packages and server setups.</p> <ul> <li>The package is built on the shoulders of giants, leveraging the power of NumPy, SciPy, Matplotlib, and Pandas for numerical computations and data handling. </li> <li>The package also utilizes Numba for JIT compilation, enhancing performance for computationally intensive tasks.</li> <li>The package is designed to be compatible with Python 3.8+ and is tested on various platforms, including Windows, macOS, and Linux. </li> </ul>"},{"location":"reference/","title":"API Reference","text":""},{"location":"reference/#bin.main.main","title":"<code>main()</code>","text":"<p>Main function to run the phosphorylation modelling process. It reads the configuration, loads the data, and processes each gene in parallel. It also handles logging and output organization.</p> Source code in <code>bin/main.py</code> <pre><code>def main():\n    \"\"\"\n    Main function to run the phosphorylation modelling process.\n    It reads the configuration, loads the data, and processes each gene in parallel.\n    It also handles logging and output organization.\n    \"\"\"\n    # Set up the logger\n    logger.info(f\"{model_type} Phosphorylation Modelling Configuration\")\n    logger.info(f\"Estimation Mode: {ESTIMATION_MODE}\")\n    log_config(logger, config['bounds'], config['fixed_params'], config['time_fixed'], args)\n\n    # Make output directory\n    ensure_output_directory(OUT_DIR)\n\n    # Load the data\n    data = pd.read_excel(config['input_excel'], sheet_name='Estimated')\n\n    # Load protein groups\n    genes = data[\"Gene\"].unique().tolist() # For testing, only process the first gene\n    logger.info(f\"Loaded Time Series for {len(genes)} Protein(s)\")\n\n    # Initiate the process pool and run the processing function for each gene\n    with ProcessPoolExecutor(max_workers=config['max_workers']) as executor:\n        results = list(executor.map(\n            process_gene_wrapper, genes,\n            [data] * len(genes),\n            [TIME_POINTS] * len(genes),\n            [config['bounds']] * len(genes),\n            [config['fixed_params']] * len(genes),\n            [desired_times] * len(genes),\n            [config['time_fixed']] * len(genes),\n            [config['bootstraps']] * len(genes)\n        ))\n    # Save the results\n    save_result(results, excel_filename=OUT_RESULTS_DIR)\n\n    # Organize output files and create a report\n    organize_output_files(OUT_DIR)\n    create_report(OUT_DIR)\n\n    logger.info(f'Report &amp; Results {location(str(OUT_DIR))}')\n</code></pre>"},{"location":"reference/#config.config.ensure_output_directory","title":"<code>ensure_output_directory(directory)</code>","text":"<p>:param directory: :type directory: str</p> Source code in <code>config/config.py</code> <pre><code>def ensure_output_directory(directory):\n    \"\"\"\n    :param directory:\n    :type directory: str\n    \"\"\"\n    os.makedirs(directory, exist_ok=True)\n</code></pre>"},{"location":"reference/#config.config.extract_config","title":"<code>extract_config(args)</code>","text":"<p>Extract configuration settings from command-line arguments. This function creates a dictionary containing the parameter bounds, fixed parameters, bootstrapping iterations, time-specific fixed parameters, and profile estimation settings. It also sets the maximum number of workers for parallel processing. The function returns the configuration dictionary. :param args: :return:</p> Source code in <code>config/config.py</code> <pre><code>def extract_config(args):\n    \"\"\"\n    Extract configuration settings from command-line arguments.\n    This function creates a dictionary containing the parameter bounds,\n    fixed parameters, bootstrapping iterations, time-specific fixed parameters,\n    and profile estimation settings. It also sets the maximum number of workers\n    for parallel processing.\n    The function returns the configuration dictionary.\n    :param args:\n    :return:\n    \"\"\"\n    bounds = {\n        \"A\": args.A_bound,\n        \"B\": args.B_bound,\n        \"C\": args.C_bound,\n        \"D\": args.D_bound,\n        \"Ssite\": args.Ssite_bound,\n        \"Dsite\": args.Dsite_bound\n    }\n    fixed_params = {\n        \"A\": args.fix_A,\n        \"B\": args.fix_B,\n        \"C\": args.fix_C,\n        \"D\": args.fix_D,\n        \"Ssite\": args.fix_Ssite,\n        \"Dsite\": args.fix_Dsite\n    }\n    time_fixed = json.loads(args.fix_t) if args.fix_t.strip() else {}\n\n    config = {\n        'bounds': bounds,\n        'fixed_params': fixed_params,\n        'time_fixed': time_fixed,\n        'bootstraps': args.bootstraps,\n        'profile_start': args.profile_start,\n        'profile_end': args.profile_end,\n        'profile_step': args.profile_step,\n        'input_excel': args.input_excel,\n        # Adjust as needed for parallel processing\n        'max_workers': os.cpu_count(),  # Use all CPU cores\n        # 'max_workers': 1,\n    }\n    return config\n</code></pre>"},{"location":"reference/#config.config.log_config","title":"<code>log_config(logger, bounds, fixed_params, time_fixed, args)</code>","text":"<p>Log the configuration settings for the PhosKinTime script. This function logs the parameter bounds, fixed parameters, bootstrapping iterations, time-specific fixed parameters, and profile estimation settings. It uses the provided logger to output the information. :param logger: :param bounds: :param fixed_params: :param time_fixed: :param args: :return:</p> Source code in <code>config/config.py</code> <pre><code>def log_config(logger, bounds, fixed_params, time_fixed, args):\n    \"\"\"\n    Log the configuration settings for the PhosKinTime script.\n    This function logs the parameter bounds, fixed parameters,\n    bootstrapping iterations, time-specific fixed parameters,\n    and profile estimation settings.\n    It uses the provided logger to output the information.\n    :param logger:\n    :param bounds:\n    :param fixed_params:\n    :param time_fixed:\n    :param args:\n    :return:\n    \"\"\"\n    logger.info(\"Parameter Bounds:\")\n    for key, val in bounds.items():\n        logger.info(f\"   {key}: {val}\")\n    logger.info(\"Fixed Parameters:\")\n    for key, val in fixed_params.items():\n        logger.info(f\"   {key}: {val}\")\n\n    logger.info(f\"Bootstrapping Iterations: {args.bootstraps}\")\n\n    logger.info(\"Time-specific Fixed Parameters:\")\n    if time_fixed:\n        for t, p in time_fixed.items():\n            logger.info(f\"   Time {t} min: {p}\")\n    else:\n        logger.info(\"   None\")\n\n    logger.info(\"Profile Estimation:\")\n    logger.info(f\"   Start: {args.profile_start} min\")\n    logger.info(f\"   End:   {args.profile_end} min\")\n    logger.info(f\"   Step:  {args.profile_step} min\")\n    np.set_printoptions(suppress=True)\n</code></pre>"},{"location":"reference/#config.config.parse_args","title":"<code>parse_args()</code>","text":"<p>Parse command-line arguments for the PhosKinTime script. This function uses argparse to define and handle the command-line options. It includes options for setting bounds, fixed parameters, bootstrapping, profile estimation, and input file paths. The function returns the parsed arguments as a Namespace object. The arguments include:     --A-bound: Bounds for parameter A (default: \"0,3\")     --B-bound: Bounds for parameter B (default: \"0,3\")     --C-bound: Bounds for parameter C (default: \"0,3\")     --D-bound: Bounds for parameter D (default: \"0,3\")     --Ssite-bound: Bounds for Ssite (default: \"0,3\")     --Dsite-bound: Bounds for Dsite (default: \"0,3\")     --fix-A: Fixed value for parameter A     --fix-B: Fixed value for parameter B     --fix-C: Fixed value for parameter C     --fix-D: Fixed value for parameter D     --fix-Ssite: Fixed value for Ssite     --fix-Dsite: Fixed value for Dsite     --fix-t: JSON string mapping time points to fixed param values     --bootstraps: Number of bootstrapping iterations (default: 0)     --profile-start: Start time for profile estimation (default: None)     --profile-end: End time for profile estimation (default: 1)     --profile-step: Step size for profile estimation (default: 0.5)     --input-excel: Path to the input Excel file (default: INPUT_EXCEL) Returns:     argparse.Namespace: The parsed command-line arguments.</p> Source code in <code>config/config.py</code> <pre><code>def parse_args():\n    \"\"\"\n    Parse command-line arguments for the PhosKinTime script.\n    This function uses argparse to define and handle the command-line options.\n    It includes options for setting bounds, fixed parameters, bootstrapping,\n    profile estimation, and input file paths.\n    The function returns the parsed arguments as a Namespace object.\n    The arguments include:\n        --A-bound: Bounds for parameter A (default: \"0,3\")\n        --B-bound: Bounds for parameter B (default: \"0,3\")\n        --C-bound: Bounds for parameter C (default: \"0,3\")\n        --D-bound: Bounds for parameter D (default: \"0,3\")\n        --Ssite-bound: Bounds for Ssite (default: \"0,3\")\n        --Dsite-bound: Bounds for Dsite (default: \"0,3\")\n        --fix-A: Fixed value for parameter A\n        --fix-B: Fixed value for parameter B\n        --fix-C: Fixed value for parameter C\n        --fix-D: Fixed value for parameter D\n        --fix-Ssite: Fixed value for Ssite\n        --fix-Dsite: Fixed value for Dsite\n        --fix-t: JSON string mapping time points to fixed param values\n        --bootstraps: Number of bootstrapping iterations (default: 0)\n        --profile-start: Start time for profile estimation (default: None)\n        --profile-end: End time for profile estimation (default: 1)\n        --profile-step: Step size for profile estimation (default: 0.5)\n        --input-excel: Path to the input Excel file (default: INPUT_EXCEL)\n    Returns:\n        argparse.Namespace: The parsed command-line arguments.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"PhosKinTime - ODE Parameter Estimation of Phosphorylation Events in Temporal Space\"\n    )\n    parser.add_argument(\"--A-bound\", type=parse_bound_pair, default=\"0,20\")\n    parser.add_argument(\"--B-bound\", type=parse_bound_pair, default=\"0,20\")\n    parser.add_argument(\"--C-bound\", type=parse_bound_pair, default=\"0,20\")\n    parser.add_argument(\"--D-bound\", type=parse_bound_pair, default=\"0,20\")\n    parser.add_argument(\"--Ssite-bound\", type=parse_bound_pair, default=\"0,20\")\n    parser.add_argument(\"--Dsite-bound\", type=parse_bound_pair, default=\"0,20\")\n\n    parser.add_argument(\"--fix-A\", type=float, default=None)\n    parser.add_argument(\"--fix-B\", type=float, default=None)\n    parser.add_argument(\"--fix-C\", type=float, default=None)\n    parser.add_argument(\"--fix-D\", type=float, default=None)\n    parser.add_argument(\"--fix-Ssite\", type=parse_fix_value, default=None)\n    parser.add_argument(\"--fix-Dsite\", type=parse_fix_value, default=None)\n\n    parser.add_argument(\"--fix-t\", type=str, default='{ '\n                                                     '\\\"0\\\": {\\\"A\\\": 0.85, \\\"S\\\": 0.1},  '\n                                                     '\\\"60\\\": {\\\"A\\\":0.85, \\\"S\\\": 0.2},  '\n                                                     '\\\"inf\\\": {\\\"A\\\":0.85, \\\"S\\\": 0.4} '\n                                                     '}',\n                        help=\"JSON string mapping time points to fixed param values, e.g. '{\\\"60\\\": {\\\"A\\\": 1.3}}'\")\n    parser.add_argument(\"--bootstraps\", type=int, default=0)\n    parser.add_argument(\"--profile-start\", type=float, default=None)\n    parser.add_argument(\"--profile-end\", type=float, default=1)\n    parser.add_argument(\"--profile-step\", type=float, default=0.5)\n    parser.add_argument(\"--input-excel\", type=str,\n                        default=INPUT_EXCEL,\n                        help=\"Path to the input Excel file\")\n\n    return parser.parse_args()\n</code></pre>"},{"location":"reference/#config.config.parse_bound_pair","title":"<code>parse_bound_pair(val)</code>","text":"<p>Parse a string representing a pair of bounds (lower, upper) into a tuple of floats. The upper bound can be 'inf' or 'infinity' to represent infinity. Raises ValueError if the input is not in the correct format. Args:     val (str): The string to parse, e.g., \"0,3\" or \"0,infinity\". Returns:     tuple: A tuple containing the lower and upper bounds as floats.</p> Source code in <code>config/config.py</code> <pre><code>def parse_bound_pair(val):\n    \"\"\"\n    Parse a string representing a pair of bounds (lower, upper) into a tuple of floats.\n    The upper bound can be 'inf' or 'infinity' to represent infinity.\n    Raises ValueError if the input is not in the correct format.\n    Args:\n        val (str): The string to parse, e.g., \"0,3\" or \"0,infinity\".\n    Returns:\n        tuple: A tuple containing the lower and upper bounds as floats.\n    \"\"\"\n    try:\n        parts = val.split(',')\n        if len(parts) != 2:\n            raise ValueError(\"Bounds must be provided as 'lower,upper'\")\n        lower = float(parts[0])\n        upper_str = parts[1].strip().lower()\n        if upper_str in [\"inf\", \"infinity\"]:\n            upper = float(\"inf\")\n        else:\n            upper = float(parts[1])\n        return lower, upper\n    except Exception as e:\n        raise argparse.ArgumentTypeError(f\"Invalid bound pair '{val}': {e}\")\n</code></pre>"},{"location":"reference/#config.config.parse_fix_value","title":"<code>parse_fix_value(val)</code>","text":"<p>Parse a fixed value or a list of fixed values from a string. If the input is a single value, it returns that value as a float. If the input is a comma-separated list, it returns a list of floats. Raises ValueError if the input is not in the correct format. Args:     val (str): The string to parse, e.g., \"1.0\" or \"1.0,2.0\". Returns:     float or list: The parsed fixed value(s) as a float or a list of floats.</p> Source code in <code>config/config.py</code> <pre><code>def parse_fix_value(val):\n    \"\"\"\n    Parse a fixed value or a list of fixed values from a string.\n    If the input is a single value, it returns that value as a float.\n    If the input is a comma-separated list, it returns a list of floats.\n    Raises ValueError if the input is not in the correct format.\n    Args:\n        val (str): The string to parse, e.g., \"1.0\" or \"1.0,2.0\".\n    Returns:\n        float or list: The parsed fixed value(s) as a float or a list of floats.\n    \"\"\"\n    if val is None:\n        return None\n    if ',' in val:\n        try:\n            return [float(x) for x in val.split(',')]\n        except Exception as e:\n            raise argparse.ArgumentTypeError(f\"Invalid fixed value list '{val}': {e}\")\n    else:\n        try:\n            return float(val)\n        except Exception as e:\n            raise argparse.ArgumentTypeError(f\"Invalid fixed value '{val}': {e}\")\n</code></pre>"},{"location":"reference/#config.config.score_fit","title":"<code>score_fit(target, prediction, params, alpha=ALPHA_WEIGHT, beta=BETA_WEIGHT, gamma=GAMMA_WEIGHT, delta=DELTA_WEIGHT, reg_penalty=MU_REG)</code>","text":"<p>Calculate the score for the fit of a model to target data. The score is a weighted combination of various metrics including mean squared error (MSE), root mean squared error (RMSE), mean absolute error (MAE), variance, and regularization penalty. The weights for each metric can be adjusted using the parameters alpha, beta, gamma, and delta. The regularization penalty is controlled by the reg_penalty parameter. The function returns the calculated score. :param target: :param prediction: :param params: :param alpha: :param beta: :param gamma: :param delta: :param reg_penalty: :return:</p> Source code in <code>config/config.py</code> <pre><code>def score_fit(target, prediction, params,\n              alpha=ALPHA_WEIGHT,\n              beta=BETA_WEIGHT,\n              gamma=GAMMA_WEIGHT,\n              delta=DELTA_WEIGHT,\n              reg_penalty=MU_REG):\n    \"\"\"\n    Calculate the score for the fit of a model to target data.\n    The score is a weighted combination of various metrics including\n    mean squared error (MSE), root mean squared error (RMSE),\n    mean absolute error (MAE), variance, and regularization penalty.\n    The weights for each metric can be adjusted using the parameters\n    alpha, beta, gamma, and delta.\n    The regularization penalty is controlled by the reg_penalty parameter.\n    The function returns the calculated score.\n    :param target:\n    :param prediction:\n    :param params:\n    :param alpha:\n    :param beta:\n    :param gamma:\n    :param delta:\n    :param reg_penalty:\n    :return:\n    \"\"\"\n    residual = target - prediction\n    mse = np.sum(np.abs(residual) ** 2)\n    rmse = np.sqrt(np.mean(residual ** 2))\n    mae = np.mean(np.abs(residual))\n    variance = np.var(residual)\n    l2_norm = np.linalg.norm(params)\n\n    score = delta * mse + alpha * rmse + beta * mae + gamma * variance + reg_penalty * l2_norm\n    return score\n</code></pre>"},{"location":"reference/#config.constants.generate_labels_ds","title":"<code>generate_labels_ds(num_psites)</code>","text":"<p>Generates labels for the states based on the number of phosphorylation sites for the distributive or successive models. Returns a list with the base labels \"R\" and \"P\", followed by labels for each individual phosphorylated state. Example for num_psites=2: [\"R\", \"P\", \"P1\", \"P2\"]</p> Source code in <code>config/helpers/__init__.py</code> <pre><code>def generate_labels_ds(num_psites: int) -&gt; list:\n    \"\"\"\n    Generates labels for the states based on the number of phosphorylation sites for the distributive or successive models.\n    Returns a list with the base labels \"R\" and \"P\", followed by labels for each individual phosphorylated state.\n    Example for num_psites=2: [\"R\", \"P\", \"P1\", \"P2\"]\n    \"\"\"\n    return [\"R\", \"P\"] + [f\"P{i}\" for i in range(1, num_psites + 1)]\n</code></pre>"},{"location":"reference/#config.constants.generate_labels_rand","title":"<code>generate_labels_rand(num_psites)</code>","text":"<p>Generates labels for the states based on the number of phosphorylation sites for the random model. Returns a list with the base labels \"R\" and \"P\", followed by labels for all combinations of phosphorylated sites. Example for num_psites=2: [\"R\", \"P\", \"P1\", \"P2\", \"P12\"]</p> Source code in <code>config/helpers/__init__.py</code> <pre><code>def generate_labels_rand(num_psites: int) -&gt; list:\n    \"\"\"\n    Generates labels for the states based on the number of phosphorylation sites for the random model.\n    Returns a list with the base labels \"R\" and \"P\", followed by labels for all combinations of phosphorylated sites.\n    Example for num_psites=2: [\"R\", \"P\", \"P1\", \"P2\", \"P12\"]\n    \"\"\"\n    labels = [\"R\", \"P\"]\n    subsets = []\n    for k in range(1, num_psites + 1):\n        for comb in combinations(range(1, num_psites + 1), k):\n            subsets.append(\"P\" + \"\".join(map(str, comb)))\n    return labels + subsets\n</code></pre>"},{"location":"reference/#config.constants.get_bounds_rand","title":"<code>get_bounds_rand(num_psites, ub=0, lower=0)</code>","text":"<p>Generate bounds for the ODE parameters based on the number of phosphorylation sites.</p> <p>Parameters:</p> Name Type Description Default <code>num_psites</code> <code>int</code> <p>Number of phosphorylation sites.</p> required <code>lower</code> <code>float</code> <p>Lower bound for parameters.</p> <code>0</code> <code>upper</code> <code>float</code> <p>Upper bound for parameters.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>List of bounds as [lower, upper] for each parameter.</p> Source code in <code>config/helpers/__init__.py</code> <pre><code>def get_bounds_rand(num_psites, ub= 0, lower=0):\n    \"\"\"\n    Generate bounds for the ODE parameters based on the number of phosphorylation sites.\n\n    Args:\n        num_psites (int): Number of phosphorylation sites.\n        lower (float): Lower bound for parameters.\n        upper (float): Upper bound for parameters.\n\n    Returns:\n        list: List of bounds as [lower, upper] for each parameter.\n    \"\"\"\n    bounds = [[lower, ub]] * 4\n    bounds += [[lower, ub]] * num_psites\n    for i in range(1, num_psites + 1):\n        for _ in combinations(range(1, num_psites + 1), i):\n            bounds.append([lower, ub])\n    return bounds\n</code></pre>"},{"location":"reference/#config.constants.get_number_of_params_rand","title":"<code>get_number_of_params_rand(num_psites)</code>","text":"<p>Calculate the number of parameters required for the ODE system based on the number of phosphorylation sites.</p> <p>Parameters:</p> Name Type Description Default <code>num_psites</code> <code>int</code> <p>Number of phosphorylation sites (1 to 4).</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>Total number of parameters.</p> Source code in <code>config/helpers/__init__.py</code> <pre><code>def get_number_of_params_rand(num_psites):\n    \"\"\"\n    Calculate the number of parameters required for the ODE system based on the number of phosphorylation sites.\n\n    Args:\n        num_psites (int): Number of phosphorylation sites (1 to 4).\n\n    Returns:\n        int: Total number of parameters.\n    \"\"\"\n    base_params = 4\n    phosphorylation_params = num_psites\n    dephosphorylation_params = sum(comb(num_psites, i) for i in range(1, num_psites + 1))\n    total_params = base_params + phosphorylation_params + dephosphorylation_params\n    return total_params\n</code></pre>"},{"location":"reference/#config.constants.get_param_names_ds","title":"<code>get_param_names_ds(num_psites)</code>","text":"<p>Generate parameter names for distributive or successive models. Format: ['A', 'B', 'C', 'D'] +         ['S1', 'S2', ..., 'S'] +         ['D1', 'D2', ..., 'D']. Source code in <code>config/helpers/__init__.py</code> <pre><code>def get_param_names_ds(num_psites: int) -&gt; list:\n    \"\"\"\n    Generate parameter names for distributive or successive models.\n    Format: ['A', 'B', 'C', 'D'] +\n            ['S1', 'S2', ..., 'S&lt;num_psites&gt;'] +\n            ['D1', 'D2', ..., 'D&lt;num_psites&gt;'].\n    \"\"\"\n    return ['A', 'B', 'C', 'D'] + [f'S{i + 1}' for i in range(num_psites)] + [f'D{i + 1}' for i in range(num_psites)]\n</code></pre>"},{"location":"reference/#config.constants.get_param_names_rand","title":"<code>get_param_names_rand(num_psites)</code>","text":"<p>Generate parameter names for the random model. Format: ['A', 'B', 'C', 'D'] +         ['S1', 'S2', ..., 'S'] +         [parameter names for all combinations of dephosphorylation sites]. Source code in <code>config/helpers/__init__.py</code> <pre><code>def get_param_names_rand(num_psites: int) -&gt; list:\n    \"\"\"\n    Generate parameter names for the random model.\n    Format: ['A', 'B', 'C', 'D'] +\n            ['S1', 'S2', ..., 'S&lt;num_psites&gt;'] +\n            [parameter names for all combinations of dephosphorylation sites].\n    \"\"\"\n    param_names = ['A', 'B', 'C', 'D']\n    param_names += [f'S{i}' for i in range(1, num_psites + 1)]\n    for i in range(1, num_psites + 1):\n        for combo in combinations(range(1, num_psites + 1), i):\n            param_names.append(f\"D{''.join(map(str, combo))}\")\n    return param_names\n</code></pre>"},{"location":"reference/#config.constants.location","title":"<code>location(path, label=None)</code>","text":"<p>Returns a clickable hyperlink string for supported terminals using ANSI escape sequences.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The file path or URL.</p> required <code>label</code> <code>str</code> <p>The display text for the link. Defaults to the path if not provided.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A string that, when printed, shows a clickable link in terminals that support ANSI hyperlinks.</p> Source code in <code>config/helpers/__init__.py</code> <pre><code>def location(path: str, label: str = None) -&gt; str:\n    \"\"\"\n    Returns a clickable hyperlink string for supported terminals using ANSI escape sequences.\n\n    Args:\n        path (str): The file path or URL.\n        label (str, optional): The display text for the link. Defaults to the path if not provided.\n\n    Returns:\n        str: A string that, when printed, shows a clickable link in terminals that support ANSI hyperlinks.\n    \"\"\"\n    if label is None:\n        label = path\n    # Ensure the path is a URL (for file paths, prepend file://)\n    if not (path.startswith(\"http://\") or path.startswith(\"https://\") or path.startswith(\"file://\")):\n        path = f\"file://{path}\"\n    # ANSI escape sequence format: ESC ] 8 ; ; &lt;URL&gt; ESC \\ &lt;label&gt; ESC ] 8 ; ; ESC \\\n    return f\"\\033]8;;{path}\\033\\\\{label}\\033]8;;\\033\\\\\"\n</code></pre>"},{"location":"reference/#config.logconf.ColoredFormatter","title":"<code>ColoredFormatter</code>","text":"<p>               Bases: <code>Formatter</code></p> <p>Custom formatter to add colors to log messages and elapsed time. This formatter uses ANSI escape codes to colorize the log messages based on their severity level. It also includes a right-aligned clock that shows the elapsed time since the logger was initialized. The elapsed time is displayed in a human-readable format (e.g., \"1h 23m 45s\"). The formatter is designed to be used with a logger that has a console handler. The elapsed time is calculated from the time the logger was initialized and is displayed in a right-aligned format. The formatter also ensures that the log messages are padded to a specified width, which can be adjusted using the <code>width</code> parameter. The <code>remove_ansi</code> method is used to strip ANSI escape codes from the log message for accurate padding calculation. The <code>format</code> method is overridden to customize the log message format, including the timestamp, logger name, log level, and message. The <code>setup_logger</code> function is used to configure the logger with a file handler and a stream handler. The file handler writes log messages to a specified log file, while the stream handler outputs log messages to the console. The logger is set to the specified logging level, and the log file is created in the specified directory. The log file is rotated based on size, and old log files are backed up.</p> Source code in <code>config/logconf.py</code> <pre><code>class ColoredFormatter(logging.Formatter):\n    \"\"\"\n    Custom formatter to add colors to log messages and elapsed time.\n    This formatter uses ANSI escape codes to colorize the log messages based on their severity level.\n    It also includes a right-aligned clock that shows the elapsed time since the logger was initialized.\n    The elapsed time is displayed in a human-readable format (e.g., \"1h 23m 45s\").\n    The formatter is designed to be used with a logger that has a console handler.\n    The elapsed time is calculated from the time the logger was initialized and is displayed in a right-aligned format.\n    The formatter also ensures that the log messages are padded to a specified width, which can be adjusted using the `width` parameter.\n    The `remove_ansi` method is used to strip ANSI escape codes from the log message for accurate padding calculation.\n    The `format` method is overridden to customize the log message format, including the timestamp, logger name, log level, and message.\n    The `setup_logger` function is used to configure the logger with a file handler and a stream handler.\n    The file handler writes log messages to a specified log file, while the stream handler outputs log messages to the console.\n    The logger is set to the specified logging level, and the log file is created in the specified directory.\n    The log file is rotated based on size, and old log files are backed up.\n    \"\"\"\n    def __init__(self, fmt=None, datefmt=None, width=120):\n        super().__init__(fmt, datefmt)\n        self.start_time = datetime.now()\n        self.width = width\n\n    def format(self, record):\n        \"\"\"\n        Format the log record with colors and elapsed time.\n        This method overrides the default format method to customize the log message format.\n        It includes the timestamp, logger name, log level, and message.\n        \"\"\"\n        elapsed = (datetime.now() - self.start_time).total_seconds()\n        elapsed_str = f\"{LOG_COLORS['ELAPSED']}\u23f1 {format_duration(elapsed)}{LOG_COLORS['ENDC']}\"\n\n        # Compose colored parts\n        color = LOG_COLORS.get(record.levelname, LOG_COLORS[\"INFO\"])\n        time_str = f\"{LOG_COLORS['DEBUG']}{self.formatTime(record)}{LOG_COLORS['ENDC']}\"\n        name_str = f\"{LOG_COLORS['WARNING']}{record.name}{LOG_COLORS['ENDC']}\"\n        level_str = f\"{color}{record.levelname}{LOG_COLORS['ENDC']}\"\n        msg_str = f\"{color}{record.getMessage()}{LOG_COLORS['ENDC']}\"\n\n        raw_msg = f\"{time_str} - {name_str} - {level_str} - {msg_str}\"\n        no_ansi_len = len(self.remove_ansi(raw_msg))\n        padding = max(0, self.width - no_ansi_len)\n        return f\"{raw_msg}{' ' * padding}{elapsed_str}\"\n\n    @staticmethod\n    def remove_ansi(s):\n        \"\"\"\n        Remove ANSI escape codes from a string.\n        \"\"\"\n        ansi_escape = re.compile(r'\\x1B\\[[0-?]*[ -/]*[@-~]')\n        return ansi_escape.sub('', s)\n</code></pre>"},{"location":"reference/#config.logconf.ColoredFormatter.format","title":"<code>format(record)</code>","text":"<p>Format the log record with colors and elapsed time. This method overrides the default format method to customize the log message format. It includes the timestamp, logger name, log level, and message.</p> Source code in <code>config/logconf.py</code> <pre><code>def format(self, record):\n    \"\"\"\n    Format the log record with colors and elapsed time.\n    This method overrides the default format method to customize the log message format.\n    It includes the timestamp, logger name, log level, and message.\n    \"\"\"\n    elapsed = (datetime.now() - self.start_time).total_seconds()\n    elapsed_str = f\"{LOG_COLORS['ELAPSED']}\u23f1 {format_duration(elapsed)}{LOG_COLORS['ENDC']}\"\n\n    # Compose colored parts\n    color = LOG_COLORS.get(record.levelname, LOG_COLORS[\"INFO\"])\n    time_str = f\"{LOG_COLORS['DEBUG']}{self.formatTime(record)}{LOG_COLORS['ENDC']}\"\n    name_str = f\"{LOG_COLORS['WARNING']}{record.name}{LOG_COLORS['ENDC']}\"\n    level_str = f\"{color}{record.levelname}{LOG_COLORS['ENDC']}\"\n    msg_str = f\"{color}{record.getMessage()}{LOG_COLORS['ENDC']}\"\n\n    raw_msg = f\"{time_str} - {name_str} - {level_str} - {msg_str}\"\n    no_ansi_len = len(self.remove_ansi(raw_msg))\n    padding = max(0, self.width - no_ansi_len)\n    return f\"{raw_msg}{' ' * padding}{elapsed_str}\"\n</code></pre>"},{"location":"reference/#config.logconf.ColoredFormatter.remove_ansi","title":"<code>remove_ansi(s)</code>  <code>staticmethod</code>","text":"<p>Remove ANSI escape codes from a string.</p> Source code in <code>config/logconf.py</code> <pre><code>@staticmethod\ndef remove_ansi(s):\n    \"\"\"\n    Remove ANSI escape codes from a string.\n    \"\"\"\n    ansi_escape = re.compile(r'\\x1B\\[[0-?]*[ -/]*[@-~]')\n    return ansi_escape.sub('', s)\n</code></pre>"},{"location":"reference/#config.logconf.setup_logger","title":"<code>setup_logger(name='phoskintime', log_file=None, level=logging.DEBUG, log_dir=LOG_DIR, rotate=True, max_bytes=2 * 1024 * 1024, backup_count=5)</code>","text":"<p>Setup a logger with colored output and file logging. This function creates a logger with colored output for console messages :param name: :param log_file: :param level: :param log_dir: :param rotate: :param max_bytes: :param backup_count: :return: logger</p> Source code in <code>config/logconf.py</code> <pre><code>def setup_logger(\n    name=\"phoskintime\",\n    log_file=None,\n    level=logging.DEBUG,\n    log_dir=LOG_DIR,\n    rotate=True,\n    max_bytes=2 * 1024 * 1024,\n    backup_count=5\n):\n    \"\"\"\n    Setup a logger with colored output and file logging.\n    This function creates a logger with colored output for console messages\n    :param name:\n    :param log_file:\n    :param level:\n    :param log_dir:\n    :param rotate:\n    :param max_bytes:\n    :param backup_count:\n    :return: logger\n    \"\"\"\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n\n    if log_file is None:\n        timestamp = datetime.now().strftime(\"%Y%m%d\")\n        log_file = os.path.join(log_dir, f\"{name}_{timestamp}.log\")\n\n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n\n    if logger.hasHandlers():\n        logger.handlers.clear()\n\n    # File Handler\n    if rotate:\n        file_handler = RotatingFileHandler(log_file, maxBytes=max_bytes, backupCount=backup_count)\n    else:\n        file_handler = logging.FileHandler(log_file)\n\n    file_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    file_handler.setFormatter(file_format)\n    logger.addHandler(file_handler)\n\n    # Stream Handler (Console)\n    stream_handler = logging.StreamHandler()\n    stream_format = ColoredFormatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    stream_handler.setFormatter(stream_format)\n    stream_handler.setLevel(logging.INFO)\n    logger.addHandler(stream_handler)\n\n    return logger\n</code></pre>"},{"location":"reference/#kinopt.evol.exporter.plotout.opt_analyze_de","title":"<code>opt_analyze_de(long_df, convergence_df, ordered_optimizer_runs, x_values, y_values, val)</code>","text":"<p>Generates and saves various plots related to optimization results. This includes waterfall plots, convergence plots, parameter trend plots, and parameter scan plots.</p> <p>:param long_df: :param convergence_df: :param ordered_optimizer_runs: :param x_values: :param y_values: :param val:</p> Source code in <code>kinopt/evol/exporter/plotout.py</code> <pre><code>def opt_analyze_de(long_df, convergence_df, ordered_optimizer_runs,\n                   x_values, y_values, val):\n    \"\"\"\n    Generates and saves various plots related to optimization results.\n    This includes waterfall plots, convergence plots, parameter trend plots,\n    and parameter scan plots.\n\n    :param long_df:\n    :param convergence_df:\n    :param ordered_optimizer_runs:\n    :param x_values:\n    :param y_values:\n    :param val:\n    \"\"\"\n    # Waterfall plot\n    plt.figure(figsize=(8, 8))\n    plt.scatter(\n        range(len(ordered_optimizer_runs[\"Objective Value (F)\"])),\n        ordered_optimizer_runs[\"Objective Value (F)\"],\n        color=\"black\",\n        marker=\"s\",\n        label=\"Objective Value\"\n    )\n    # Customize the plot\n    plt.title(\"\")\n    plt.xlabel(\"Optimizer Runs\", fontsize=8)\n    plt.ylabel(\"f\", fontsize=8, fontstyle='italic')\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/waterfall.png', dpi=300)\n    plt.close()\n    # Waterfall plot\n    plt.figure(figsize=(8, 8))\n    plt.plot(x_values, y_values, color=\"gray\", linestyle=\"-\", alpha=0.7)\n    # Plot the points\n    plt.scatter(\n        x_values,\n        y_values,\n        color=\"black\",\n        marker=\"s\",\n        label=\"Objective Value\"\n    )\n    plt.title(\"\")\n    plt.xlabel(\"Optimizer Runs\", fontsize=8)\n    plt.ylabel(\"f\", fontsize=8, fontstyle='italic')\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/waterfall_2.png', dpi=300)\n    plt.close()\n\n    # Covergence plot\n    plt.figure(figsize=(8, 8))\n    plt.bar(\n        convergence_df[\"Iteration\"],\n        convergence_df[\"Value\"].diff().fillna(convergence_df[\"Value\"]),  # Changes in Value\n        color=\"coral\",\n        alpha=0.6,\n        label=\"\u2206Error\"\n    )\n    plt.plot(convergence_df[\"Iteration\"], convergence_df[\"Value\"], marker=\"o\", color=\"red\", label=\"Error\")\n    plt.title(\"\")\n    plt.xlabel(\"Iteration\", fontsize=8)\n    plt.ylabel(\"f\", fontsize=8, fontstyle='italic')\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/convergence_2.png', dpi=300)\n    plt.close()\n\n    plt.figure(figsize=(8, 8))\n    plt.plot(np.arange(len(val)), val, marker='o', linestyle='-', color='red')\n    plt.title(\"\")\n    plt.xlabel(\"Iteration\", fontsize=8)\n    plt.ylabel(\"f\", fontsize=8, fontstyle='italic')\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/convergence.png\", dpi=300)\n    plt.close()\n    plt.figure(figsize=(8, 8))\n    style = {\"\u03b1\": {\"color\": 'teal', \"marker\": \"o\"},\n             \"\u03b2\": {\"color\": 'indigo', \"marker\": \"o\"}}\n    for param_type, props in style.items():\n        subset = long_df[long_df[\"Type\"] == param_type]\n        plt.scatter(\n            subset[\"Parameter Value\"],\n            subset[\"Objective Value (F)\"],\n            label=param_type,\n            alpha=0.4,\n            color=props[\"color\"],\n            marker=props[\"marker\"]\n        )\n    plt.title(\"\")\n    plt.xlabel(\"Optimized Values\", fontsize=10)\n    plt.ylabel(\"f\", fontsize=8, fontstyle='italic')\n    plt.legend(title=\"Parameter\")\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/parameter_trend.png', dpi=300)\n    plt.close()\n    # Use a hexbin plot to visualize distributions of parameter values\n    # across the objective function\n    plt.figure(figsize=(8, 8))\n    hb = plt.hexbin(\n        long_df[\"Parameter Value\"],\n        long_df[\"Objective Value (F)\"],\n        gridsize=50,\n        cmap=\"viridis\",\n        mincnt=1\n    )\n    plt.colorbar(hb, label=\"Frequency\")\n    plt.title(\"\")\n    plt.xlabel(\"Optimized Values\", fontsize=8)\n    plt.ylabel(\"f\", fontsize=10, fontstyle='italic')\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/parameter_scan.png\", dpi=300)\n    plt.close()\n    # Plot the distributional plot\n    plt.figure(figsize=(8, 8))  # Adjust width to accommodate many parameters\n    sns.violinplot(\n        x=\"Parameter\",\n        y=\"Parameter Value\",\n        hue=\"Objective Value (F)\",  # This shows the distribution with respect to objective values\n        data=long_df,\n        palette=\"viridis\",\n        density_norm='width',\n        cut=0,\n        legend=False,\n    )\n    plt.xticks([])  # Remove x-axis ticks\n    plt.title(\"\")\n    plt.xlabel(\"\")  # Remove the x-axis label\n    plt.ylabel(\"Optimized Values\", fontsize=8)\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/parameter_scatter.png\", format=\"png\", dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#kinopt.evol.exporter.plotout.opt_analyze_nsga","title":"<code>opt_analyze_nsga(problem, result, F, pairs, approx_ideal, approx_nadir, asf_i, pseudo_i, n_evals, hv, hist, val, hist_cv_avg, k, igd, best_objectives, waterfall_df, convergence_df, alpha_values, beta_values)</code>","text":"<p>Generates and saves various plots related to optimization results. This includes design space plots, objective space plots, convergence plots, and parameter trend plots.</p> <p>:param problem: :param result: :param F: :param pairs: :param approx_ideal: :param approx_nadir: :param asf_i: :param pseudo_i: :param n_evals: :param hv: :param hist: :param val: :param hist_cv_avg: :param k: :param igd: :param best_objectives: :param waterfall_df: :param convergence_df: :param alpha_values: :param beta_values:</p> Source code in <code>kinopt/evol/exporter/plotout.py</code> <pre><code>def opt_analyze_nsga(problem, result, F, pairs, approx_ideal,\n                approx_nadir, asf_i, pseudo_i, n_evals,\n                hv, hist, val, hist_cv_avg, k, igd, best_objectives,\n                waterfall_df, convergence_df, alpha_values,\n                beta_values):\n    \"\"\"\n    Generates and saves various plots related to optimization results.\n    This includes design space plots, objective space plots,\n    convergence plots, and parameter trend plots.\n\n    :param problem:\n    :param result:\n    :param F:\n    :param pairs:\n    :param approx_ideal:\n    :param approx_nadir:\n    :param asf_i:\n    :param pseudo_i:\n    :param n_evals:\n    :param hv:\n    :param hist:\n    :param val:\n    :param hist_cv_avg:\n    :param k:\n    :param igd:\n    :param best_objectives:\n    :param waterfall_df:\n    :param convergence_df:\n    :param alpha_values:\n    :param beta_values:\n    \"\"\"\n    xl, xu = problem.bounds()\n    plt.figure(figsize=(8, 8))\n    plt.scatter(result.X[:, 0], result.X[:, 1], s=30, facecolors='none', edgecolors='r')\n    plt.xlim(xl[0], xu[0])\n    plt.ylim(xl[1], xu[1])\n    plt.title(\"Design Space\")\n    plt.savefig(f\"{OUT_DIR}/design_space.png\", dpi=300)\n    plt.close()\n    for i, (x, y) in enumerate(pairs):\n        plt.figure(figsize=(8, 8))\n        plt.scatter(F[:, x], F[:, y], s=30, facecolors='none', edgecolors='blue')\n        plt.title(f\"Objective Space (F[{x}] vs F[{y}])\")\n        plt.xlabel(f\"F[{x}]\")\n        plt.ylabel(f\"F[{y}]\")\n        plt.savefig(f\"{OUT_DIR}/objective_space_{x}_{y}.png\", dpi=300)\n        plt.close()\n    plt.figure(figsize=(8, 8))\n    ax = plt.axes(projection=\"3d\")\n    ax.scatter(F[:, 0], F[:, 1], F[:, 2], s=30, c='blue', label=\"Solutions\")\n    ax.scatter(approx_ideal[0], approx_ideal[1], approx_ideal[2], c='red', s=100, marker=\"*\",\n               label=\"Ideal Point (Approx)\")\n    ax.scatter(approx_nadir[0], approx_nadir[1], approx_nadir[2], c='black', s=100, marker=\"p\",\n               label=\"Nadir Point (Approx)\")\n    ax.set_title(\"Objective Space (3D)\")\n    ax.set_xlabel(\"F[0]\")\n    ax.set_ylabel(\"F[1]\")\n    ax.set_zlabel(\"F[2]\")\n    ax.legend()\n    plt.savefig(f\"{OUT_DIR}/objective_space_3d.png\", dpi=300)\n    plt.close()\n\n    plt.figure(figsize=(8, 8))\n    plt.scatter(F[:, 0], F[:, 1], s=30, facecolors='none', edgecolors='blue')\n    plt.scatter(F[asf_i, 0], F[asf_i, 1], marker=\"x\", color=\"red\", s=200)\n    plt.title(\"ASF (Alpha Constraints vs Error)\")\n    plt.savefig(f\"{OUT_DIR}/asf_plot1.png\", dpi=300)\n    plt.close()\n\n    plt.figure(figsize=(8, 8))\n    plt.scatter(F[:, 1], F[:, 2], s=30, facecolors='none', edgecolors='blue')\n    plt.scatter(F[asf_i, 1], F[asf_i, 2], marker=\"x\", color=\"red\", s=200)\n    plt.title(\"ASF (Alpha vs Beta Constraints)\")\n    plt.savefig(f\"{OUT_DIR}/asf_plot2.png\", dpi=300)\n    plt.close()\n\n    plt.figure(figsize=(8, 8))\n    plt.scatter(F[:, 0], F[:, 2], s=30, facecolors='none', edgecolors='blue')\n    plt.scatter(F[asf_i, 0], F[asf_i, 2], marker=\"x\", color=\"red\", s=200)\n    plt.title(\"ASF (Beta Constraints vs Error)\")\n    plt.savefig(f\"{OUT_DIR}/asf_plot3.png\", dpi=300)\n    plt.close()\n\n    plt.figure(figsize=(8, 8))\n    plt.scatter(F[:, 0], F[:, 1], s=30, facecolors='none', edgecolors='blue')\n    plt.scatter(F[pseudo_i, 0], F[pseudo_i, 1], marker=\"x\", color=\"red\", s=200)\n    plt.title(\"Pseudo Weights (Alpha Constraints vs Error)\")\n    plt.savefig(f\"{OUT_DIR}/pseudo_weights_plot1.png\", dpi=300)\n    plt.close()\n\n    plt.figure(figsize=(8, 8))\n    plt.scatter(F[:, 1], F[:, 2], s=30, facecolors='none', edgecolors='blue')\n    plt.scatter(F[pseudo_i, 1], F[pseudo_i, 2], marker=\"x\", color=\"red\", s=200)\n    plt.title(\"Pseudo Weights (Alpha vs Beta Constraints)\")\n    plt.savefig(f\"{OUT_DIR}/pseudo_weights_plot2.png\", dpi=300)\n    plt.close()\n\n    plt.figure(figsize=(8, 8))\n    plt.scatter(F[:, 0], F[:, 2], s=30, facecolors='none', edgecolors='blue')\n    plt.scatter(F[pseudo_i, 0], F[pseudo_i, 2], marker=\"x\", color=\"red\", s=200)\n    plt.title(\"Pseudo Weights (Beta Constraints vs Error)\")\n    plt.savefig(f\"{OUT_DIR}/pseudo_weights_plot2.png\", dpi=300)\n    plt.close()\n\n    plt.figure(figsize=(8, 8))\n    plt.plot(n_evals, hv, color='black', lw=0.7, label=\"Avg. CV of Pop\")\n    plt.scatter(n_evals, hv, facecolor=\"none\", edgecolor='black', marker=\"p\")\n    plt.title(\"Convergence\")\n    plt.xlabel(\"Function Evaluations\")\n    plt.ylabel(\"Hypervolume\")\n    plt.legend()\n    plt.savefig(f\"{OUT_DIR}/hypervolume_plot.png\", dpi=300)\n    plt.close()\n\n    plt.figure(figsize=(8, 8))\n    plt.plot(n_evals, hist_cv_avg, color='black', lw=0.7, label=\"Avg. CV of Pop\")\n    plt.scatter(n_evals, hist_cv_avg, facecolor=\"none\", edgecolor='black', marker=\"p\")\n    plt.axvline(n_evals[k], color=\"red\", label=\"All Feasible\", linestyle=\"--\")\n    plt.title(\"Convergence\")\n    plt.xlabel(\"Function Evaluations\")\n    plt.ylabel(\"Constraint Violation\")\n    plt.legend()\n    plt.savefig(f\"{OUT_DIR}/convergence_plot.png\", dpi=300)\n    plt.close()\n\n    plt.figure(figsize=(8, 8))\n    plt.plot(n_evals, igd, color='black', lw=0.7, label=\"IGD+\")\n    plt.scatter(n_evals, igd, facecolor=\"none\", edgecolor='black', marker=\"p\")\n    plt.axhline(10 ** -2, color=\"red\", label=\"10^-2\", linestyle=\"--\")\n    plt.title(\"IGD+ Convergence\")\n    plt.xlabel(\"Function Evaluations\")\n    plt.ylabel(\"IGD+\")\n    plt.yscale(\"log\")\n    plt.legend()\n    plt.savefig(f\"{OUT_DIR}/igd_convergence.png\", dpi=300)\n    plt.close()\n\n    plot = Radar(bounds=[approx_ideal, approx_nadir], normalize_each_objective=True, tight_layout=True)\n    plot.add(best_objectives)\n    plot.show()\n    plot.save(f\"{OUT_DIR}/radar_plot.png\", dpi=300)\n\n    # Get min and max values for each objective across all generations\n    all_f = np.vstack([algo.opt.get(\"F\") for algo in hist])  # Combine all generations\n    min_f = np.min(all_f, axis=0)\n    max_f = np.max(all_f, axis=0)\n    # Set up the figure and axis for 3D plotting\n    fig = plt.figure(figsize=(8, 8))\n    ax = fig.add_subplot(111, projection=\"3d\")\n    def update_frame(frame):\n        \"\"\"\n        Update the frame for the animation.\n        Args:\n            frame (int): The current frame number.\n        \"\"\"\n        ax.clear()\n        gen_data = hist[frame].opt.get(\"F\")  # Extract objective values for the current generation\n        ax.scatter(gen_data[:, 0], gen_data[:, 1], gen_data[:, 2], c='blue', alpha=0.6)\n        ax.set_title(f\"Generation {frame}\")\n        ax.set_xlabel(\"F[0]\")\n        ax.set_ylabel(\"F[1]\")\n        ax.set_zlabel(\"F[2]\")\n        ax.set_xlim([min_f[0], max_f[0]])\n        ax.set_ylim([min_f[1], max_f[1]])\n        ax.set_zlim([min_f[2], max_f[2]])\n    # Create the animation\n    anim = FuncAnimation(fig, update_frame, frames=len(hist), repeat=False)\n    # Save as GIF\n    anim.save(f\"{OUT_DIR}/optimization_run.gif\", writer=PillowWriter(fps=10), dpi=300)\n\n    ordered_optimizer_runs = waterfall_df.sort_values(by=\"Objective Value (F)\", ascending=True)\n    # Generate a waterfall plot for the convergence data\n    plt.figure(figsize=(8, 8))\n    plt.scatter(\n        range(len(ordered_optimizer_runs[\"Objective Value (F)\"])),\n        ordered_optimizer_runs[\"Objective Value (F)\"],\n        color=\"black\",\n        marker=\"s\",\n        label=\"Objective Value\"\n    )\n\n    # Customize the plot\n    plt.title(\"\")\n    plt.xlabel(\"Optimizer Runs\", fontsize=8)\n    plt.ylabel(\"f\", fontsize=8, fontstyle='italic')\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/waterfall.png', dpi=300)\n    plt.close()\n\n    # Generate a waterfall plot for the convergence data\n    plt.figure(figsize=(8, 8))\n\n    objective_values = ordered_optimizer_runs[\"Objective Value (F)\"].values\n\n    # Dynamically determine the threshold based on the range of objective values\n    threshold = 0.05 * (objective_values.max() - objective_values.min())\n\n    # Determine indices to plot\n    indices_to_plot = [0]  # Always plot the first point\n    for i in range(1, len(objective_values)):\n        if abs(objective_values[i] - objective_values[i - 1]) &gt; threshold:  # Significant change\n            indices_to_plot.append(i)\n        elif i % 10 == 0:  # Plot sparsely for small changes\n            indices_to_plot.append(i)\n\n            # Plot only the selected indices\n    x_values = indices_to_plot\n    y_values = [objective_values[i] for i in indices_to_plot]\n\n    # Plot the line connecting points\n    plt.plot(x_values, y_values, color=\"gray\", linestyle=\"-\", alpha=0.7)\n\n    # Plot the points\n    plt.scatter(\n        x_values,\n        y_values,\n        color=\"black\",\n        marker=\"s\",\n        label=\"Objective Value\"\n    )\n\n    # Customize the plot\n    plt.title(\"\")\n    plt.xlabel(\"Optimizer Runs\", fontsize=8)\n    plt.ylabel(\"f\", fontsize=8, fontstyle='italic')\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/waterfall_2.png', dpi=300)\n    plt.close()\n\n    # Covergence plot\n    plt.figure(figsize=(8, 8))\n    plt.bar(\n        convergence_df[\"Iteration\"],\n        convergence_df[\"Value\"].diff().fillna(convergence_df[\"Value\"]),  # Changes in Value\n        color=\"coral\",\n        alpha=0.6,\n        label=\"\u2206Error\"\n    )\n    plt.plot(convergence_df[\"Iteration\"], convergence_df[\"Value\"], marker=\"o\", color=\"red\", label=\"Error\")\n    plt.title(\"\")\n    plt.xlabel(\"Iteration\", fontsize=8)\n    plt.ylabel(\"f\", fontsize=8, fontstyle='italic')\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig('{OUT_DIR}/convergence_2.png', dpi=300)\n    plt.close()\n\n    plt.figure(figsize=(8, 8))\n    plt.plot(np.arange(len(val)), val, marker='o', linestyle='-', color='red')\n    plt.title(\"\")\n    plt.xlabel(\"Iteration\", fontsize=8)\n    plt.ylabel(\"f\", fontsize=8, fontstyle='italic')\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/convergence.png\", dpi=300)\n    plt.close()\n\n    # Combine alpha and beta labels with Greek symbols\n    param_labels = []\n\n    # Add alpha labels\n    for (gene, psite), kinases in alpha_values.items():\n        for kinase in kinases.keys():\n            param_labels.append(f\"\u03b1_{gene}_{psite}_{kinase}\")\n\n    # Add beta labels\n    for (kinase, psite), _ in beta_values.items():\n        param_labels.append(f\"\u03b2_{kinase}_{psite}\")\n\n    # Melt the DataFrame to make it long-form for easy plotting\n    long_df = waterfall_df.melt(id_vars=[\"Individual\", \"Objective Value (F)\"],\n                                value_vars=param_labels,\n                                var_name=\"Parameter\",\n                                value_name=\"Parameter Value\")\n\n    # Add a column to classify parameters as '\u03b1' or '\u03b2'\n    long_df[\"Type\"] = long_df[\"Parameter\"].apply(\n        lambda x: \"\u03b1\" if x.startswith(\"\u03b1\") else (\"\u03b2\" if x.startswith(\"\u03b2\") else \"Other\"))\n\n    # Sort the DataFrame by \"Parameter Value\"\n    long_df = long_df.sort_values(by=\"Objective Value (F)\")\n\n    plt.figure(figsize=(8, 8))\n    style = {\"\u03b1\": {\"color\": 'teal', \"marker\": \"o\"},\n             \"\u03b2\": {\"color\": 'indigo', \"marker\": \"o\"}}\n    for param_type, props in style.items():\n        subset = long_df[long_df[\"Type\"] == param_type]\n        plt.scatter(\n            subset[\"Parameter Value\"],\n            subset[\"Objective Value (F)\"],\n            label=param_type,\n            alpha=0.4,\n            color=props[\"color\"],\n            marker=props[\"marker\"]\n        )\n    plt.title(\"\")\n    plt.xlabel(\"Optimized Values\", fontsize=10)\n    plt.ylabel(\"f\", fontsize=8, fontstyle='italic')\n    plt.legend(title=\"Parameter\")\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/parameter_trend.png', dpi=300)\n    plt.close()\n\n    # Use a hexbin plot to visualize distributions of parameter values across the objective function\n    plt.figure(figsize=(8, 8))\n\n    hb = plt.hexbin(\n        long_df[\"Parameter Value\"],\n        long_df[\"Objective Value (F)\"],\n        gridsize=50,\n        cmap=\"viridis\",\n        mincnt=1\n    )\n    plt.colorbar(hb, label=\"Frequency\")\n    plt.title(\"\")\n    plt.xlabel(\"Optimized Values\", fontsize=8)\n    plt.ylabel(\"f\", fontsize=10, fontstyle='italic')\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/parameter_scan.png\", dpi=300)\n    plt.close()\n\n    # Plot the distributional plot\n    plt.figure(figsize=(8, 8))  # Adjust width to accommodate many parameters\n    sns.violinplot(\n        x=\"Parameter\",\n        y=\"Parameter Value\",\n        hue=\"Objective Value (F)\",  # This shows the distribution with respect to objective values\n        data=long_df,\n        palette=\"viridis\",\n        density_norm='width',\n        cut=0,\n        legend=False,\n    )\n    plt.xticks([])  # Remove x-axis ticks\n    plt.title(\"\")\n    plt.xlabel(\"\")  # Remove the x-axis label\n    plt.ylabel(\"Optimized Values\", fontsize=8)\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/parameter_scatter.png\", format=\"png\", dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#kinopt.evol.exporter.plotout.plot_residuals_for_gene","title":"<code>plot_residuals_for_gene(gene, gene_data)</code>","text":"<p>Generates and saves combined residual-related plots for one gene with all psites in the legend.</p> <p>Parameters:</p> Name Type Description Default <code>gene</code> <code>str</code> <p>Gene identifier.</p> required <code>gene_data</code> <code>dict</code> <p>Dictionary with keys 'psites', 'observed', 'estimated', and 'residuals' containing data for all psites.</p> required <code>TIME_POINTS</code> <code>ndarray or list</code> <p>Time points corresponding to the series.</p> required Source code in <code>kinopt/evol/exporter/plotout.py</code> <pre><code>def plot_residuals_for_gene(gene, gene_data):\n    \"\"\"\n    Generates and saves combined residual-related plots for one gene with all psites in the legend.\n\n    Args:\n        gene (str): Gene identifier.\n        gene_data (dict): Dictionary with keys 'psites', 'observed', 'estimated', and 'residuals' containing data for all psites.\n        TIME_POINTS (np.ndarray or list): Time points corresponding to the series.\n    \"\"\"\n    # Get colors from Dark2 palette\n    cmap = mpl.cm.get_cmap(\"Dark2\")\n    # cmap = mpl.cm.get_cmap(\"Set1\")\n    # cmap = mpl.cm.get_cmap(\"Set2\")\n\n    colors = [cmap(i % 20) for i in range(len(gene_data[\"psites\"]))]\n\n    fig, axs = plt.subplots(1, 2, figsize=(18, 8), sharey=True)\n\n    # Full timepoints plot\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        axs[0].plot(TIME_POINTS, gene_data[\"observed\"][i],\n                    label=f\"{psite}\", marker='s', linestyle='--',\n                    color=colors[i], alpha=0.5, markeredgecolor='black')\n        axs[0].plot(TIME_POINTS, gene_data[\"estimated\"][i],\n                    linestyle='-', color=colors[i])\n    axs[0].set_title(f\"{gene}\")\n    axs[0].set_xlabel(\"Time (minutes)\")\n    axs[0].set_ylabel(\"Phosphorylation Level (FC)\")\n    axs[0].grid(True, alpha=0.2)\n    axs[0].set_xticks(TIME_POINTS[9:])\n\n    # First 7 timepoints plot\n    short_timepoints = TIME_POINTS[:7]\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        axs[1].plot(short_timepoints, gene_data[\"observed\"][i][:7],\n                    label=f\"{psite}\", marker='s', linestyle='--',\n                    color=colors[i], alpha=0.5, markeredgecolor='black')\n        axs[1].plot(short_timepoints, gene_data[\"estimated\"][i][:7],\n                    linestyle='-', color=colors[i])\n    # axs[1].set_title(f\"{gene}\")\n    axs[1].set_xlabel(\"Time (minutes)\")\n    axs[1].grid(True, alpha=0.2)\n    axs[1].set_xticks(short_timepoints)\n    axs[1].legend(title=\"Residue_Position\", bbox_to_anchor=(1.05, 1), loc='upper left')\n    plt.tight_layout()\n    filename = f\"{OUT_DIR}/{gene}_fit_.png\"\n    plt.savefig(filename, dpi=300, bbox_inches='tight')\n    plt.close()\n\n    # 2. Cumulative Sum of Residuals\n    plt.figure(figsize=(8, 8))\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        plt.plot(\n            TIME_POINTS, np.cumsum(gene_data[\"residuals\"][i]),\n            label=f\"{psite}\", marker='o', color=colors[i], alpha=0.8, markeredgecolor='black'\n        )\n    plt.title(f\"{gene}\")\n    plt.xlabel(\"Time (minutes)\")\n    plt.ylabel(\"Cumulative Residuals\")\n    plt.grid(True)\n    plt.legend(title=\"Residue_Position\")\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/cumulative_residuals_{gene}.png\", format='png', dpi=300)\n    plt.close()\n\n    # 3. Autocorrelation of Residuals\n    plt.figure(figsize=(8, 8))\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        plot_acf(gene_data[\"residuals\"][i], lags=len(TIME_POINTS) - 1, alpha=0.05)\n    plt.title(f\"{gene}\")\n    plt.xlabel(\"Lags\")\n    plt.ylabel(\"Autocorrelation\")\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/autocorrelation_residuals_{gene}.png\", format='png', dpi=300)\n    plt.close()\n\n    # 4. Histogram of Residuals\n    plt.figure(figsize=(8, 8))\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        sns.histplot(gene_data[\"residuals\"][i], bins=20, kde=True, color=colors[i], label=f\"{psite}\", alpha=0.8)\n    plt.title(f\"{gene}\")\n    plt.xlabel(\"Residuals\")\n    plt.ylabel(\"Frequency\")\n    plt.grid(True)\n    plt.legend(title=\"Residue_Position\")\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/histogram_residuals_{gene}.png\", format='png', dpi=300)\n    plt.close()\n\n    # 5. QQ Plot of Residuals\n    plt.figure(figsize=(8, 8))\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        qqplot(gene_data[\"residuals\"][i], line='s', ax=plt.gca())\n    plt.title(f\"{gene}\")\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/qqplot_residuals_{gene}.png\", format='png', dpi=300)\n    plt.close('all')\n</code></pre>"},{"location":"reference/#kinopt.evol.exporter.sheetutils.output_results","title":"<code>output_results(P_initial, P_init_dense, P_estimated, residuals, alpha_values, beta_values, result, timepoints, OUT_FILE)</code>","text":"<p>This function is responsible for exporting the results of the optimization process to an Excel file. It creates multiple sheets in the Excel file, each containing different types of data related to the optimization results. The function also generates plots for the residuals of each gene. The data is organized in a structured manner, making it easy to analyze and interpret the results. The function takes the following parameters:</p> <p>:param P_initial: :param P_init_dense: :param P_estimated: :param residuals: :param alpha_values: :param beta_values: :param result: :param timepoints: :param OUT_FILE:</p> Source code in <code>kinopt/evol/exporter/sheetutils.py</code> <pre><code>def output_results(P_initial, P_init_dense, P_estimated, residuals, alpha_values, beta_values,\n                   result, timepoints, OUT_FILE):\n    \"\"\"\n    This function is responsible for exporting the results of the optimization process to an Excel file.\n    It creates multiple sheets in the Excel file, each containing different types of data related to the optimization results.\n    The function also generates plots for the residuals of each gene.\n    The data is organized in a structured manner, making it easy to analyze and interpret the results.\n    The function takes the following parameters:\n\n    :param P_initial:\n    :param P_init_dense:\n    :param P_estimated:\n    :param residuals:\n    :param alpha_values:\n    :param beta_values:\n    :param result:\n    :param timepoints:\n    :param OUT_FILE:\n    \"\"\"\n\n    # Build a genes_data dictionary from computed metrics.\n    genes_data = build_genes_data(P_initial, P_init_dense, P_estimated, residuals)\n\n    # For each gene, call the plotting functions.\n    for gene, gene_data in genes_data.items():\n        plot_residuals_for_gene(gene, gene_data)\n\n        # Write results to Excel.\n    output_file = OUT_FILE\n    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n        # Sheet 1: Alpha Values\n        # Create a DataFrame for alphas\n        alpha_data = []\n        for (gene, psite), kinases in alpha_values.items():\n            for kinase, value in kinases.items():\n                alpha_data.append({'Protein': gene, 'Psite': psite, 'Kinase': kinase, 'Alpha': value})\n        alpha_df = pd.DataFrame(alpha_data)\n\n        # Write alpha values to a separate sheet\n        alpha_df.to_excel(writer, sheet_name=\"Alpha Values\", index=False)\n\n        # Sheet 2: Beta Values\n        # Create a DataFrame for betas\n        # Collect beta data for each kinase and psite combination\n        beta_data = []\n        for (kinase, psite), value in beta_values.items():\n            beta_data.append({'Kinase': kinase, 'Psite': psite,\n                              'Beta': float(value.item()) if hasattr(value, \"item\") else float(value)})\n\n        # Create DataFrame from the collected data\n        beta_df = pd.DataFrame(beta_data)\n\n        # Write beta values to a separate sheet\n        beta_df.to_excel(writer, sheet_name=\"Beta Values\", index=False)\n\n        # Sheet 4: Residuals with Gene and Psite Labels\n        residuals_data = []\n        for i, ((gene, psite), data) in enumerate(P_initial.items()):\n            residual_row = {'Gene': gene, 'Psite': psite}\n            residual_row.update({time: residuals[i, t] for t, time in enumerate(timepoints)})\n            residuals_data.append(residual_row)\n        residuals_df = pd.DataFrame(residuals_data)\n        residuals_df.to_excel(writer, sheet_name=\"Residuals\", index=False)\n\n        # Sheet 5: Estimated Values with Gene and Psite Labels\n        estimated_data = []\n        for i, ((gene, psite), data) in enumerate(P_initial.items()):\n            estimated_row = {'Gene': gene, 'Psite': psite}\n            estimated_row.update({time: P_estimated[i, t] for t, time in enumerate(timepoints)})\n            estimated_data.append(estimated_row)\n        estimated_df = pd.DataFrame(estimated_data)\n        estimated_df.to_excel(writer, sheet_name=\"Estimated Values\", index=False)\n\n    logger.info(f\"Optimization results saved for ODE modelling.\")\n</code></pre>"},{"location":"reference/#kinopt.evol.objfn.minfndiffevo.PhosphorylationOptimizationProblem","title":"<code>PhosphorylationOptimizationProblem</code>","text":"<p>               Bases: <code>ElementwiseProblem</code></p> <p>Custom optimization problem for phosphorylation analysis.</p> <p>Defines the constraints, bounds, and objective function for optimizing alpha and beta parameters across gene-psite-kinase relationships.</p> <p>Attributes:</p> Name Type Description <code>P_initial</code> <code>dict</code> <p>Mapping of gene-psite pairs to kinase relationships and time-series data.</p> <code>P_initial_array</code> <code>ndarray</code> <p>Observed time-series data for gene-psite pairs.</p> <code>K_index</code> <code>dict</code> <p>Mapping of kinases to their respective psite data.</p> <code>K_array</code> <code>ndarray</code> <p>Array containing time-series data for kinase-psite combinations.</p> <code>gene_psite_counts</code> <code>list</code> <p>Number of kinases per gene-psite combination.</p> <code>beta_counts</code> <code>dict</code> <p>Mapping of kinase indices to the number of associated psites.</p> Source code in <code>kinopt/evol/objfn/minfndiffevo.py</code> <pre><code>class PhosphorylationOptimizationProblem(ElementwiseProblem):\n    \"\"\"\n    Custom optimization problem for phosphorylation analysis.\n\n    Defines the constraints, bounds, and objective function for optimizing\n    alpha and beta parameters across gene-psite-kinase relationships.\n\n    Attributes:\n        P_initial (dict): Mapping of gene-psite pairs to kinase relationships and time-series data.\n        P_initial_array (np.ndarray): Observed time-series data for gene-psite pairs.\n        K_index (dict): Mapping of kinases to their respective psite data.\n        K_array (np.ndarray): Array containing time-series data for kinase-psite combinations.\n        gene_psite_counts (list): Number of kinases per gene-psite combination.\n        beta_counts (dict): Mapping of kinase indices to the number of associated psites.\n    \"\"\"\n\n    def __init__(self, P_initial, P_initial_array, K_index, K_array, gene_psite_counts, beta_counts, **kwargs):\n        \"\"\"\n        Initializes the optimization problem with given data and constraints.\n\n        Args:\n            P_initial (dict): Mapping of gene-psite pairs to kinase relationships and time-series data.\n            P_initial_array (np.ndarray): Observed time-series data for gene-psite pairs.\n            K_index (dict): Mapping of kinases to their respective psite data.\n            K_array (np.ndarray): Array containing time-series data for kinase-psite combinations.\n            gene_psite_counts (list): Number of kinases per gene-psite combination.\n            beta_counts (dict): Mapping of kinase indices to the number of associated psites.\n        \"\"\"\n        self.P_initial = P_initial\n        self.P_initial_array = P_initial_array\n        self.K_index = K_index\n        self.K_array = K_array\n        self.gene_psite_counts = gene_psite_counts\n        self.beta_counts = beta_counts\n        self.num_alpha = sum(gene_psite_counts)\n        self.num_beta = sum(beta_counts.values())\n\n        # Define the problem with pymoo\n        super().__init__(\n            n_var=self.num_alpha + self.num_beta,\n            n_obj=1,  # Single objective (sum of squared residuals)\n            n_ieq_constr=self.num_alpha + len(beta_counts),  # Constraints for alpha and beta\n            xl=np.concatenate([(0,) * self.num_alpha, (lb,) * self.num_beta]),\n            xu=np.concatenate([(1,) * self.num_alpha, (ub,) * self.num_beta])\n        )\n\n    def _evaluate(self, x, out, *args, **kwargs):\n        \"\"\"\n        Evaluates the objective function and constraints for the given decision variables.\n\n        Args:\n            x (np.ndarray): Decision variable vector.\n            out (dict): Dictionary to store objective function value and constraint values.\n        \"\"\"\n        # Calculate the residuals for the objective function\n        error = self.objective_function(x)\n\n        # Initialize an empty list for constraints\n        constraints = []\n\n        # Constraints for alphas (sum to 1 for each gene-psite-kinase group)\n        alpha_start = 0\n        for count in self.gene_psite_counts:\n            constraints.append(np.sum(x[alpha_start:alpha_start + count]) - 1)\n            alpha_start += count\n\n        # Constraints for betas (sum to 1 for each kinase across its psites)\n        beta_start = self.num_alpha\n        for kinase, psites in self.K_index.items():\n            num_psites = len(psites)\n            constraints.append(np.sum(x[beta_start:beta_start + num_psites]) - 1)\n            beta_start += num_psites\n\n        # Ensure constraints list matches the expected length (self.n_ieq_constr)\n        # Pad constraints with zeros if fewer constraints are defined\n        constraints = np.array(constraints)\n        if constraints.shape[0] &lt; self.n_ieq_constr:\n            constraints = np.concatenate([constraints, np.zeros(self.n_ieq_constr - constraints.shape[0])])\n\n        # Output the objective and constraints, reshaping G to have shape (1, n_ieq_constr)\n        out[\"F\"] = error\n        out[\"G\"] = constraints.reshape(1, self.n_ieq_constr)\n\n    def objective_function(self, params):\n        \"\"\"\n        Computes the loss value for the given parameters using the selected loss type.\n\n        Args:\n            params (np.ndarray): Decision variables vector.\n\n        Returns:\n            float: Computed loss value.\n        \"\"\"\n        alpha, beta = {}, {}\n        alpha_start, beta_start = 0, self.num_alpha\n\n        # Extract alphas for each gene-psite-kinase combination\n        alpha = []\n        for count in self.gene_psite_counts:\n            alpha.append(params[alpha_start:alpha_start + count])\n            alpha_start += count\n\n        # Extract betas for each kinase-psite combination\n        for idx, count in self.beta_counts.items():\n            beta[idx] = params[beta_start:beta_start + count]\n            beta_start += count\n\n        # Calculate predicted matrix using alpha and beta values\n        i_max, t_max = self.P_initial_array.shape\n        P_i_t_matrix = np.zeros((i_max, t_max))\n\n        for i, ((gene, psite), data) in enumerate(self.P_initial.items()):\n            kinases = data['Kinases']\n            gene_psite_prediction = np.zeros(t_max, dtype=np.float64)\n\n            # Sum contributions of each kinase for the gene-psite\n            for j, kinase in enumerate(kinases):\n                kinase_psites = self.K_index.get(kinase)\n                if kinase_psites is None:\n                    continue\n\n                # Sum contributions across all psites of the kinase\n                for k_idx, (k_psite, k_time_series) in enumerate(kinase_psites):\n                    kinase_betas = beta[k_idx]\n                    gene_psite_prediction += alpha[i][j] * kinase_betas * k_time_series\n\n            P_i_t_matrix[i, :] = gene_psite_prediction\n\n        # Calculate residuals and sum of squared errors\n        residuals = self.P_initial_array - P_i_t_matrix\n\n        # Select the loss function based on global loss_type\n        if loss_type == \"base\":\n            # MSE\n            return np.sum((residuals) ** 2) / n\n        elif loss_type == \"base\" and include_regularization:\n            # MSE + L1 penalty (absolute values) + L2 penalty (squared values)\n            return np.sum((residuals) ** 2) / n + np.sum(np.abs(params)) + np.sum((params) ** 2)\n        elif loss_type == \"autocorrelation\":\n            # Autocorrelation Loss\n            return np.sum([np.corrcoef(residuals[i, :-1], residuals[i, 1:])[0, 1] ** 2 for i in range(i_max)])\n        elif loss_type == \"autocorrelation\" and include_regularization:\n            # Autocorrelation Loss + L1 penalty (absolute values) + L2 penalty (squared values)\n            return np.sum([np.corrcoef(residuals[i, :-1], residuals[i, 1:])[0, 1] ** 2 for i in range(i_max)]) + np.sum(\n                np.abs(params)) + np.sum((params) ** 2)\n        elif loss_type == \"huber\":\n            # Huber Loss\n            return np.mean(np.where(\n                np.abs(residuals) &lt;= 1.0,  # Delta (adjust as necessary)\n                0.5 * residuals ** 2,\n                1.0 * (np.abs(residuals) - 0.5 * 1.0)\n            ))\n        elif loss_type == \"huber\" and include_regularization:\n            # Huber Loss + L1 penalty (absolute values) + L2 penalty (squared values)\n            return np.mean(np.where(\n                np.abs(residuals) &lt;= 1.0,  # Delta (adjust as necessary)\n                0.5 * residuals ** 2,\n                1.0 * (np.abs(residuals) - 0.5 * 1.0)\n            )) + np.sum(np.abs(params)) + np.sum((params) ** 2)\n        elif loss_type == \"mape\":\n            # MAPE\n            return np.mean(np.abs(residuals / (self.P_initial_array + 1e-12))) * 100\n        elif loss_type == \"mape\" and include_regularization:\n            # MAPE + L1 penalty (absolute values) + L2 penalty (squared values)\n            return np.mean(np.abs(residuals / (self.P_initial_array + 1e-12))) * 100 + np.sum(np.abs(params)) + np.sum(\n                (params) ** 2)\n</code></pre>"},{"location":"reference/#kinopt.evol.objfn.minfndiffevo.PhosphorylationOptimizationProblem.__init__","title":"<code>__init__(P_initial, P_initial_array, K_index, K_array, gene_psite_counts, beta_counts, **kwargs)</code>","text":"<p>Initializes the optimization problem with given data and constraints.</p> <p>Parameters:</p> Name Type Description Default <code>P_initial</code> <code>dict</code> <p>Mapping of gene-psite pairs to kinase relationships and time-series data.</p> required <code>P_initial_array</code> <code>ndarray</code> <p>Observed time-series data for gene-psite pairs.</p> required <code>K_index</code> <code>dict</code> <p>Mapping of kinases to their respective psite data.</p> required <code>K_array</code> <code>ndarray</code> <p>Array containing time-series data for kinase-psite combinations.</p> required <code>gene_psite_counts</code> <code>list</code> <p>Number of kinases per gene-psite combination.</p> required <code>beta_counts</code> <code>dict</code> <p>Mapping of kinase indices to the number of associated psites.</p> required Source code in <code>kinopt/evol/objfn/minfndiffevo.py</code> <pre><code>def __init__(self, P_initial, P_initial_array, K_index, K_array, gene_psite_counts, beta_counts, **kwargs):\n    \"\"\"\n    Initializes the optimization problem with given data and constraints.\n\n    Args:\n        P_initial (dict): Mapping of gene-psite pairs to kinase relationships and time-series data.\n        P_initial_array (np.ndarray): Observed time-series data for gene-psite pairs.\n        K_index (dict): Mapping of kinases to their respective psite data.\n        K_array (np.ndarray): Array containing time-series data for kinase-psite combinations.\n        gene_psite_counts (list): Number of kinases per gene-psite combination.\n        beta_counts (dict): Mapping of kinase indices to the number of associated psites.\n    \"\"\"\n    self.P_initial = P_initial\n    self.P_initial_array = P_initial_array\n    self.K_index = K_index\n    self.K_array = K_array\n    self.gene_psite_counts = gene_psite_counts\n    self.beta_counts = beta_counts\n    self.num_alpha = sum(gene_psite_counts)\n    self.num_beta = sum(beta_counts.values())\n\n    # Define the problem with pymoo\n    super().__init__(\n        n_var=self.num_alpha + self.num_beta,\n        n_obj=1,  # Single objective (sum of squared residuals)\n        n_ieq_constr=self.num_alpha + len(beta_counts),  # Constraints for alpha and beta\n        xl=np.concatenate([(0,) * self.num_alpha, (lb,) * self.num_beta]),\n        xu=np.concatenate([(1,) * self.num_alpha, (ub,) * self.num_beta])\n    )\n</code></pre>"},{"location":"reference/#kinopt.evol.objfn.minfndiffevo.PhosphorylationOptimizationProblem.objective_function","title":"<code>objective_function(params)</code>","text":"<p>Computes the loss value for the given parameters using the selected loss type.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>ndarray</code> <p>Decision variables vector.</p> required <p>Returns:</p> Name Type Description <code>float</code> <p>Computed loss value.</p> Source code in <code>kinopt/evol/objfn/minfndiffevo.py</code> <pre><code>def objective_function(self, params):\n    \"\"\"\n    Computes the loss value for the given parameters using the selected loss type.\n\n    Args:\n        params (np.ndarray): Decision variables vector.\n\n    Returns:\n        float: Computed loss value.\n    \"\"\"\n    alpha, beta = {}, {}\n    alpha_start, beta_start = 0, self.num_alpha\n\n    # Extract alphas for each gene-psite-kinase combination\n    alpha = []\n    for count in self.gene_psite_counts:\n        alpha.append(params[alpha_start:alpha_start + count])\n        alpha_start += count\n\n    # Extract betas for each kinase-psite combination\n    for idx, count in self.beta_counts.items():\n        beta[idx] = params[beta_start:beta_start + count]\n        beta_start += count\n\n    # Calculate predicted matrix using alpha and beta values\n    i_max, t_max = self.P_initial_array.shape\n    P_i_t_matrix = np.zeros((i_max, t_max))\n\n    for i, ((gene, psite), data) in enumerate(self.P_initial.items()):\n        kinases = data['Kinases']\n        gene_psite_prediction = np.zeros(t_max, dtype=np.float64)\n\n        # Sum contributions of each kinase for the gene-psite\n        for j, kinase in enumerate(kinases):\n            kinase_psites = self.K_index.get(kinase)\n            if kinase_psites is None:\n                continue\n\n            # Sum contributions across all psites of the kinase\n            for k_idx, (k_psite, k_time_series) in enumerate(kinase_psites):\n                kinase_betas = beta[k_idx]\n                gene_psite_prediction += alpha[i][j] * kinase_betas * k_time_series\n\n        P_i_t_matrix[i, :] = gene_psite_prediction\n\n    # Calculate residuals and sum of squared errors\n    residuals = self.P_initial_array - P_i_t_matrix\n\n    # Select the loss function based on global loss_type\n    if loss_type == \"base\":\n        # MSE\n        return np.sum((residuals) ** 2) / n\n    elif loss_type == \"base\" and include_regularization:\n        # MSE + L1 penalty (absolute values) + L2 penalty (squared values)\n        return np.sum((residuals) ** 2) / n + np.sum(np.abs(params)) + np.sum((params) ** 2)\n    elif loss_type == \"autocorrelation\":\n        # Autocorrelation Loss\n        return np.sum([np.corrcoef(residuals[i, :-1], residuals[i, 1:])[0, 1] ** 2 for i in range(i_max)])\n    elif loss_type == \"autocorrelation\" and include_regularization:\n        # Autocorrelation Loss + L1 penalty (absolute values) + L2 penalty (squared values)\n        return np.sum([np.corrcoef(residuals[i, :-1], residuals[i, 1:])[0, 1] ** 2 for i in range(i_max)]) + np.sum(\n            np.abs(params)) + np.sum((params) ** 2)\n    elif loss_type == \"huber\":\n        # Huber Loss\n        return np.mean(np.where(\n            np.abs(residuals) &lt;= 1.0,  # Delta (adjust as necessary)\n            0.5 * residuals ** 2,\n            1.0 * (np.abs(residuals) - 0.5 * 1.0)\n        ))\n    elif loss_type == \"huber\" and include_regularization:\n        # Huber Loss + L1 penalty (absolute values) + L2 penalty (squared values)\n        return np.mean(np.where(\n            np.abs(residuals) &lt;= 1.0,  # Delta (adjust as necessary)\n            0.5 * residuals ** 2,\n            1.0 * (np.abs(residuals) - 0.5 * 1.0)\n        )) + np.sum(np.abs(params)) + np.sum((params) ** 2)\n    elif loss_type == \"mape\":\n        # MAPE\n        return np.mean(np.abs(residuals / (self.P_initial_array + 1e-12))) * 100\n    elif loss_type == \"mape\" and include_regularization:\n        # MAPE + L1 penalty (absolute values) + L2 penalty (squared values)\n        return np.mean(np.abs(residuals / (self.P_initial_array + 1e-12))) * 100 + np.sum(np.abs(params)) + np.sum(\n            (params) ** 2)\n</code></pre>"},{"location":"reference/#kinopt.evol.objfn.minfnnsgaii.PhosphorylationOptimizationProblem","title":"<code>PhosphorylationOptimizationProblem</code>","text":"<p>               Bases: <code>ElementwiseProblem</code></p> <p>Multi-objective optimization problem for phosphorylation analysis.</p> <p>Objectives: - Minimize sum of squared residuals (main objective). - Minimize violations of constraints for alpha (secondary objective). - Minimize violations of constraints for beta (tertiary objective).</p> Source code in <code>kinopt/evol/objfn/minfnnsgaii.py</code> <pre><code>class PhosphorylationOptimizationProblem(ElementwiseProblem):\n    \"\"\"\n    Multi-objective optimization problem for phosphorylation analysis.\n\n    Objectives:\n    - Minimize sum of squared residuals (main objective).\n    - Minimize violations of constraints for alpha (secondary objective).\n    - Minimize violations of constraints for beta (tertiary objective).\n    \"\"\"\n\n    def __init__(self, P_initial, P_initial_array, K_index, K_array, gene_psite_counts, beta_counts, **kwargs):\n        \"\"\"\n        Initializes the multi-objective optimization problem.\n\n        Args:\n            P_initial (dict): Mapping of gene-psite pairs to kinase relationships and time-series data.\n            P_initial_array (np.ndarray): Observed time-series data for gene-psite pairs.\n            K_index (dict): Mapping of kinases to their respective psite data.\n            K_array (np.ndarray): Array containing time-series data for kinase-psite combinations.\n            gene_psite_counts (list): Number of kinases per gene-psite combination.\n            beta_counts (dict): Mapping of kinase indices to the number of associated psites.\n        \"\"\"\n        self.P_initial = P_initial\n        self.P_initial_array = P_initial_array\n        self.K_index = K_index\n        self.K_array = K_array\n        self.gene_psite_counts = gene_psite_counts\n        self.beta_counts = beta_counts\n        self.num_alpha = sum(gene_psite_counts)\n        self.num_beta = sum(beta_counts.values())\n\n        # Define the problem with pymoo\n        super().__init__(\n            n_var=self.num_alpha + self.num_beta,\n            # Multi-objective: [residuals, alpha constraints, beta constraints]\n            n_obj=3,\n            # Constraints are part of the objectives\n            n_ieq_constr=0,\n            xl=np.concatenate([(0,) * self.num_alpha, (lb,) * self.num_beta]),\n            xu=np.concatenate([(1,) * self.num_alpha, (ub,) * self.num_beta])\n        )\n\n    def _evaluate(self, x, out, *args, **kwargs):\n        \"\"\"\n        Evaluates the objectives for the given decision variables.\n\n        Args:\n            x (np.ndarray): Decision variable vector.\n            out (dict): Dictionary to store objective function values.\n        \"\"\"\n        # Primary objective: sum of squared residuals\n        error = self.objective_function(x)\n\n        # Secondary objective: alpha constraint violations\n        alpha_violations = 0\n        alpha_start = 0\n        for count in self.gene_psite_counts:\n            alpha_sum = np.sum(x[alpha_start:alpha_start + count])\n            alpha_violations += max(0, abs(alpha_sum - 1))\n            alpha_start += count\n\n        # Tertiary objective: beta constraint violations\n        beta_violations = 0\n        beta_start = self.num_alpha\n        for kinase, psites in self.K_index.items():\n            num_psites = len(psites)\n            beta_sum = np.sum(x[beta_start:beta_start + num_psites])\n            beta_violations += max(0, abs(beta_sum - 1))\n            beta_start += num_psites\n\n        # Set objectives\n        out[\"F\"] = [error, alpha_violations, beta_violations]\n\n    def objective_function(self, params):\n        \"\"\"\n        Computes the loss value for the given parameters using the selected loss type.\n\n        Args:\n            params (np.ndarray): Decision variables vector.\n\n        Returns:\n            float: Computed loss value.\n        \"\"\"\n        alpha, beta = {}, {}\n        alpha_start, beta_start = 0, self.num_alpha\n\n        # Extract alphas for each gene-psite-kinase combination\n        alpha = []\n        for count in self.gene_psite_counts:\n            alpha.append(params[alpha_start:alpha_start + count])\n            alpha_start += count\n\n        # Extract betas for each kinase-psite combination\n        for idx, count in self.beta_counts.items():\n            beta[idx] = params[beta_start:beta_start + count]\n            beta_start += count\n\n        # Calculate predicted matrix using alpha and beta values\n        i_max, t_max = self.P_initial_array.shape\n        P_i_t_matrix = np.zeros((i_max, t_max))\n\n        for i, ((gene, psite), data) in enumerate(self.P_initial.items()):\n            kinases = data['Kinases']\n            gene_psite_prediction = np.zeros(t_max, dtype=np.float64)\n\n            # Sum contributions of each kinase for the gene-psite\n            for j, kinase in enumerate(kinases):\n                kinase_psites = self.K_index.get(kinase)\n                if kinase_psites is None:\n                    continue\n\n                # Sum contributions across all psites of the kinase\n                for k_idx, (k_psite, k_time_series) in enumerate(kinase_psites):\n                    kinase_betas = beta[k_idx]\n                    gene_psite_prediction += alpha[i][j] * kinase_betas * k_time_series\n\n            P_i_t_matrix[i, :] = gene_psite_prediction\n\n        # Calculate residuals and sum of squared errors\n        residuals = self.P_initial_array - P_i_t_matrix\n\n        # Select the loss function based on global loss_type\n        if loss_type == \"base\":\n            # MSE\n            return np.sum((residuals) ** 2) / n\n        elif loss_type == \"base\" and include_regularization:\n            # MSE + L1 penalty (absolute values) + L2 penalty (squared values)\n            return np.sum((residuals) ** 2) / n + np.sum(np.abs(params)) + np.sum((params) ** 2)\n        elif loss_type == \"autocorrelation\":\n            # Autocorrelation Loss\n            return np.sum([np.corrcoef(residuals[i, :-1], residuals[i, 1:])[0, 1] ** 2 for i in range(i_max)])\n        elif loss_type == \"autocorrelation\" and include_regularization:\n            # Autocorrelation Loss + L1 penalty (absolute values) + L2 penalty (squared values)\n            return np.sum([np.corrcoef(residuals[i, :-1], residuals[i, 1:])[0, 1] ** 2 for i in range(i_max)]) + np.sum(\n                np.abs(params)) + np.sum((params) ** 2)\n        elif loss_type == \"huber\":\n            # Huber Loss\n            return np.mean(np.where(\n                np.abs(residuals) &lt;= 1.0,  # Delta (adjust as necessary)\n                0.5 * residuals ** 2,\n                1.0 * (np.abs(residuals) - 0.5 * 1.0)\n            ))\n        elif loss_type == \"huber\" and include_regularization:\n            # Huber Loss + L1 penalty (absolute values) + L2 penalty (squared values)\n            return np.mean(np.where(\n                np.abs(residuals) &lt;= 1.0,  # Delta (adjust as necessary)\n                0.5 * residuals ** 2,\n                1.0 * (np.abs(residuals) - 0.5 * 1.0)\n            )) + np.sum(np.abs(params)) + np.sum((params) ** 2)\n        elif loss_type == \"mape\":\n            # MAPE\n            return np.mean(np.abs(residuals / (self.P_initial_array + 1e-12))) * 100\n        elif loss_type == \"mape\" and include_regularization:\n            # MAPE + L1 penalty (absolute values) + L2 penalty (squared values)\n            return np.mean(np.abs(residuals / (self.P_initial_array + 1e-12))) * 100 + np.sum(np.abs(params)) + np.sum(\n                (params) ** 2)\n</code></pre>"},{"location":"reference/#kinopt.evol.objfn.minfnnsgaii.PhosphorylationOptimizationProblem.__init__","title":"<code>__init__(P_initial, P_initial_array, K_index, K_array, gene_psite_counts, beta_counts, **kwargs)</code>","text":"<p>Initializes the multi-objective optimization problem.</p> <p>Parameters:</p> Name Type Description Default <code>P_initial</code> <code>dict</code> <p>Mapping of gene-psite pairs to kinase relationships and time-series data.</p> required <code>P_initial_array</code> <code>ndarray</code> <p>Observed time-series data for gene-psite pairs.</p> required <code>K_index</code> <code>dict</code> <p>Mapping of kinases to their respective psite data.</p> required <code>K_array</code> <code>ndarray</code> <p>Array containing time-series data for kinase-psite combinations.</p> required <code>gene_psite_counts</code> <code>list</code> <p>Number of kinases per gene-psite combination.</p> required <code>beta_counts</code> <code>dict</code> <p>Mapping of kinase indices to the number of associated psites.</p> required Source code in <code>kinopt/evol/objfn/minfnnsgaii.py</code> <pre><code>def __init__(self, P_initial, P_initial_array, K_index, K_array, gene_psite_counts, beta_counts, **kwargs):\n    \"\"\"\n    Initializes the multi-objective optimization problem.\n\n    Args:\n        P_initial (dict): Mapping of gene-psite pairs to kinase relationships and time-series data.\n        P_initial_array (np.ndarray): Observed time-series data for gene-psite pairs.\n        K_index (dict): Mapping of kinases to their respective psite data.\n        K_array (np.ndarray): Array containing time-series data for kinase-psite combinations.\n        gene_psite_counts (list): Number of kinases per gene-psite combination.\n        beta_counts (dict): Mapping of kinase indices to the number of associated psites.\n    \"\"\"\n    self.P_initial = P_initial\n    self.P_initial_array = P_initial_array\n    self.K_index = K_index\n    self.K_array = K_array\n    self.gene_psite_counts = gene_psite_counts\n    self.beta_counts = beta_counts\n    self.num_alpha = sum(gene_psite_counts)\n    self.num_beta = sum(beta_counts.values())\n\n    # Define the problem with pymoo\n    super().__init__(\n        n_var=self.num_alpha + self.num_beta,\n        # Multi-objective: [residuals, alpha constraints, beta constraints]\n        n_obj=3,\n        # Constraints are part of the objectives\n        n_ieq_constr=0,\n        xl=np.concatenate([(0,) * self.num_alpha, (lb,) * self.num_beta]),\n        xu=np.concatenate([(1,) * self.num_alpha, (ub,) * self.num_beta])\n    )\n</code></pre>"},{"location":"reference/#kinopt.evol.objfn.minfnnsgaii.PhosphorylationOptimizationProblem.objective_function","title":"<code>objective_function(params)</code>","text":"<p>Computes the loss value for the given parameters using the selected loss type.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>ndarray</code> <p>Decision variables vector.</p> required <p>Returns:</p> Name Type Description <code>float</code> <p>Computed loss value.</p> Source code in <code>kinopt/evol/objfn/minfnnsgaii.py</code> <pre><code>def objective_function(self, params):\n    \"\"\"\n    Computes the loss value for the given parameters using the selected loss type.\n\n    Args:\n        params (np.ndarray): Decision variables vector.\n\n    Returns:\n        float: Computed loss value.\n    \"\"\"\n    alpha, beta = {}, {}\n    alpha_start, beta_start = 0, self.num_alpha\n\n    # Extract alphas for each gene-psite-kinase combination\n    alpha = []\n    for count in self.gene_psite_counts:\n        alpha.append(params[alpha_start:alpha_start + count])\n        alpha_start += count\n\n    # Extract betas for each kinase-psite combination\n    for idx, count in self.beta_counts.items():\n        beta[idx] = params[beta_start:beta_start + count]\n        beta_start += count\n\n    # Calculate predicted matrix using alpha and beta values\n    i_max, t_max = self.P_initial_array.shape\n    P_i_t_matrix = np.zeros((i_max, t_max))\n\n    for i, ((gene, psite), data) in enumerate(self.P_initial.items()):\n        kinases = data['Kinases']\n        gene_psite_prediction = np.zeros(t_max, dtype=np.float64)\n\n        # Sum contributions of each kinase for the gene-psite\n        for j, kinase in enumerate(kinases):\n            kinase_psites = self.K_index.get(kinase)\n            if kinase_psites is None:\n                continue\n\n            # Sum contributions across all psites of the kinase\n            for k_idx, (k_psite, k_time_series) in enumerate(kinase_psites):\n                kinase_betas = beta[k_idx]\n                gene_psite_prediction += alpha[i][j] * kinase_betas * k_time_series\n\n        P_i_t_matrix[i, :] = gene_psite_prediction\n\n    # Calculate residuals and sum of squared errors\n    residuals = self.P_initial_array - P_i_t_matrix\n\n    # Select the loss function based on global loss_type\n    if loss_type == \"base\":\n        # MSE\n        return np.sum((residuals) ** 2) / n\n    elif loss_type == \"base\" and include_regularization:\n        # MSE + L1 penalty (absolute values) + L2 penalty (squared values)\n        return np.sum((residuals) ** 2) / n + np.sum(np.abs(params)) + np.sum((params) ** 2)\n    elif loss_type == \"autocorrelation\":\n        # Autocorrelation Loss\n        return np.sum([np.corrcoef(residuals[i, :-1], residuals[i, 1:])[0, 1] ** 2 for i in range(i_max)])\n    elif loss_type == \"autocorrelation\" and include_regularization:\n        # Autocorrelation Loss + L1 penalty (absolute values) + L2 penalty (squared values)\n        return np.sum([np.corrcoef(residuals[i, :-1], residuals[i, 1:])[0, 1] ** 2 for i in range(i_max)]) + np.sum(\n            np.abs(params)) + np.sum((params) ** 2)\n    elif loss_type == \"huber\":\n        # Huber Loss\n        return np.mean(np.where(\n            np.abs(residuals) &lt;= 1.0,  # Delta (adjust as necessary)\n            0.5 * residuals ** 2,\n            1.0 * (np.abs(residuals) - 0.5 * 1.0)\n        ))\n    elif loss_type == \"huber\" and include_regularization:\n        # Huber Loss + L1 penalty (absolute values) + L2 penalty (squared values)\n        return np.mean(np.where(\n            np.abs(residuals) &lt;= 1.0,  # Delta (adjust as necessary)\n            0.5 * residuals ** 2,\n            1.0 * (np.abs(residuals) - 0.5 * 1.0)\n        )) + np.sum(np.abs(params)) + np.sum((params) ** 2)\n    elif loss_type == \"mape\":\n        # MAPE\n        return np.mean(np.abs(residuals / (self.P_initial_array + 1e-12))) * 100\n    elif loss_type == \"mape\" and include_regularization:\n        # MAPE + L1 penalty (absolute values) + L2 penalty (squared values)\n        return np.mean(np.abs(residuals / (self.P_initial_array + 1e-12))) * 100 + np.sum(np.abs(params)) + np.sum(\n            (params) ** 2)\n</code></pre>"},{"location":"reference/#kinopt.evol.opt.optrun.post_optimization_de","title":"<code>post_optimization_de(result, alpha_values, beta_values)</code>","text":"<p>Post-processes the result of a multi-objective optimization run. 1) Extracts the Pareto front and computes a weighted score to pick a 'best' solution. 2) Gathers metrics like Hypervolume (HV) and IGD+ over the optimization history. 3) Logs feasibility generation info, saves waterfall and convergence data to CSV.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <p>The final result object from the optimizer (e.g., a pymoo result).</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary with keys: 'best_solution': The best individual from the weighted scoring. 'best_objectives': Its corresponding objective vector. 'optimized_params': The individual's decision variables (X). 'scores': Weighted scores for each solution in the Pareto front. 'best_index': The index of the best solution according to weighted score. 'hist_hv': The hypervolume per generation. 'hist_igd': The IGD+ per generation. 'convergence_df': The DataFrame with iteration vs. best objective value     for each iteration in the result history.</p> Source code in <code>kinopt/evol/opt/optrun.py</code> <pre><code>def post_optimization_de(\n    result,\n    alpha_values,\n    beta_values):\n    \"\"\"\n    Post-processes the result of a multi-objective optimization run.\n    1) Extracts the Pareto front and computes a weighted score to pick a 'best' solution.\n    2) Gathers metrics like Hypervolume (HV) and IGD+ over the optimization history.\n    3) Logs feasibility generation info, saves waterfall and convergence data to CSV.\n\n    Args:\n        result: The final result object from the optimizer (e.g., a pymoo result).\n\n    Returns:\n        dict: A dictionary with keys:\n            'best_solution': The best individual from the weighted scoring.\n            'best_objectives': Its corresponding objective vector.\n            'optimized_params': The individual's decision variables (X).\n            'scores': Weighted scores for each solution in the Pareto front.\n            'best_index': The index of the best solution according to weighted score.\n            'hist_hv': The hypervolume per generation.\n            'hist_igd': The IGD+ per generation.\n            'convergence_df': The DataFrame with iteration vs. best objective value\n                for each iteration in the result history.\n    \"\"\"\n    # # Display key results\n    # print(\"Optimization Results:\\n\")\n    # print(\"Objective Value (F):\", result.F)  # Best objective value\n    # print(\"Best Solution Variables (X):\", result.X)  # Best solution variables\n    # print(\"Constraint Violations (G):\", result.G)  # Constraint violations\n    # print(\"Constraint Violation Summary (CV):\", result.CV)  # Summary of constraint violations\n    # # Additional attributes\n    # print(\"\\nAdditional Information:\")\n    # print(\"Algorithm:\", result.algorithm)\n    # print(\"Archive:\", result.archive)\n    # print(\"Feasibility (feas):\", result.feas)\n    # # Display details about the population with more attributes for each individual\n    # print(\"\\nFirst 5 Population Details:\")\n    # for i, individual in enumerate(result.pop[:5]):  # Displaying first 5 individuals for brevity\n    #     print(f\"\\nIndividual {i + 1}:\")\n    #     print(\"  Decision Variables (X):\", individual.X)\n    #     print(\"  Objective Value (F):\", individual.F)\n    #     print(\"  Constraint Violation (CV):\", individual.CV if hasattr(individual, 'CV') else \"N/A\")\n    #     print(\"  Feasibility (feas):\", individual.feas if hasattr(individual, 'feas') else \"N/A\")\n    # Combined alpha and beta labels with Greek symbols\n    param_labels = []\n    # Add alpha (\u03b1) labels\n    for (gene, psite), kinases in alpha_values.items():\n        for kinase in kinases.keys():\n            param_labels.append(f\"\u03b1_{gene}_{psite}_{kinase}\")\n    # Add beta (\u03b2) labels\n    for (kinase, psite), _ in beta_values.items():\n        param_labels.append(f\"\u03b2_{kinase}_{psite}\")\n    # Initialize an empty list to store individual data\n    pops = []\n    # Loop through the first 5 individuals and extract data\n    for i, individual in enumerate(result.pop):  # Displaying first 5 individuals for brevity\n        row = {\"Individual\": i + 1, \"Objective Value (F)\": individual.F[0]}  # Add individual info\n        row.update({param_labels[j]: x for j, x in enumerate(individual.X)})  # Add decision variables\n        pops.append(row)\n    # Create a DataFrame from the collected data\n    waterfall_df = pd.DataFrame(pops)\n    waterfall_df.to_csv(f'{OUT_DIR}/parameter_scan.csv', index=False)\n    # Visualize the convergence\n    val = [e.opt.get(\"F\")[0] for e in result.history]\n    # Flatten the list or extract the first element of each value\n    flattened_val = [v[0] if isinstance(v, (list, np.ndarray)) else v for v in val]\n    # Correctly construct the DataFrame\n    convergence_df = pd.DataFrame({\n        \"Iteration\": np.arange(len(flattened_val)),\n        \"Value\": flattened_val\n    })\n    # Save the DataFrame to a CSV file\n    convergence_df.to_csv(f'{OUT_DIR}/convergence.csv', index=False)\n    ordered_optimizer_runs = waterfall_df.sort_values(by=\"Objective Value (F)\", ascending=True)\n    objective_values = ordered_optimizer_runs[\"Objective Value (F)\"].values\n    # Dynamically determine the threshold based on the range of objective values\n    threshold = 0.05 * (objective_values.max() - objective_values.min())\n    # Determine indices to plot\n    indices_to_plot = [0]  # Always plot the first point\n    for i in range(1, len(objective_values)):\n        if abs(objective_values[i] - objective_values[i - 1]) &gt; threshold:  # Significant change\n            indices_to_plot.append(i)\n        elif i % 10 == 0:  # Plot sparsely for small changes\n            indices_to_plot.append(i)\n    # Plot only the selected indices\n    x_values = indices_to_plot\n    y_values = [objective_values[i] for i in indices_to_plot]\n    # Melt the DataFrame to make it long-form for easy plotting\n    long_df = waterfall_df.melt(id_vars=[\"Individual\", \"Objective Value (F)\"],\n                                value_vars=param_labels,\n                                var_name=\"Parameter\",\n                                value_name=\"Parameter Value\")\n    # Add a column to classify parameters as '\u03b1' or '\u03b2'\n    long_df[\"Type\"] = long_df[\"Parameter\"].apply(\n        lambda x: \"\u03b1\" if x.startswith(\"\u03b1\") else (\"\u03b2\" if x.startswith(\"\u03b2\") else \"Other\"))\n    # Sort the DataFrame by \"Parameter Value\"\n    long_df = long_df.sort_values(by=\"Objective Value (F)\")\n\n    return (\n        ordered_optimizer_runs,\n        convergence_df,\n        long_df,\n        x_values,\n        y_values,\n        val\n    )\n</code></pre>"},{"location":"reference/#kinopt.evol.opt.optrun.post_optimization_nsga","title":"<code>post_optimization_nsga(result, weights=np.array([1.0, 1.0, 1.0]), ref_point=np.array([3, 1, 1]))</code>","text":"<p>Post-processes the result of a multi-objective optimization run. 1) Extracts the Pareto front and computes a weighted score to pick a 'best' solution. 2) Gathers metrics like Hypervolume (HV) and IGD+ over the optimization history. 3) Logs feasibility generation info, saves waterfall and convergence data to CSV.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <p>The final result object from the optimizer (e.g., a pymoo result).</p> required <code>weights</code> <code>ndarray</code> <p>Array of length 3 for weighting the objectives.</p> <code>array([1.0, 1.0, 1.0])</code> <code>ref_point</code> <code>ndarray</code> <p>Reference point for hypervolume computations.</p> <code>array([3, 1, 1])</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary with keys: 'best_solution': The best individual from the weighted scoring. 'best_objectives': Its corresponding objective vector. 'optimized_params': The individual's decision variables (X). 'scores': Weighted scores for each solution in the Pareto front. 'best_index': The index of the best solution according to weighted score. 'hist_hv': The hypervolume per generation. 'hist_igd': The IGD+ per generation. 'convergence_df': The DataFrame with iteration vs. best objective value     for each iteration in the result history.</p> Source code in <code>kinopt/evol/opt/optrun.py</code> <pre><code>def post_optimization_nsga(\n    result,\n    weights=np.array([1.0, 1.0, 1.0]),\n    ref_point=np.array([3, 1, 1])):\n    \"\"\"\n    Post-processes the result of a multi-objective optimization run.\n    1) Extracts the Pareto front and computes a weighted score to pick a 'best' solution.\n    2) Gathers metrics like Hypervolume (HV) and IGD+ over the optimization history.\n    3) Logs feasibility generation info, saves waterfall and convergence data to CSV.\n\n    Args:\n        result: The final result object from the optimizer (e.g., a pymoo result).\n        weights (np.ndarray): Array of length 3 for weighting the objectives.\n        ref_point (np.ndarray): Reference point for hypervolume computations.\n\n    Returns:\n        dict: A dictionary with keys:\n            'best_solution': The best individual from the weighted scoring.\n            'best_objectives': Its corresponding objective vector.\n            'optimized_params': The individual's decision variables (X).\n            'scores': Weighted scores for each solution in the Pareto front.\n            'best_index': The index of the best solution according to weighted score.\n            'hist_hv': The hypervolume per generation.\n            'hist_igd': The IGD+ per generation.\n            'convergence_df': The DataFrame with iteration vs. best objective value\n                for each iteration in the result history.\n    \"\"\"\n    # 1) Extract the Pareto front from the final population\n    pareto_front = np.array([ind.F for ind in result.pop])\n\n    # Weighted scoring for picking a single 'best' solution from Pareto\n    scores = pareto_front[:, 0] + weights[1]*np.abs(pareto_front[:, 1]) + weights[2]*np.abs(pareto_front[:, 2])\n    best_index = np.argmin(scores)\n    best_solution = result.pop[best_index]\n    best_objectives = pareto_front[best_index]\n    optimized_params = best_solution.X\n\n    # Additional references from the result\n    F = result.F  # The entire final objective set\n    pairs = [(0,1),(0,2),(1,2)]\n    approx_ideal = F.min(axis=0)\n    approx_nadir = F.max(axis=0)\n\n    # Decomposition objects\n    decomp = ASF()\n    asf_i = decomp.do(F, 1/weights).argmin()\n\n    hist = result.history  # the full history of the optimization\n\n    n_evals = []\n    hist_F = []\n    hist_cv = []\n    hist_cv_avg = []\n\n    # 2) Gather feasibility, objective space data over each generation\n    for algo in hist:\n        n_evals.append(algo.evaluator.n_eval)\n\n        opt = algo.opt\n        hist_cv.append(opt.get(\"CV\").min())\n        hist_cv_avg.append(algo.pop.get(\"CV\").mean())\n\n        feas = np.where(opt.get(\"feasible\"))[0]\n        hist_F.append(opt.get(\"F\")[feas])\n\n    # Identify when we first got a feasible solution\n    k = np.where(np.array(hist_cv) &lt;= 0.0)[0].min()\n    logger.info(f\"At least one feasible solution in Generation {k} after {n_evals[k]} evaluations.\")\n\n    # Identify when the whole population became feasible\n    vals = hist_cv_avg\n    k = np.where(np.array(vals) &lt;= 0.0)[0].min()\n    logger.info(f\"Whole population feasible in Generation {k} after {n_evals[k]} evaluations.\")\n\n    # 3) Metrics: Hypervolume &amp; IGD+ across generations\n    metric_hv = Hypervolume(\n        ref_point=ref_point,\n        norm_ref_point=False,\n        zero_to_one=True,\n        ideal=approx_ideal,\n        nadir=approx_nadir\n    )\n    hist_hv = [metric_hv.do(_F) for _F in hist_F]\n\n    metric_igd = IGDPlus(F)\n    hist_igd = [metric_igd.do(_F) for _F in hist_F]\n\n    # 4) Waterfall or 'pops' data (currently empty in snippet)\n    pops = []\n    # You could populate 'pops' with relevant info from each generation if desired\n    for i, individual in enumerate(result.pop):  # Displaying first 5 individuals for brevity\n        row = {\"Individual\": i + 1, \"Objective Value (F)\": individual.F[0]}  # Add individual info\n        row.update({f\"\u03b1_{j}\": x for j, x in enumerate(individual.X)})  # Add decision variables\n        pops.append(row)\n\n\n    waterfall_df = pd.DataFrame(pops)\n    waterfall_df.to_csv(f'{OUT_DIR}/parameter_scan.csv', index=False)\n\n    # 5) Convergence data (best objective value each generation)\n    val = [e.opt.get(\"F\")[0] for e in hist]  # each iteration's best F\n    # Flatten if it is list or array\n    flattened_val = [\n        v[0] if isinstance(v, (list, np.ndarray)) else v\n        for v in val\n    ]\n    convergence_df = pd.DataFrame({\n        \"Iteration\": np.arange(len(flattened_val)),\n        \"Value\": flattened_val\n    })\n    convergence_df.to_csv(f'{OUT_DIR}/convergence.csv', index=False)\n\n    # Display the selected solution and objectives\n    logger.info(\"--- Best Solution ---\")\n    logger.info(f\"Objective Values (F): {best_objectives}\")\n\n    return (\n        F,\n        pairs,\n        n_evals,\n        hist_cv,\n        hist_cv_avg,\n        k,\n        metric_igd,\n        metric_hv,\n        best_solution,\n        best_objectives,\n        optimized_params,\n        approx_nadir,\n        approx_ideal,\n        scores,\n        best_index,\n        hist,\n        hist_hv,\n        hist_igd,\n        convergence_df,\n        waterfall_df,\n        asf_i,\n        PseudoWeights(weights).do(F),\n        pairs,\n        val\n    )\n</code></pre>"},{"location":"reference/#kinopt.evol.opt.optrun.run_optimization","title":"<code>run_optimization(P_initial, P_initial_array, K_index, K_array, gene_psite_counts, beta_counts, PhosphorylationOptimizationProblem)</code>","text":"<p>Sets up and runs the multi-objective optimization problem for phosphorylation using an NSGA2 algorithm and a thread pool for parallelization.</p> <p>Parameters:</p> Name Type Description Default <code>P_initial,</code> <code>(P_initial_array, K_index, K_array, gene_psite_counts, beta_counts)</code> <p>Data structures describing the problem (time-series data, kinases, etc.).</p> required <code>PhosphorylationOptimizationProblem</code> <code>class</code> <p>The custom problem class to be instantiated.</p> required <p>Returns:</p> Name Type Description <code>result</code> <p>The pymoo result object containing the optimized population and history.</p> <code>exec_time</code> <p>Execution time for the optimization.</p> Source code in <code>kinopt/evol/opt/optrun.py</code> <pre><code>def run_optimization(\n    P_initial,\n    P_initial_array,\n    K_index,\n    K_array,\n    gene_psite_counts,\n    beta_counts,\n    PhosphorylationOptimizationProblem\n):\n    \"\"\"\n    Sets up and runs the multi-objective optimization problem for phosphorylation\n    using an NSGA2 algorithm and a thread pool for parallelization.\n\n    Args:\n        P_initial, P_initial_array, K_index, K_array, gene_psite_counts, beta_counts:\n            Data structures describing the problem (time-series data, kinases, etc.).\n        PhosphorylationOptimizationProblem (class):\n            The custom problem class to be instantiated.\n\n    Returns:\n        result: The pymoo result object containing the optimized population and history.\n        exec_time: Execution time for the optimization.\n    \"\"\"\n    # 1) Determine the number of threads via lscpu\n    n_threads_cmd = \"lscpu -p | grep -v '^#' | wc -l\"\n    n_threads = int(subprocess.check_output(n_threads_cmd, shell=True).decode().strip())\n    logger.info(f\"Number of threads: {n_threads}\")\n\n    # 2) Create a thread pool and a parallelization runner\n    pool = ThreadPool(n_threads)\n    runner = StarmapParallelization(pool.starmap)\n\n    # 3) Instantiate the problem\n    problem = PhosphorylationOptimizationProblem(\n        P_initial=P_initial,\n        P_initial_array=P_initial_array,\n        K_index=K_index,\n        K_array=K_array,\n        gene_psite_counts=gene_psite_counts,\n        beta_counts=beta_counts,\n        elementwise_runner=runner\n    )\n    if METHOD == \"DE\":\n        # 4) Set up the algorithm and termination criteria\n        # for single-objective optimization\n        algorithm = DE(\n            pop_size=500,\n            sampling=LHS(),\n            variant=\"DE/rand/1/bin\",\n            CR=0.9,\n            dither=\"vector\",\n            jitter=False\n        )\n        termination = DefaultSingleObjectiveTermination(\n            # xtol=1e-8,\n            # cvtol=1e-6,\n            # ftol=1e-6,\n            # period=20,\n            # n_max_gen=1000,\n            # n_max_evals=100000\n        )\n    else:\n        # 4) Set up the algorithm and termination criteria\n        # for multi-objective optimization\n        algorithm = NSGA2(\n            pop_size=500,\n            crossover=TwoPointCrossover(),\n            eliminate_duplicates=True\n        )\n        termination = DefaultMultiObjectiveTermination(\n            # xtol=1e-8,\n            # cvtol=1e-6,\n            # ftol=0.0025,\n            # n_max_gen=1000,\n            # n_max_evals=100000\n        )\n\n    # 5) Run the optimization\n    # buf = io.StringIO()\n    # with contextlib.redirect_stdout(buf):\n    result = minimize(\n        problem,\n        algorithm,\n        termination=termination,\n        verbose=True,\n        save_history=True\n    )\n\n    # # Log the captured pymoo progress\n    # pymoo_progress = buf.getvalue()\n    # if pymoo_progress.strip():  # only log if there's actual text\n    #     logger.info(\"--- Progress Output ---\\n\" + pymoo_progress)\n\n    # 6) Grab execution time and close the pool\n    # Convert execution time to minutes and hours\n    exec_time_seconds = result.exec_time\n    exec_time_minutes = exec_time_seconds / 60\n    exec_time_hours = exec_time_seconds / 3600\n    logger.info(f\"Execution Time: {exec_time_seconds:.2f} seconds |  \"\n                f\"{exec_time_minutes:.2f} minutes |  \"\n                f\"{exec_time_hours:.2f} hours\")\n    pool.close()\n\n    return problem, result\n</code></pre>"},{"location":"reference/#kinopt.evol.optcon.construct.pipeline","title":"<code>pipeline(input1_path, input2_path, time_series_columns, scaling_method, split_point, segment_points, estimate_missing_kinases, kinase_to_psites)</code>","text":"<p>Constructs the pipeline for the optimization process. This function orchestrates the loading of data, scaling, and the construction of the P_initial and K_array structures. It returns the necessary data structures for the optimization process. The function takes the following parameters:</p> <p>:param input1_path: Path to the first CSV file (HGNC data) :param input2_path: Path to the second CSV file (kinase interactions) :param time_series_columns: List of time series columns to extract :param scaling_method: Method for scaling the data :param split_point: Split point for scaling :param segment_points: Segment points for scaling :param estimate_missing_kinases: Boolean flag for estimating missing kinases :param kinase_to_psites: Dictionary mapping kinases to their respective psites</p> <p>:return: Tuple containing:     - full_hgnc_df (pd.DataFrame): The scaled data from input1     - interaction_df (pd.DataFrame): The subset/merged DataFrame from input2     - observed (pd.DataFrame): Subset of full_hgnc_df merged with interaction_df     - P_initial (dict): Initial mapping of gene-psite pairs to kinase relationships and time-series data     - P_initial_array (np.ndarray): Array containing observed time-series data for gene-psite pairs     - K_index (dict): Mapping of kinases to their respective psite data     - K_array (np.ndarray): Array containing time-series data for kinase-psite combinations     - beta_counts (dict): Mapping of kinase indices to the number of associated psites     - gene_psite_counts (list): Number of kinases per gene-psite combination     - n (int): Number of decision variables in the optimization problem</p> Source code in <code>kinopt/evol/optcon/construct.py</code> <pre><code>def pipeline(\n    input1_path: str,\n    input2_path: str,\n    time_series_columns: list[str],\n    scaling_method: str,\n    split_point: float,\n    segment_points: list[float],\n    estimate_missing_kinases: bool,\n    kinase_to_psites: dict[str, int]\n):\n    \"\"\"\n    Constructs the pipeline for the optimization process.\n    This function orchestrates the loading of data, scaling,\n    and the construction of the P_initial and K_array structures.\n    It returns the necessary data structures for the optimization process.\n    The function takes the following parameters:\n\n    :param input1_path: Path to the first CSV file (HGNC data)\n    :param input2_path: Path to the second CSV file (kinase interactions)\n    :param time_series_columns: List of time series columns to extract\n    :param scaling_method: Method for scaling the data\n    :param split_point: Split point for scaling\n    :param segment_points: Segment points for scaling\n    :param estimate_missing_kinases: Boolean flag for estimating missing kinases\n    :param kinase_to_psites: Dictionary mapping kinases to their respective psites\n\n    :return: Tuple containing:\n        - full_hgnc_df (pd.DataFrame): The scaled data from input1\n        - interaction_df (pd.DataFrame): The subset/merged DataFrame from input2\n        - observed (pd.DataFrame): Subset of full_hgnc_df merged with interaction_df\n        - P_initial (dict): Initial mapping of gene-psite pairs to kinase relationships and time-series data\n        - P_initial_array (np.ndarray): Array containing observed time-series data for gene-psite pairs\n        - K_index (dict): Mapping of kinases to their respective psite data\n        - K_array (np.ndarray): Array containing time-series data for kinase-psite combinations\n        - beta_counts (dict): Mapping of kinase indices to the number of associated psites\n        - gene_psite_counts (list): Number of kinases per gene-psite combination\n        - n (int): Number of decision variables in the optimization problem\n    \"\"\"\n    # 1) Load and scale\n    full_hgnc_df, interaction_df, observed = _load_and_scale_data(\n        input1_path=input1_path,\n        input2_path=input2_path,\n        time_series_columns=time_series_columns,\n        scaling_method=scaling_method,\n        split_point=split_point,\n        segment_points=segment_points,\n        estimate_missing_kinases=estimate_missing_kinases\n    )\n\n    # 2) Build P_initial\n    P_initial, P_initial_array = _build_p_initial(\n        interaction_df, full_hgnc_df, time_series_columns\n    )\n    n = P_initial_array.size\n\n    # 3) Build K_array\n    K_array, K_index, beta_counts = _build_k_array(\n        interaction_df=interaction_df,\n        full_hgnc_df=full_hgnc_df,\n        time=time_series_columns,\n        estimate_missing_kinases=estimate_missing_kinases,\n        kinase_to_psites=kinase_to_psites\n    )\n\n    # 4) gene_psite_counts for alpha parameters\n    gene_psite_counts = [len(data['Kinases']) for data in P_initial.values()]\n\n    return (\n        full_hgnc_df,         # pd.DataFrame\n        interaction_df,       # pd.DataFrame\n        observed,             # pd.DataFrame\n        P_initial,            # dict\n        P_initial_array,      # np.ndarray\n        K_array,              # np.ndarray\n        K_index,              # dict\n        beta_counts,          # dict\n        gene_psite_counts,    # list\n        n                     # int\n    )\n</code></pre>"},{"location":"reference/#kinopt.evol.utils.iodata.apply_scaling","title":"<code>apply_scaling(df, time_series_columns, method, split_point, segment_points)</code>","text":"<p>Applies different scaling methods to the time-series columns of a DataFrame. Args:     df (pd.DataFrame): The DataFrame containing the time-series data.     time_series_columns (list): List of columns to be scaled.     method (str): The scaling method to apply ('min_max', 'log', 'temporal', 'segmented', 'slope', 'cumulative').     split_point (int): Column index for temporal scaling.     segment_points (list): List of column indices for segmented scaling. :returns:     pd.DataFrame: The DataFrame with scaled time-series columns.</p> Source code in <code>kinopt/evol/utils/iodata.py</code> <pre><code>def apply_scaling(df, time_series_columns, method, split_point, segment_points):\n    \"\"\"\n    Applies different scaling methods to the time-series columns of a DataFrame.\n    Args:\n        df (pd.DataFrame): The DataFrame containing the time-series data.\n        time_series_columns (list): List of columns to be scaled.\n        method (str): The scaling method to apply ('min_max', 'log', 'temporal', 'segmented', 'slope', 'cumulative').\n        split_point (int): Column index for temporal scaling.\n        segment_points (list): List of column indices for segmented scaling.\n    :returns:\n        pd.DataFrame: The DataFrame with scaled time-series columns.\n    \"\"\"\n\n    if method == 'min_max':\n        # Min-Max Scaling (row-wise)\n        scaler = MinMaxScaler()\n        df[time_series_columns] = pd.DataFrame(\n            df[time_series_columns]\n            .apply(lambda row: scaler.fit_transform(row.values.reshape(-1, 1)).flatten(), axis=1).tolist(),\n            index=df.index\n        )\n\n    elif method == 'log':\n        # Log Scaling\n        df[time_series_columns] = df[time_series_columns].applymap(lambda x: np.log(x))\n\n    elif method == 'temporal':\n        # Temporal Scaling (first split_point columns vs the rest)\n        first_part_columns = time_series_columns[:split_point]\n        second_part_columns = time_series_columns[split_point:]\n\n        scaler_first = MinMaxScaler()\n        scaler_second = MinMaxScaler()\n\n        df[first_part_columns] = scaler_first.fit_transform(df[first_part_columns])\n        df[second_part_columns] = scaler_second.fit_transform(df[second_part_columns])\n\n    elif method == 'segmented':\n        # Segmented Scaling (multiple segments)\n        if not segment_points:\n            raise ValueError(\"segment_points must be provided for segmented scaling.\")\n        segment_columns = [time_series_columns[segment_points[i]:segment_points[i + 1]] for i in\n                           range(len(segment_points) - 1)]\n        for segment in segment_columns:\n            scaler = MinMaxScaler()\n            df[segment] = scaler.fit_transform(df[segment])\n\n    elif method == 'slope':\n        # Slope Scaling (rate of change)\n        diffs_df = df[time_series_columns].diff(axis=1).fillna(0)\n        scaler = MinMaxScaler()\n        df[time_series_columns] = scaler.fit_transform(diffs_df)\n\n    elif method == 'cumulative':\n        # Cumulative Scaling (cumulative sum)\n        cum_df = df[time_series_columns].cumsum(axis=1)\n        scaler = MinMaxScaler()\n        df[time_series_columns] = scaler.fit_transform(cum_df)\n\n    elif method == \"None\":\n        return df\n\n    else:\n        raise ValueError(\n            \"Invalid scaling method. Choose from 'min_max', 'log', 'temporal', 'segmented', 'slope', 'cumulative'.\")\n\n    return df\n</code></pre>"},{"location":"reference/#kinopt.evol.utils.iodata.create_report","title":"<code>create_report(results_dir, output_file='report.html')</code>","text":"<p>Creates a single global report HTML file from all gene folders inside the results directory.</p> <p>For each gene folder (e.g. \"ABL2\"), the report will include:   - All PNG plots and interactive HTML plots displayed in a grid with three plots per row.   - Each plot is confined to a fixed size of 900px by 900px.   - Data tables from XLSX or CSV files in the gene folder are displayed below the plots, one per row.</p> <p>Parameters:</p> Name Type Description Default <code>results_dir</code> <code>str</code> <p>Path to the root results directory.</p> required <code>output_file</code> <code>str</code> <p>Name of the generated global report file (placed inside results_dir).</p> <code>'report.html'</code> Source code in <code>kinopt/evol/utils/iodata.py</code> <pre><code>def create_report(results_dir: str, output_file: str = \"report.html\"):\n    \"\"\"\n    Creates a single global report HTML file from all gene folders inside the results directory.\n\n    For each gene folder (e.g. \"ABL2\"), the report will include:\n      - All PNG plots and interactive HTML plots displayed in a grid with three plots per row.\n      - Each plot is confined to a fixed size of 900px by 900px.\n      - Data tables from XLSX or CSV files in the gene folder are displayed below the plots, one per row.\n\n    Args:\n        results_dir (str): Path to the root results directory.\n        output_file (str): Name of the generated global report file (placed inside results_dir).\n    \"\"\"\n    # Gather gene folders (skip \"General\" and \"logs\")\n    gene_folders = [\n        d for d in os.listdir(results_dir)\n        if os.path.isdir(os.path.join(results_dir, d)) and d not in (\"General\", \"logs\")\n    ]\n\n    # Build HTML content with updated CSS for spacing.\n    html_parts = [\n        \"&lt;html&gt;\",\n        \"&lt;head&gt;\",\n        \"&lt;meta charset='UTF-8'&gt;\",\n        \"&lt;title&gt;Estimation Report&lt;/title&gt;\",\n        \"&lt;style&gt;\",\n        \"body { font-family: Arial, sans-serif; margin: 20px; }\",\n        \"h1 { color: #333; }\",\n        \"h2 { color: #555; font-size: 1.8em; border-bottom: 1px solid #ccc; padding-bottom: 5px; }\",\n        \"h3 { color: #666; font-size: 1.4em; margin-top: 10px; margin-bottom: 10px; }\",\n        # /* CSS grid for plots: two per row, fixed size 500px x 500px, extra space between rows */\n        \".plot-container {\",\n        \"  display: grid;\",\n        \"  grid-template-columns: repeat(2, 500px);\",\n        \"  column-gap: 20px;\",\n        \"  row-gap: 40px;\", # /* extra vertical gap */\n        \"  justify-content: left;\",\n        \"  margin-bottom: 20px;\",\n        \"}\",\n        \".plot-item {\",\n        \"  width: 500px;\",\n        \"  height: 500px;\",\n        \"}\",\n        \"img, iframe {\",\n        \"  width: 100%;\",\n        \"  height: 100%;\",\n        \"  object-fit: contain;\",\n        \"  border: none;\",\n        \"}\",\n        # /* Data tables: full width, one per row */\n        \".data-table {\",\n        \"  width: 50%;\",\n        \"  margin-bottom: 20px;\",\n        \"}\",\n        \"table {\",\n        \"  border-collapse: collapse;\",\n        \"  width: 100%;\",\n        \"  margin-top: 10px;\",\n        \"}\",\n        \"th, td {\",\n        \"  border: 1px solid #ccc;\",\n        \"  padding: 8px;\",\n        \"  text-align: left;\",\n        \"}\",\n        \"&lt;/style&gt;\",\n        \"&lt;/head&gt;\",\n        \"&lt;body&gt;\",\n        \"&lt;h1&gt;Kinase Optimization Report&lt;/h1&gt;\"\n    ]\n\n    # For each gene folder, create a section in the report.\n    for gene in sorted(gene_folders):\n        gene_folder = os.path.join(results_dir, gene)\n        html_parts.append(f\"&lt;h2&gt;Protein Group: {gene}&lt;/h2&gt;\")\n\n        # Create grid container for fixed-size plots.\n        html_parts.append('&lt;div class=\"plot-container\"&gt;')\n        files = sorted(os.listdir(gene_folder))\n        for filename in files:\n            file_path = os.path.join(gene_folder, filename)\n            if os.path.isfile(file_path):\n                if filename.endswith(\".png\"):\n                    rel_path = os.path.join(gene, filename)\n                    html_parts.append(\n                        f'&lt;div class=\"plot-item\"&gt;&lt;h3&gt;{filename}&lt;/h3&gt;&lt;img src=\"{rel_path}\" alt=\"{filename}\"&gt;&lt;/div&gt;'\n                    )\n        html_parts.append('&lt;/div&gt;')  # End of plot container\n\n        # Data tables: display XLSX or CSV files from the gene folder, one per row.\n        for filename in files:\n            file_path = os.path.join(gene_folder, filename)\n            if os.path.isfile(file_path) and filename.endswith(\".xlsx\"):\n                try:\n                    df = pd.read_excel(file_path)\n                    table_html = df.to_html(index=False, border=0)\n                    html_parts.append(f'&lt;div class=\"data-table\"&gt;&lt;h3&gt;Data Table: {filename}&lt;/h3&gt;{table_html}&lt;/div&gt;')\n                except Exception as e:\n                    html_parts.append(\n                        f'&lt;div class=\"data-table\"&gt;&lt;h3&gt;Data Table: {filename}&lt;/h3&gt;&lt;p&gt;Error reading {filename}: {e}&lt;/p&gt;&lt;/div&gt;'\n                    )\n\n    html_parts.append(\"&lt;/body&gt;\")\n    html_parts.append(\"&lt;/html&gt;\")\n\n    # Write the report into the results directory.\n    output_path = os.path.join(results_dir, output_file)\n    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(html_parts))\n</code></pre>"},{"location":"reference/#kinopt.evol.utils.iodata.format_duration","title":"<code>format_duration(seconds)</code>","text":"<p>Returns a formatted string representing the duration in seconds, minutes, or hours. The format is: - seconds: \"xx.xx sec\" - minutes: \"xx.xx min\" - hours: \"xx.xx hr\"</p> <p>:param seconds: :return:</p> Source code in <code>kinopt/evol/utils/iodata.py</code> <pre><code>def format_duration(seconds):\n    \"\"\"\n    Returns a formatted string representing the duration in seconds, minutes, or hours.\n    The format is:\n    - seconds: \"xx.xx sec\"\n    - minutes: \"xx.xx min\"\n    - hours: \"xx.xx hr\"\n\n    :param seconds:\n    :return:\n    \"\"\"\n    if seconds &lt; 60:\n        return f\"{seconds:.2f} sec\"\n    elif seconds &lt; 3600:\n        return f\"{seconds / 60:.2f} min\"\n    else:\n        return f\"{seconds / 3600:.2f} hr\"\n</code></pre>"},{"location":"reference/#kinopt.evol.utils.iodata.load_and_scale_data","title":"<code>load_and_scale_data(estimate_missing, scaling_method, split_point, seg_points)</code>","text":"<p>Loads the full HGNC data and kinase interaction data, applies scaling to the time-series columns, and subsets/merges them. The first file is the full HGNC data, and the second file contains kinase interactions. The function also handles the conversion of kinases from string format to list format.</p> <p>:param estimate_missing: :param scaling_method: :param split_point: :param seg_points:</p> <p>:return: full_hgnc_df (pd.DataFrame): The scaled data from input1 interaction_df (pd.DataFrame): The subset/merged DataFrame from input2 observed (pd.DataFrame): Subset of full_hgnc_df merged with interaction_df</p> Source code in <code>kinopt/evol/utils/iodata.py</code> <pre><code>def load_and_scale_data(estimate_missing, scaling_method, split_point, seg_points):\n    \"\"\"\n    Loads the full HGNC data and kinase interaction data, applies scaling to the time-series columns,\n    and subsets/merges them. The first file is the full HGNC data, and the second file contains kinase interactions.\n    The function also handles the conversion of kinases from string format to list format.\n\n    :param estimate_missing:\n    :param scaling_method:\n    :param split_point:\n    :param seg_points:\n\n    :return:\n    full_hgnc_df (pd.DataFrame): The scaled data from input1\n    interaction_df (pd.DataFrame): The subset/merged DataFrame from input2\n    observed (pd.DataFrame): Subset of full_hgnc_df merged with interaction_df\n    \"\"\"\n    full_hgnc_df = pd.read_csv(INPUT1)\n    full_hgnc_df = full_hgnc_df[full_hgnc_df['Psite'].notna() &amp; (full_hgnc_df['Psite'] != '')]\n    time_series_cols = [f'x{i}' for i in range(1, 15)]\n    full_hgnc_df = apply_scaling(full_hgnc_df, time_series_cols, scaling_method, split_point, seg_points)\n    interaction_df = pd.read_csv(INPUT2, header=0)\n    if estimate_missing:\n        observed = full_hgnc_df.merge(interaction_df.iloc[:, :2], on=[\"GeneID\", \"Psite\"]).drop(columns=[\"max\", \"min\"])\n        interaction_df['Kinase'] = interaction_df['Kinase'].str.strip('{}').apply(lambda x: [k.strip() for k in x.split(',')])\n    else:\n        interaction_df = interaction_df[interaction_df['Kinase'].apply(\n            lambda k: all(kinase in set(full_hgnc_df['GeneID'][1:]) for kinase in k.strip('{}').split(',')))]\n        interaction_df['Kinase'] = interaction_df['Kinase'].str.strip('{}').apply(lambda x: [k.strip() for k in x.split(',')])\n        observed = full_hgnc_df.merge(interaction_df.iloc[:, :2], on=[\"GeneID\", \"Psite\"]).drop(columns=[\"max\", \"min\"])\n    return full_hgnc_df, interaction_df, observed\n</code></pre>"},{"location":"reference/#kinopt.evol.utils.iodata.organize_output_files","title":"<code>organize_output_files(*directories)</code>","text":"<p>Organizes output files from the optimization process into separate folders based on protein names. Each protein's files are moved into a folder named after the protein. Any remaining files that do not match the protein pattern are moved to a \"General\" folder.</p> <p>:param directories: List of directories to organize.</p> Source code in <code>kinopt/evol/utils/iodata.py</code> <pre><code>def organize_output_files(*directories):\n    \"\"\"\n    Organizes output files from the optimization process into separate folders based on protein names.\n    Each protein's files are moved into a folder named after the protein.\n    Any remaining files that do not match the protein pattern are moved to a \"General\" folder.\n\n    :param directories: List of directories to organize.\n    \"\"\"\n    protein_regex = re.compile(r'([A-Za-z0-9]+)_.*\\.(json|svg|png|html|csv|xlsx)$')\n\n    for directory in directories:\n        if not os.path.isdir(directory):\n            print(f\"Warning: '{directory}' is not a valid directory. Skipping.\")\n            continue\n\n        # Move files matching the protein pattern.\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            if os.path.isfile(file_path):\n                match = protein_regex.search(filename)\n                if match:\n                    protein = match.group(1)\n                    protein_folder = os.path.join(directory, protein)\n                    os.makedirs(protein_folder, exist_ok=True)\n                    destination_path = os.path.join(protein_folder, filename)\n                    shutil.move(file_path, destination_path)\n\n        # After protein files have been moved, move remaining files to a \"General\" folder.\n        general_folder = os.path.join(directory, \"General\")\n        os.makedirs(general_folder, exist_ok=True)\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            if os.path.isfile(file_path):\n                destination_path = os.path.join(general_folder, filename)\n                shutil.move(file_path, destination_path)\n</code></pre>"},{"location":"reference/#kinopt.evol.utils.params.compute_metrics","title":"<code>compute_metrics(optimized_params, P_initial, P_initial_array, K_index, K_array, gene_psite_counts, beta_counts, n)</code>","text":"<p>Computes various error metrics to evaluate the performance of the optimization process. The function calculates the Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and R-squared value. These metrics provide insights into the accuracy of the estimated time series compared to the observed data.</p> <p>The function takes the following parameters: :param optimized_params: :param P_initial: :param P_initial_array: :param K_index: :param K_array: :param gene_psite_counts: :param beta_counts: :param n:</p> <p>:return: - P_estimated: Estimated time series matrix for all gene-psite combinations. - residuals: Residuals between observed and estimated values. - mse: Mean Squared Error. - rmse: Root Mean Squared Error. - mae: Mean Absolute Error. - mape: Mean Absolute Percentage Error. - r_squared: R-squared value.</p> Source code in <code>kinopt/evol/utils/params.py</code> <pre><code>def compute_metrics(optimized_params, P_initial, P_initial_array, K_index, K_array,\n                    gene_psite_counts, beta_counts, n):\n    \"\"\"\n    Computes various error metrics to evaluate the performance of the optimization process.\n    The function calculates the Mean Squared Error (MSE), Root Mean Squared Error (RMSE),\n    Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and R-squared value.\n    These metrics provide insights into the accuracy of the estimated time series compared to the observed data.\n\n    The function takes the following parameters:\n    :param optimized_params:\n    :param P_initial:\n    :param P_initial_array:\n    :param K_index:\n    :param K_array:\n    :param gene_psite_counts:\n    :param beta_counts:\n    :param n:\n\n    :return:\n    - P_estimated: Estimated time series matrix for all gene-psite combinations.\n    - residuals: Residuals between observed and estimated values.\n    - mse: Mean Squared Error.\n    - rmse: Root Mean Squared Error.\n    - mae: Mean Absolute Error.\n    - mape: Mean Absolute Percentage Error.\n    - r_squared: R-squared value.\n    \"\"\"\n    P_estimated = estimated_series(\n        optimized_params, P_initial, K_index, K_array, gene_psite_counts, beta_counts\n    )\n    residuals = P_initial_array - P_estimated\n    mse = np.sum((residuals) ** 2) / n\n    rmse = np.sqrt(mse)\n    mae = np.mean(np.abs(residuals))\n    mape = np.mean(np.abs(residuals / P_initial_array)) * 100\n    r_squared = 1 - (np.sum((residuals) ** 2) / np.sum((P_initial_array - np.mean(P_initial_array)) ** 2))\n    logger.info(\"--- Error Metrics ---\")\n    logger.info(f\"Mean Squared Error (MSE): {mse:.4f}\")\n    logger.info(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n    logger.info(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n    logger.info(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n    logger.info(f\"R-squared (R^2): {r_squared:.4f}\")\n    return P_estimated, residuals, mse, rmse, mae, mape, r_squared\n</code></pre>"},{"location":"reference/#kinopt.evol.utils.params.extract_parameters","title":"<code>extract_parameters(P_initial, gene_psite_counts, K_index, optimized_params)</code>","text":"<p>Extracts the optimized alpha and beta values from the optimized parameters. The function organizes the values into dictionaries for easy access and interpretation. The alpha values are associated with gene-psite pairs and their corresponding kinases, while the beta values are associated with kinase-psite pairs. The function also logs the optimized values for transparency and debugging purposes.</p> <p>The function takes the following parameters: :param P_initial: :param gene_psite_counts: :param K_index: :param optimized_params:</p> <p>:return: - alpha_values: Dictionary mapping (gene, psite) to a dictionary of kinases and their alpha values. - beta_values: Dictionary mapping (kinase, psite) to their corresponding beta values.</p> Source code in <code>kinopt/evol/utils/params.py</code> <pre><code>def extract_parameters(P_initial, gene_psite_counts, K_index, optimized_params):\n    \"\"\"\n    Extracts the optimized alpha and beta values from the optimized parameters.\n    The function organizes the values into dictionaries for easy access and\n    interpretation. The alpha values are associated with gene-psite pairs and\n    their corresponding kinases, while the beta values are associated with\n    kinase-psite pairs. The function also logs the optimized values for\n    transparency and debugging purposes.\n\n    The function takes the following parameters:\n    :param P_initial:\n    :param gene_psite_counts:\n    :param K_index:\n    :param optimized_params:\n\n    :return:\n    - alpha_values: Dictionary mapping (gene, psite) to a dictionary of kinases and their alpha values.\n    - beta_values: Dictionary mapping (kinase, psite) to their corresponding beta values.\n    \"\"\"\n    alpha_values = {}\n    alpha_start = 0\n    for idx, count in enumerate(gene_psite_counts):\n        gene, psite = list(P_initial.keys())[idx]\n        kinases = P_initial[(gene, psite)]['Kinases']\n        alpha_values[(gene, psite)] = dict(zip(kinases, optimized_params[alpha_start:alpha_start + count]))\n        alpha_start += count\n\n    # Extract betas for kinase-psite\n    beta_values = {}\n    beta_start = sum(gene_psite_counts)\n    for kinase, kinase_psites in K_index.items():\n        for psite, _ in kinase_psites:\n            count = 1  # Each psite in beta_counts has a count of 1\n            beta_values[(kinase, psite)] = optimized_params[beta_start:beta_start + count]\n            beta_start += count\n            # Display optimized values\n    logger.info(\"Optimized Alpha Values:\")\n    for (gene, psite), kinases in alpha_values.items():\n        logger.info(f\"Protein {gene}, Psite {psite}:\")\n        for kinase, value in kinases.items():\n            logger.info(f\"  Kinase {kinase}: {value}\")\n\n    logger.info(\"Optimized Beta Values:\")\n    for (kinase, psite), value in beta_values.items():\n        logger.info(f\"Kinase {kinase}, Psite {psite}: {value}\")\n    return alpha_values, beta_values\n</code></pre>"},{"location":"reference/#kinopt.fitanalysis.helpers.postfit.additional_plots","title":"<code>additional_plots(df, scaled_data, alpha_values, beta_values, residuals_df)</code>","text":"<p>Function to create additional plots including CDF, KDE, Boxplot, and Hierarchical Clustering.</p> <p>:param df: :param scaled_data: :param alpha_values: :param beta_values: :param residuals_df:</p> Source code in <code>kinopt/fitanalysis/helpers/postfit.py</code> <pre><code>def additional_plots(df, scaled_data, alpha_values, beta_values, residuals_df):\n    \"\"\"\n    Function to create additional plots including CDF, KDE, Boxplot, and Hierarchical Clustering.\n\n    :param df:\n    :param scaled_data:\n    :param alpha_values:\n    :param beta_values:\n    :param residuals_df:\n    \"\"\"\n    alpha_df = df[df['Parameter'].str.startswith('\u03b1')]\n    beta_df = df[df['Parameter'].str.startswith('\u03b2')]\n\n    # KDE Plot\n    plt.figure(figsize=(8, 8))\n    sns.kdeplot(alpha_df['Value'], color='blue', label='\u03b1', fill=True)\n    sns.kdeplot(beta_df['Value'], color='green', label='\u03b2', fill=True)\n    plt.title('')\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/distribution_parameters.png', format='png', dpi=300)\n    plt.close()\n\n    # Box Plot\n    plt.figure(figsize=(8, 8))\n    sns.boxplot(\n        x='Type',\n        y='Value',\n        data=pd.concat([alpha_df, beta_df]).assign(Type=lambda df: df['Parameter'].str[0])\n    )\n    plt.title('')\n    plt.ylabel('Value')\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/boxplot_parameters.png', format='png', dpi=300)\n    plt.close()\n\n    # CDF Plots\n    plt.figure(figsize=(8, 8))\n    sns.ecdfplot(alpha_df['Value'], color='blue', label='\u03b1')\n    sns.ecdfplot(beta_df['Value'], color='green', label='\u03b2')\n    plt.title('')\n    plt.xlabel('Value')\n    plt.ylabel('CDF')\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/cdf_parameters.png', format='png', dpi=300)\n    plt.close()\n\n    # Prepare data\n    alpha_data = alpha_values[['Gene', 'Alpha']].rename(columns={'Gene': 'Group', 'Alpha': 'Value'})\n    alpha_data['Parameter'] = r'$\\alpha$'\n    beta_data = beta_values[['Kinase', 'Beta']].rename(columns={'Kinase': 'Group', 'Beta': 'Value'})\n    beta_data['Parameter'] = r'$\\beta$'\n    combined_data = pd.concat([alpha_data, beta_data])\n    sorted_data = combined_data.sort_values(by='Value')\n\n    # Plot the violin plot\n    plt.figure(figsize=(8, 8))\n    sns.violinplot(data=sorted_data, y='Group', x='Value', hue='Parameter', split=True, palette='tab20', orient='h')\n    plt.yticks(rotation=0)\n    plt.title(\"\")\n    plt.xlabel(\"Estimated Values\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/violin_parameters.png', format='png', dpi=300)\n    plt.close()\n\n    # Rename the columns of time points in the residuals DataFrame to 1, 2, ..., 14\n    # Create a mapping of known column names to their replacements\n    column_mapping = {f\"x{i}\": str(i) for i in range(1, 15)}\n    # Rename the columns directly using the mapping\n    residuals_df.rename(columns=column_mapping, inplace=True)\n\n    # Define consistent time columns\n    time_columns = [str(i) for i in range(1, 15)]\n\n    # Heatmap data for optimization progression\n    heatmap_data = residuals_df.set_index('Gene')[time_columns]\n\n    # Optimization progression heatmap\n    plt.figure(figsize=(8, 8))\n    sns.heatmap(\n        heatmap_data,\n        cmap='viridis',\n        annot=False,\n        cbar_kws={'label': 'Magnitude'}\n    )\n    plt.title(\"\")\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"Group\")\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/time_residuals.png', format='png', dpi=300)\n    plt.close()\n\n    # Variance across time points\n    time_point_variance = residuals_df.set_index('Gene')[time_columns].var(axis=0)\n\n    # Identify the top 5 highest variance time points\n    top_5_variances = time_point_variance.nlargest(5)\n\n    # Plot the variance across time points with top 5 highlighted\n    plt.figure(figsize=(8, 8))\n    bars = plt.bar(time_point_variance.index, time_point_variance, color='lightblue', edgecolor='black')\n    for time_point in top_5_variances.index:\n        bars[time_point_variance.index.get_loc(time_point)].set_color('coral')\n\n    plt.title(\"\")\n    plt.xlabel(\"Time\")\n    plt.ylabel(r\"$\\mathrm{Var}(\\text{residuals})$\")\n    plt.xticks(rotation=45)\n\n    # Annotate the top 5 points\n    for time_point, variance in top_5_variances.items():\n        plt.text(time_point_variance.index.get_loc(time_point), variance + 0.01, f\"{variance:.2f}\",\n                 ha='center', va='bottom', fontsize=8, color='black')\n\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/variance_residuals.png', format='png', dpi=300)\n    plt.close()\n\n    # Error trends over time\n    # Mean absolute residuals across all Genes for each time point\n    mean_absolute_error = residuals_df[time_columns].abs().mean(axis=0)\n\n    # Identify top 3 lowest and top 3 highest MAE time points\n    top_3_highest_mae = mean_absolute_error.nlargest(3)\n    top_3_lowest_mae = mean_absolute_error.nsmallest(3)\n\n    plt.figure(figsize=(8, 8))\n    plt.plot(mean_absolute_error.index, mean_absolute_error, marker='o', color='lightblue', linestyle='-')\n\n    # Highlight top 3 highest with upward triangles and lowest with downward triangles\n    for time_point, value in top_3_highest_mae.items():\n        plt.scatter(mean_absolute_error.index.get_loc(time_point), value, color='red', s=100, marker='^', zorder=5)\n    for time_point, value in top_3_lowest_mae.items():\n        plt.scatter(mean_absolute_error.index.get_loc(time_point), value, color='green', s=100, marker='v', zorder=5)\n\n    plt.title(\"\")\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"MAE\")\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/error_trends.png', format='png', dpi=300)\n    plt.close()\n\n    # Residual profiles across Genes\n    # Sum residuals across time points for each gene\n    residual_profiles = residuals_df.set_index('Gene')[time_columns].sum(axis=1)\n\n    # Sort and identify top 5 and bottom 5 Genes with highest and lowest cumulative residuals\n    sorted_residual_profiles = residual_profiles.sort_values(ascending=False)\n    top_5_residuals = sorted_residual_profiles.head(5)\n    bottom_5_residuals = sorted_residual_profiles.tail(5)\n\n    plt.figure(figsize=(8, 8))\n\n    # Assign unique colors to the top 5 and bottom 5 bars\n    top_colors = ['red', 'blue', 'green', 'orange', 'purple']\n    bottom_colors = ['cyan', 'magenta', 'yellow', 'brown', 'pink']\n    default_color = 'teal'\n\n    # Create bars with distinct colors for the top 5 and bottom 5\n    for index, (gene, value) in enumerate(sorted_residual_profiles.items()):\n        if gene in top_5_residuals.index:\n            color_index = top_5_residuals.index.tolist().index(gene)\n            plt.bar(index, value, color=top_colors[color_index], edgecolor='black',\n                    label=gene if gene not in plt.gca().get_legend_handles_labels()[1] else None)\n        elif gene in bottom_5_residuals.index:\n            color_index = bottom_5_residuals.index.tolist().index(gene)\n            plt.bar(index, value, color=bottom_colors[color_index], edgecolor='black',\n                    label=gene if gene not in plt.gca().get_legend_handles_labels()[1] else None)\n        else:\n            plt.bar(index, value, color=default_color, edgecolor='black')\n\n    # Add a single legend for the top 5 and bottom 5 Genes\n    plt.legend(title=\"Protein\")\n\n    # Remove x-axis labels and ticks for a cleaner look\n    plt.xticks([], [])\n    plt.title(\"\")\n    plt.ylabel(\"Cumulative Residuals\")\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/residual_profiles.png', format='png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#kinopt.fitanalysis.helpers.postfit.create_sankey_from_network","title":"<code>create_sankey_from_network(output_dir, data, title)</code>","text":"<p>Creates a Sankey diagram from the given data and saves it as an HTML file.</p> <p>This function processes the input data to generate nodes and links for a Sankey diagram. It assigns colors to nodes and links based on their attributes and values, and uses Plotly to render the diagram. The resulting diagram is saved as an HTML file in the specified output directory.</p> <p>:param output_dir: str     The directory where the Sankey diagram HTML file will be saved. :param data: pd.DataFrame     A DataFrame containing the data for the Sankey diagram. It must include the following columns:     - 'Source': The source node of the link.     - 'Target': The target node of the link.     - 'Value': The value of the link, which determines the flow size. :param title: str     The title of the Sankey diagram.</p> <p>The function performs the following steps: 1. Initializes nodes and links for the Sankey diagram. 2. Maps node labels to indices and assigns colors to nodes. 3. Processes the data to create links between nodes, assigning colors based on link values. 4. Builds the Sankey diagram using Plotly. 5. Adds a color bar to explain the flow gradient. 6. Saves the Sankey diagram as an HTML file in the specified output directory.</p> Source code in <code>kinopt/fitanalysis/helpers/postfit.py</code> <pre><code>def create_sankey_from_network(output_dir, data, title):\n    \"\"\"\n    Creates a Sankey diagram from the given data and saves it as an HTML file.\n\n    This function processes the input data to generate nodes and links for a Sankey diagram.\n    It assigns colors to nodes and links based on their attributes and values, and uses Plotly\n    to render the diagram. The resulting diagram is saved as an HTML file in the specified output directory.\n\n    :param output_dir: str\n        The directory where the Sankey diagram HTML file will be saved.\n    :param data: pd.DataFrame\n        A DataFrame containing the data for the Sankey diagram. It must include the following columns:\n        - 'Source': The source node of the link.\n        - 'Target': The target node of the link.\n        - 'Value': The value of the link, which determines the flow size.\n    :param title: str\n        The title of the Sankey diagram.\n\n    The function performs the following steps:\n    1. Initializes nodes and links for the Sankey diagram.\n    2. Maps node labels to indices and assigns colors to nodes.\n    3. Processes the data to create links between nodes, assigning colors based on link values.\n    4. Builds the Sankey diagram using Plotly.\n    5. Adds a color bar to explain the flow gradient.\n    6. Saves the Sankey diagram as an HTML file in the specified output directory.\n    \"\"\"\n\n    # Initialize nodes and links for Sankey diagram\n    nodes = []\n    links = []\n\n    # Create a mapping for node indices\n    node_indices = {}\n    index = 0\n\n    # Define color scale\n    cmap = plt.cm.tab20  # Choose a colormap\n    norm = mcolors.Normalize(vmin=data['Value'].abs().min(), vmax=data['Value'].abs().max())\n\n    # Process the data to extract nodes and edges\n    for _, row in data.iterrows():\n        source = row['Source']\n        target = row['Target']\n        value = abs(row['Value']) * 100  # Use absolute value for Sankey flow size\n\n        # Add source and target nodes if not already added\n        if source not in node_indices:\n            nodes.append({\"label\": source, \"color\": \"green\" if \"Kinase\" in source else \"red\"})\n            node_indices[source] = index\n            index += 1\n        if target not in node_indices:\n            nodes.append({\"label\": target, \"color\": \"gray\"})\n            node_indices[target] = index\n            index += 1\n\n        # Generate color for the link based on value\n        flow_color = mcolors.rgb2hex(cmap(norm(value)))\n\n        # Add a link between the source and target\n        links.append({\n            \"source\": node_indices[source],\n            \"target\": node_indices[target],\n            \"value\": value,\n            \"color\": flow_color\n        })\n\n    # Build the Sankey diagram\n    fig = go.Figure(go.Sankey(\n        node=dict(\n            pad=15,\n            thickness=20,\n            line=dict(color=\"black\", width=0.5),\n            label=[node[\"label\"] for node in nodes],\n            color=[node[\"color\"] for node in nodes]\n        ),\n        link=dict(\n            source=[link[\"source\"] for link in links],\n            target=[link[\"target\"] for link in links],\n            value=[link[\"value\"] for link in links],\n            color=[link[\"color\"] for link in links]  # Set link colors\n        )\n    ))\n    # Add a color bar to explain the flow gradient\n    colorbar = go.Scatter(\n        x=[None],\n        y=[None],\n        mode='markers',\n        marker=dict(\n            colorscale='Viridis',\n            cmin=data['Value'].abs().min(),\n            cmax=data['Value'].abs().max(),\n            colorbar=dict(\n                title=\"Edge Value\"\n            )\n        ),\n        hoverinfo='none'\n    )\n    # Add the color bar scatter plot\n    fig.add_trace(colorbar)\n    # Update layout\n    fig.update_layout(xaxis_visible=False, yaxis_visible=False)\n    fig.update_xaxes(showgrid=False)\n    fig.update_yaxes(showgrid=False)\n    fig.update_layout(title_text=title, font_size=10)\n    fig.write_html(f\"{output_dir}/sankey.html\")\n</code></pre>"},{"location":"reference/#kinopt.fitanalysis.helpers.postfit.goodnessoffit","title":"<code>goodnessoffit(estimated, observed)</code>","text":"<p>Function to plot the goodness of fit for estimated and observed values. It creates scatter plots with confidence intervals and labels for genes outside the 95% CI. The function also calculates KL divergence and generates a heatmap for optimization progression.</p> <p>:param estimated: :param observed:</p> Source code in <code>kinopt/fitanalysis/helpers/postfit.py</code> <pre><code>def goodnessoffit(estimated, observed):\n    \"\"\"\n    Function to plot the goodness of fit for estimated and observed values.\n    It creates scatter plots with confidence intervals and labels for genes outside the 95% CI.\n    The function also calculates KL divergence and generates a heatmap for optimization progression.\n\n    :param estimated:\n    :param observed:\n    \"\"\"\n    merged_data = estimated.rename(columns={\"Gene\": \"GeneID\"}).merge(observed, on=['GeneID', 'Psite'],\n                                                                     suffixes=('_est', '_obs'))\n    merged_data['Observed_Mean'] = merged_data.loc[:, 'x1_obs':'x14_obs'].mean(axis=1)\n    merged_data['Estimated_Mean'] = merged_data.loc[:, 'x1_est':'x14_est'].mean(axis=1)\n    colors = cm.tab20(range(len(merged_data)))\n\n    ci_color_95 = 'red'\n    ci_color_99 = 'gray'\n    diagonal_color = 'gray'\n\n    # Generate a palette with as many distinct colors as genes\n    unique_genes_list = merged_data['GeneID'].unique()\n\n    # Generate a categorical color palette with fully distinct colors (tab20 has 20 distinct colors)\n    palette = sns.color_palette(\"tab20\", len(unique_genes_list))\n\n    # Map each gene to a unique color from the categorical palette\n    gene_color_map = {gene: palette[i % len(palette)] for i, gene in enumerate(unique_genes_list)}\n\n    # Calculate overall mean and standard deviation\n    overall_std = merged_data.loc[:, 'x1_obs':'x14_obs'].values.std()\n\n    # Calculate CI offsets for 95% and 99%\n    ci_offset_95 = 1.96 * overall_std\n    ci_offset_99 = 2.576 * overall_std\n\n    # Goodness of Fit: Time-Series\n    plt.figure(figsize=(8, 8))\n\n    # Plot Observed vs. Estimated for x1 to x14 values\n    gene_handles = []\n    # Plot Observed vs. Estimated for x1 to x14 values\n    for i, (gene, psite, obs_vals, est_vals) in enumerate(zip(merged_data['GeneID'],\n                                                              merged_data['Psite'],\n                                                              merged_data.loc[:, 'x1_obs':'x14_obs'].values,\n                                                              merged_data.loc[:, 'x1_est':'x14_est'].values)):\n        # Sort values for plotting\n        sorted_indices = np.argsort(obs_vals)\n        obs_vals_sorted = obs_vals[sorted_indices]\n        est_vals_sorted = est_vals[sorted_indices]\n\n        # Plot observed and estimated values\n        plt.scatter(obs_vals_sorted, est_vals_sorted, color=gene_color_map[gene], edgecolor='black', s=50)\n\n        # Add label for each gene once, matching the point color\n        if gene not in [handle.get_label() for handle in gene_handles]:\n            handle = plt.Line2D([], [], color=gene_color_map[gene], marker='o', linestyle='', markersize=8, label=gene)\n            gene_handles.append(handle)\n\n    # Add diagonal line through the origin\n    min_val = min(merged_data.loc[:, 'x1_obs':'x14_obs'].values.min(),\n                  merged_data.loc[:, 'x1_est':'x14_est'].values.min())\n    max_val = max(merged_data.loc[:, 'x1_obs':'x14_obs'].values.max(),\n                  merged_data.loc[:, 'x1_est':'x14_est'].values.max())\n    plt.plot([min_val, max_val], [min_val, max_val], color=diagonal_color, linestyle='-', linewidth=1.5)\n\n    # Add lines parallel to the diagonal for 95% and 99% CI\n    plt.plot([min_val, max_val], [min_val + ci_offset_95, max_val + ci_offset_95], color=ci_color_95, linestyle='--',\n             linewidth=1, label='95% CI')\n    plt.plot([min_val, max_val], [min_val - ci_offset_95, max_val - ci_offset_95], color=ci_color_95, linestyle='--',\n             linewidth=1)\n    plt.plot([min_val, max_val], [min_val + ci_offset_99, max_val + ci_offset_99], color=ci_color_99, linestyle='--',\n             linewidth=1, label='99% CI')\n    plt.plot([min_val, max_val], [min_val - ci_offset_99, max_val - ci_offset_99], color=ci_color_99, linestyle='--',\n             linewidth=1)\n\n    # Expand the axes limits slightly to include all points without clipping\n    x_min = merged_data.loc[:, 'x1_obs':'x14_obs'].values.min() - 0.1 * (\n                merged_data.loc[:, 'x1_obs':'x14_obs'].values.max() - merged_data.loc[:,\n                                                                      'x1_obs':'x14_obs'].values.min())\n    x_max = merged_data.loc[:, 'x1_obs':'x14_obs'].values.max() + 0.1 * (\n                merged_data.loc[:, 'x1_obs':'x14_obs'].values.max() - merged_data.loc[:,\n                                                                      'x1_obs':'x14_obs'].values.min())\n    y_min = merged_data.loc[:, 'x1_est':'x14_est'].values.min() - 0.1 * (\n                merged_data.loc[:, 'x1_est':'x14_est'].values.max() - merged_data.loc[:,\n                                                                      'x1_est':'x14_est'].values.min())\n    y_max = merged_data.loc[:, 'x1_est':'x14_est'].values.max() + 0.1 * (\n                merged_data.loc[:, 'x1_est':'x14_est'].values.max() - merged_data.loc[:,\n                                                                      'x1_est':'x14_est'].values.min())\n    plt.xlim(x_min, x_max)\n    plt.ylim(y_min, y_max)\n\n    # Add labels and legends\n    plt.xlabel(\"Observed\")\n    plt.ylabel(\"Fitted\")\n    plt.title(\"\")\n    plt.legend(loc='best', fontsize='small', ncol=2)\n\n    # Add first legend for CI lines and diagonal\n    ci_legend = plt.legend(loc='best', fontsize='small', ncol=2)\n    plt.gca().add_artist(ci_legend)\n\n    # Add second legend for gene labels\n    gene_legend = plt.legend(handles=gene_handles, loc='best', fontsize='small', ncol=3, title=\"Proteins\")\n    plt.gca().add_artist(gene_legend)\n\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/gof_1.png\", dpi=300)\n    plt.close()\n\n    # Goodness of Fit: Time-Series\n    plt.figure(figsize=(8, 8))\n\n    # Plot Observed vs. Estimated for x1 to x14 values\n    gene_handles = []\n    # Plot Observed vs. Estimated for x1 to x14 values\n    for i, (gene, psite, obs_vals, est_vals) in enumerate(zip(merged_data['GeneID'],\n                                                              merged_data['Psite'],\n                                                              merged_data.loc[:, 'x1_obs':'x14_obs'].values,\n                                                              merged_data.loc[:, 'x1_est':'x14_est'].values)):\n        # Sort values for plotting\n        sorted_indices = np.argsort(obs_vals)\n        obs_vals_sorted = obs_vals[sorted_indices]\n        est_vals_sorted = est_vals[sorted_indices]\n\n        # Plot observed and estimated values\n        plt.scatter(obs_vals_sorted, est_vals_sorted, color=gene_color_map[gene], edgecolor='black', s=50)\n\n        # Add label for each gene once, matching the point color\n        if gene not in [handle.get_label() for handle in gene_handles]:\n            handle = plt.Line2D([], [], color=gene_color_map[gene], marker='o', linestyle='', markersize=8, label=gene)\n            gene_handles.append(handle)\n\n    # Add diagonal line through the origin\n    min_val = min(merged_data.loc[:, 'x1_obs':'x14_obs'].values.min(),\n                  merged_data.loc[:, 'x1_est':'x14_est'].values.min())\n    max_val = max(merged_data.loc[:, 'x1_obs':'x14_obs'].values.max(),\n                  merged_data.loc[:, 'x1_est':'x14_est'].values.max())\n    plt.plot([min_val, max_val], [min_val, max_val], color=diagonal_color, linestyle='-', linewidth=1.5)\n\n    # Add lines parallel to the diagonal for 95% and 99% CI\n    plt.plot([min_val, max_val], [min_val + ci_offset_95, max_val + ci_offset_95], color=ci_color_95, linestyle='--',\n             linewidth=1, label='95% CI')\n    plt.plot([min_val, max_val], [min_val - ci_offset_95, max_val - ci_offset_95], color=ci_color_95, linestyle='--',\n             linewidth=1)\n    plt.plot([min_val, max_val], [min_val + ci_offset_99, max_val + ci_offset_99], color=ci_color_99, linestyle='--',\n             linewidth=1, label='99% CI')\n    plt.plot([min_val, max_val], [min_val - ci_offset_99, max_val - ci_offset_99], color=ci_color_99, linestyle='--',\n             linewidth=1)\n\n    # Add labels and legends\n    plt.xlabel(\"Observed\")\n    plt.ylabel(\"Fitted\")\n    plt.title(\"\")\n    plt.legend(loc='best', fontsize='small', ncol=2)\n\n    # Add first legend for CI lines and diagonal\n    ci_legend = plt.legend(loc='best', fontsize='small', ncol=2)\n    plt.gca().add_artist(ci_legend)\n\n    # Add second legend for gene labels\n    gene_legend = plt.legend(handles=gene_handles, loc='best', fontsize='small', ncol=3, title=\"Proteins\")\n    plt.gca().add_artist(gene_legend)\n\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/gof_2.png\", dpi=300)\n    plt.close()\n\n    plt.figure(figsize=(8, 8))\n\n    # Plot Observed vs. Estimated for x1 to x14 values\n    plotted_genes = set()\n    text_annotations = []  # Collect text objects for adjustment\n    for i, (gene, psite, obs_vals, est_vals) in enumerate(zip(merged_data['GeneID'],\n                                                              merged_data['Psite'],\n                                                              merged_data.loc[:, 'x1_obs':'x14_obs'].values,\n                                                              merged_data.loc[:, 'x1_est':'x14_est'].values)):\n        # Sort values for plotting\n        sorted_indices = np.argsort(obs_vals)\n        obs_vals_sorted = obs_vals[sorted_indices]\n        est_vals_sorted = est_vals[sorted_indices]\n\n        # Plot observed and estimated values\n        plt.scatter(obs_vals_sorted, est_vals_sorted, color=gene_color_map[gene], edgecolor='black', s=50, marker='o')\n\n        # Add label only for genes outside the 95% CI\n        for obs, est in zip(obs_vals_sorted, est_vals_sorted):\n            if gene not in plotted_genes and (est &gt; obs + ci_offset_95 or est &lt; obs - ci_offset_95):\n                plt.text(obs, est, gene, fontsize=10, color=gene_color_map[gene],\n                         fontweight='bold', ha='center', va='center',\n                         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n                plotted_genes.add(gene)\n\n    # Adjust text positions to avoid overlap\n    adjust_text(text_annotations, arrowprops=dict(arrowstyle='-&gt;', color='gray', lw=0.5))\n\n    # Add diagonal line through the origin\n    plt.plot([min_val, max_val], [min_val, max_val], color=diagonal_color, linestyle='-', linewidth=1.5)\n\n    # Add lines parallel to the diagonal for 95% and 99% CI\n    plt.plot([min_val, max_val], [min_val + ci_offset_95, max_val + ci_offset_95], color=ci_color_95, linestyle='--',\n             linewidth=1, label='95% CI')\n    plt.plot([min_val, max_val], [min_val - ci_offset_95, max_val - ci_offset_95], color=ci_color_95, linestyle='--',\n             linewidth=1)\n    plt.plot([min_val, max_val], [min_val + ci_offset_99, max_val + ci_offset_99], color=ci_color_99, linestyle='--',\n             linewidth=1, label='99% CI')\n    plt.plot([min_val, max_val], [min_val - ci_offset_99, max_val - ci_offset_99], color=ci_color_99, linestyle='--',\n             linewidth=1)\n\n    # Add labels and grid\n    plt.xlabel(\"Observed\")\n    plt.ylabel(\"Fitted\")\n    plt.title(\"\")\n    plt.legend(loc='best', fontsize='small', ncol=2)\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/gof_3.png\", dpi=300)\n    plt.close()\n\n    plt.figure(figsize=(8, 8))\n\n    # Plot Observed vs. Estimated for x1 to x14 values\n    plotted_genes = set()\n    text_annotations = []  # Collect text objects for adjustment\n    for i, (gene, psite, obs_vals, est_vals) in enumerate(zip(merged_data['GeneID'],\n                                                              merged_data['Psite'],\n                                                              merged_data.loc[:, 'x1_obs':'x14_obs'].values,\n                                                              merged_data.loc[:, 'x1_est':'x14_est'].values)):\n        # Sort values for plotting\n        sorted_indices = np.argsort(obs_vals)\n        obs_vals_sorted = obs_vals[sorted_indices]\n        est_vals_sorted = est_vals[sorted_indices]\n\n        # Plot observed and estimated values\n        plt.scatter(obs_vals_sorted, est_vals_sorted, color=gene_color_map[gene], edgecolor='black', s=50, marker='o')\n\n        # Add label only for genes outside the 95% CI\n        for obs, est in zip(obs_vals_sorted, est_vals_sorted):\n            if gene not in plotted_genes and (est &gt; obs + ci_offset_95 or est &lt; obs - ci_offset_95):\n                plt.text(obs, est, gene, fontsize=10, color=gene_color_map[gene],\n                         fontweight='bold', ha='center', va='center',\n                         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n                plotted_genes.add(gene)\n\n    # Adjust text positions to avoid overlap\n    adjust_text(text_annotations, arrowprops=dict(arrowstyle='-&gt;', color='gray', lw=0.5))\n\n    # Add diagonal line through the origin\n    plt.plot([min_val, max_val], [min_val, max_val], color=diagonal_color, linestyle='-', linewidth=1.5)\n\n    # Add lines parallel to the diagonal for 95% and 99% CI\n    plt.plot([min_val, max_val], [min_val + ci_offset_95, max_val + ci_offset_95], color=ci_color_95, linestyle='--',\n             linewidth=1, label='95% CI')\n    plt.plot([min_val, max_val], [min_val - ci_offset_95, max_val - ci_offset_95], color=ci_color_95, linestyle='--',\n             linewidth=1)\n    plt.plot([min_val, max_val], [min_val + ci_offset_99, max_val + ci_offset_99], color=ci_color_99, linestyle='--',\n             linewidth=1, label='99% CI')\n    plt.plot([min_val, max_val], [min_val - ci_offset_99, max_val - ci_offset_99], color=ci_color_99, linestyle='--',\n             linewidth=1)\n\n    # Expand the axes limits slightly to include all points without clipping\n    x_min = merged_data.loc[:, 'x1_obs':'x14_obs'].values.min() - 0.1 * (\n                merged_data.loc[:, 'x1_obs':'x14_obs'].values.max() - merged_data.loc[:,\n                                                                      'x1_obs':'x14_obs'].values.min())\n    x_max = merged_data.loc[:, 'x1_obs':'x14_obs'].values.max() + 0.1 * (\n                merged_data.loc[:, 'x1_obs':'x14_obs'].values.max() - merged_data.loc[:,\n                                                                      'x1_obs':'x14_obs'].values.min())\n    y_min = merged_data.loc[:, 'x1_est':'x14_est'].values.min() - 0.1 * (\n                merged_data.loc[:, 'x1_est':'x14_est'].values.max() - merged_data.loc[:,\n                                                                      'x1_est':'x14_est'].values.min())\n    y_max = merged_data.loc[:, 'x1_est':'x14_est'].values.max() + 0.1 * (\n                merged_data.loc[:, 'x1_est':'x14_est'].values.max() - merged_data.loc[:,\n                                                                      'x1_est':'x14_est'].values.min())\n    plt.xlim(x_min, x_max)\n    plt.ylim(y_min, y_max)\n\n    # Add labels and grid\n    plt.xlabel(\"Observed\")\n    plt.ylabel(\"Fitted\")\n    plt.title(\"\")\n    plt.legend(loc='best', fontsize='small', ncol=2)\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/gof_4.png\", dpi=300)\n    plt.close()\n\n    # Goodness of Fit: Overall\n    plt.figure(figsize=(8, 8))\n\n    # Define the color palette for distinct colors\n    palette = sns.color_palette(\"tab20\", len(merged_data))\n    colors = {gene: palette[i] for i, gene in enumerate(merged_data['GeneID'].unique())}\n\n    # Calculate 95% and 99% CI bounds\n    ci_offset_95 = 1.96 * merged_data['Observed_Mean'].std()\n    ci_offset_99 = 2.576 * merged_data['Observed_Mean'].std()\n\n    lower_bound_95 = lambda x: x - ci_offset_95\n    upper_bound_95 = lambda x: x + ci_offset_95\n    lower_bound_99 = lambda x: x - ci_offset_99\n    upper_bound_99 = lambda x: x + ci_offset_99\n\n    # Plot points\n    plotted_genes = set()\n    for obs, est, gene, psite in zip(merged_data['Observed_Mean'],\n                                     merged_data['Estimated_Mean'],\n                                     merged_data['GeneID'],\n                                     merged_data['Psite']):\n        color = colors[gene]\n        plt.scatter(obs, est, color=color, edgecolor='black', s=100, marker='o')\n\n        # Add labels only for points outside the 95% CI, ensuring each gene is labeled once\n        if gene not in plotted_genes and (est &gt; upper_bound_95(obs) or est &lt; lower_bound_95(obs)):\n            label = f\"{gene}\"\n            plt.text(obs, est, label, fontsize=10, color=color, fontweight='bold',\n                     ha='center', va='center', bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n            plotted_genes.add(gene)\n\n    # Add straight grey line through origin diagonal\n    x_vals = [min(merged_data['Observed_Mean'].min(), merged_data['Estimated_Mean'].min()),\n              max(merged_data['Observed_Mean'].max(), merged_data['Estimated_Mean'].max())]\n    plt.plot(x_vals, x_vals, color='grey', linestyle='-', linewidth=1.5)\n\n    # Add dashed 95% CI lines in red parallel to the diagonal\n    plt.plot(x_vals, [upper_bound_95(x) for x in x_vals], color='red', linestyle='--', linewidth=1, label='95% CI')\n    plt.plot(x_vals, [lower_bound_95(x) for x in x_vals], color='red', linestyle='--', linewidth=1)\n\n    # Add dashed 99% CI lines in grey parallel to the diagonal\n    plt.plot(x_vals, [upper_bound_99(x) for x in x_vals], color='gray', linestyle='--', linewidth=1, label='99% CI')\n    plt.plot(x_vals, [lower_bound_99(x) for x in x_vals], color='gray', linestyle='--', linewidth=1)\n\n    # Add labels and grid\n    plt.xlabel(\"Observed\")\n    plt.ylabel(\"Fitted\")\n    plt.title(\"\")\n    plt.legend(loc='best', fontsize='small', ncol=2)\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/gof_5.png\", dpi=300)\n    plt.close()\n\n    # Goodness of Fit: Overall with sorting by values directly in the loop\n    plt.figure(figsize=(8, 8))\n\n    # Define the color palette for distinct colors\n    palette = sns.color_palette(\"tab20\", len(merged_data))\n    colors = {gene: palette[i] for i, gene in enumerate(merged_data['GeneID'].unique())}\n\n    # Calculate 95% and 99% CI bounds\n    ci_offset_95 = 1.96 * merged_data['Observed_Mean'].std()\n    ci_offset_99 = 2.576 * merged_data['Observed_Mean'].std()\n\n    lower_bound_95 = lambda x: x - ci_offset_95\n    upper_bound_95 = lambda x: x + ci_offset_95\n    lower_bound_99 = lambda x: x - ci_offset_99\n    upper_bound_99 = lambda x: x + ci_offset_99\n\n    # Sort observed and estimated values while iterating\n    plotted_genes = set()\n    sorted_indices = np.argsort(merged_data['Observed_Mean'].values)\n    for idx in sorted_indices:\n        obs = merged_data['Observed_Mean'].iloc[idx]\n        est = merged_data['Estimated_Mean'].iloc[idx]\n        gene = merged_data['GeneID'].iloc[idx]\n        # psite = merged_data['Psite'].iloc[idx]\n\n        color = colors[gene]\n        plt.scatter(obs, est, color=color, edgecolor='black', s=100, marker='o')\n\n        # Add labels only for points outside the 95% CI, ensuring each gene is labeled once\n        if gene not in plotted_genes and (est &gt; upper_bound_95(obs) or est &lt; lower_bound_95(obs)):\n            label = f\"{gene}\"\n            plt.text(obs, est, label, fontsize=10, color=color, fontweight='bold',\n                     ha='center', va='center', bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n            plotted_genes.add(gene)\n\n    # Add straight grey line through origin diagonal\n    x_vals = [merged_data['Observed_Mean'].min(), merged_data['Observed_Mean'].max()]\n    plt.plot(x_vals, x_vals, color='grey', linestyle='-', linewidth=1.5)\n\n    # Add dashed 95% CI lines in red parallel to the diagonal\n    plt.plot(x_vals, [upper_bound_95(x) for x in x_vals], color='red', linestyle='--', linewidth=1, label='95% CI')\n    plt.plot(x_vals, [lower_bound_95(x) for x in x_vals], color='red', linestyle='--', linewidth=1)\n\n    # Add dashed 99% CI lines in grey parallel to the diagonal\n    plt.plot(x_vals, [upper_bound_99(x) for x in x_vals], color='gray', linestyle='--', linewidth=1, label='99% CI')\n    plt.plot(x_vals, [lower_bound_99(x) for x in x_vals], color='gray', linestyle='--', linewidth=1)\n\n    # Expand the axes limits slightly to include all points without clipping\n    x_min = merged_data['Observed_Mean'].min() - 0.1 * (\n                merged_data['Observed_Mean'].max() - merged_data['Observed_Mean'].min())\n    x_max = merged_data['Observed_Mean'].max() + 0.1 * (\n                merged_data['Observed_Mean'].max() - merged_data['Observed_Mean'].min())\n    y_min = merged_data['Estimated_Mean'].min() - 0.1 * (\n                merged_data['Estimated_Mean'].max() - merged_data['Estimated_Mean'].min())\n    y_max = merged_data['Estimated_Mean'].max() + 0.1 * (\n                merged_data['Estimated_Mean'].max() - merged_data['Estimated_Mean'].min())\n    plt.xlim(x_min, x_max)\n    plt.ylim(y_min, y_max)\n\n    # Add labels and grid\n    plt.xlabel(\"Observed\")\n    plt.ylabel(\"Fitted\")\n    plt.title(\"\")\n    plt.legend(loc='best', fontsize='small', ncol=2)\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/gof_6.png\", dpi=300)\n    plt.close()\n\n    # KL Divergence\n    normalized_obs = merged_data.loc[:, 'x1_obs':'x14_obs'].div(merged_data.loc[:, 'x1_obs':'x14_obs'].sum(axis=1),\n                                                                axis=0)\n    normalized_est = merged_data.loc[:, 'x1_est':'x14_est'].div(merged_data.loc[:, 'x1_est':'x14_est'].sum(axis=1),\n                                                                axis=0)\n    kl_divergence = normalized_obs.apply(lambda row: entropy(row, normalized_est.loc[row.name]), axis=1)\n\n    # Sort before plotting\n    kl_divergence_df = merged_data[['GeneID', 'Psite']].copy()\n    kl_divergence_df['KL'] = kl_divergence.values\n    kl_divergence_by_gene = kl_divergence_df.groupby('GeneID')['KL'].mean().sort_values()\n\n    plt.figure(figsize=(8, 8))\n\n    # Ensure distinct values for index (GeneID) on x-axis\n    indices = kl_divergence_by_gene.index.tolist()\n    values = kl_divergence_by_gene.values\n\n    plt.scatter(indices, values, marker='s', linestyle='-', color='blue', label=r\"$\\bar{x}$\")\n    plt.xticks(rotation=45, ha='right')  # Rotate and align x-axis labels\n    plt.ylabel(\"Entropy\")\n    plt.title('')\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(f'{OUT_DIR}/kld.png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#kinopt.fitanalysis.helpers.postfit.important_connections","title":"<code>important_connections(output_dir, data, top_n=20)</code>","text":"<p>Extracts the top N most important connections based on their absolute values and saves them to a CSV file.</p> <p>:param output_dir: str     The directory where the CSV file will be saved. :param data: pd.DataFrame     A DataFrame containing the connections with columns 'Source', 'Target', and 'Value'. :param top_n: int, optional     The number of top connections to extract (default is 20).</p> <p>The function sorts the connections by their absolute values in descending order, selects the top N connections, and saves them to a CSV file named 'top_connections.csv' in the specified output directory.</p> Source code in <code>kinopt/fitanalysis/helpers/postfit.py</code> <pre><code>def important_connections(output_dir, data, top_n=20):\n    \"\"\"\n    Extracts the top N most important connections based on their absolute values\n    and saves them to a CSV file.\n\n    :param output_dir: str\n        The directory where the CSV file will be saved.\n    :param data: pd.DataFrame\n        A DataFrame containing the connections with columns 'Source', 'Target', and 'Value'.\n    :param top_n: int, optional\n        The number of top connections to extract (default is 20).\n\n    The function sorts the connections by their absolute values in descending order,\n    selects the top N connections, and saves them to a CSV file named 'top_connections.csv'\n    in the specified output directory.\n    \"\"\"\n\n    sorted_edges = data.sort_values(by=\"Value\", key=abs, ascending=False).head(top_n)\n    important_connections = sorted_edges[[\"Source\", \"Target\", \"Value\"]]\n    important_connections.to_csv(f\"{output_dir}/top_connections.csv\", index=False)\n</code></pre>"},{"location":"reference/#kinopt.fitanalysis.helpers.postfit.perform_pca","title":"<code>perform_pca(df)</code>","text":"<p>Perform PCA analysis on the given DataFrame. The DataFrame should contain a 'Value' column for PCA analysis. The function returns a DataFrame with PCA results and additional columns for type and gene/psite information.</p> <p>:param df: DataFrame containing the data for PCA analysis. :return: DataFrame with PCA results and additional columns.</p> Source code in <code>kinopt/fitanalysis/helpers/postfit.py</code> <pre><code>def perform_pca(df):\n    \"\"\"\n    Perform PCA analysis on the given DataFrame.\n    The DataFrame should contain a 'Value' column for PCA analysis.\n    The function returns a DataFrame with PCA results and additional columns for type and gene/psite information.\n\n    :param df: DataFrame containing the data for PCA analysis.\n    :return: DataFrame with PCA results and additional columns.\n    \"\"\"\n    numeric_df = df[['Value']].copy()\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(numeric_df)\n\n    pca = PCA(n_components=1)\n    pca_result = pca.fit_transform(scaled_data)\n\n    pca_df = pd.DataFrame(pca_result, columns=['PCA'])\n    result_df = pd.concat([df[['Parameter']], pca_df], axis=1)\n    result_df['Type'] = result_df['Parameter'].apply(lambda x: 'Alpha' if x.startswith('\u03b1') else 'Beta')\n    result_df['Gene_Psite'] = result_df['Parameter'].str.extract(r'\u03b1_(.*?)_|\u03b2_(.*)')[0].combine_first(\n        result_df['Parameter'].str.extract(r'\u03b2_(.*?)_')[0]\n    )\n    return result_df.sort_values(by=['Gene_Psite', 'Type'])\n</code></pre>"},{"location":"reference/#kinopt.fitanalysis.helpers.postfit.perform_tsne","title":"<code>perform_tsne(scaled_data, df)</code>","text":"<p>Perform t-SNE analysis on the given scaled data. The function returns a DataFrame with t-SNE results and additional columns for type and gene/psite information.</p> <p>:param scaled_data: :param df:</p> <p>:return: - pd.DataFrame: DataFrame with t-SNE results and additional columns.</p> Source code in <code>kinopt/fitanalysis/helpers/postfit.py</code> <pre><code>def perform_tsne(scaled_data, df):\n    \"\"\"\n    Perform t-SNE analysis on the given scaled data.\n    The function returns a DataFrame with t-SNE results and additional columns for type and gene/psite information.\n\n    :param scaled_data:\n    :param df:\n\n    :return:\n    - pd.DataFrame: DataFrame with t-SNE results and additional columns.\n    \"\"\"\n    tsne = TSNE(n_components=1, perplexity=30, max_iter=1000, random_state=42)\n    tsne_result = tsne.fit_transform(scaled_data)\n\n    tsne_df = pd.DataFrame(tsne_result, columns=['tSNE'])\n    tsne_result_df = pd.concat([df[['Parameter']], tsne_df], axis=1)\n    tsne_result_df['Type'] = tsne_result_df['Parameter'].apply(lambda x: 'Alpha' if x.startswith('\u03b1') else 'Beta')\n    tsne_result_df['Gene_Psite'] = tsne_result_df['Parameter'].str.extract(r'\u03b1_(.*?)_|\u03b2_(.*)')[0].combine_first(\n        tsne_result_df['Parameter'].str.extract(r'\u03b2_(.*?)_')[0]\n    )\n    return tsne_result_df.sort_values(by=['Gene_Psite', 'Type'])\n</code></pre>"},{"location":"reference/#kinopt.fitanalysis.helpers.postfit.plot_pca","title":"<code>plot_pca(result_df_sorted, y_axis_column)</code>","text":"<p>Plot PCA or t-SNE results for each gene/psite. The function creates scatter plots with different markers for alpha and beta parameters, and adds labels for each point. The function also adjusts text labels to avoid overlap using the adjustText library.</p> <p>:param result_df_sorted: DataFrame containing PCA or t-SNE results. :param y_axis_column: Column name for the y-axis values in the plot.</p> Source code in <code>kinopt/fitanalysis/helpers/postfit.py</code> <pre><code>def plot_pca(result_df_sorted, y_axis_column):\n    \"\"\"\n    Plot PCA or t-SNE results for each gene/psite.\n    The function creates scatter plots with different markers for alpha and beta parameters,\n    and adds labels for each point.\n    The function also adjusts text labels to avoid overlap using the adjustText library.\n\n    :param result_df_sorted: DataFrame containing PCA or t-SNE results.\n    :param y_axis_column: Column name for the y-axis values in the plot.\n    \"\"\"\n\n    for gene_psite, group in result_df_sorted.groupby('Gene_Psite'):\n        plt.figure(figsize=(8, 8))\n        alpha_marker = '^'\n        beta_marker = 'v'\n\n        texts = []\n        for param_type, marker in [('Alpha', alpha_marker), ('Beta', beta_marker)]:\n            subset = group[group['Type'] == param_type]\n            if not subset.empty:\n                plt.scatter(subset['Parameter'], subset[y_axis_column], alpha=0.7, marker=marker, label=param_type)\n                for _, row in subset.iterrows():\n                    if param_type == 'Alpha':\n                        label = \"_\".join(row['Parameter'].split('_')[2:5])\n                    else:\n                        label = \"_\".join(row['Parameter'].split('_')[1:4])\n                    texts.append(plt.text(row['Parameter'], row[y_axis_column], label, fontsize=8, alpha=0.7))\n\n        adjustText.adjust_text(\n            texts, arrowprops=dict(arrowstyle=\"-\", color='gray', alpha=0.5, lw=0.5, shrinkA=5, shrinkB=5)\n        )\n        plt.title(f'{gene_psite}', fontsize=12)\n        plt.ylabel(y_axis_column, fontsize=8)\n        plt.xticks([])\n        plt.legend(title='Type', fontsize=8)\n        plt.grid(alpha=0.3)\n        plt.tight_layout()\n        plt.savefig(f'{OUT_DIR}/{y_axis_column}_{gene_psite}.png', format='png', dpi=300)\n        plt.close()\n</code></pre>"},{"location":"reference/#kinopt.fitanalysis.helpers.postfit.reshape_alpha_beta","title":"<code>reshape_alpha_beta(alpha_values, beta_values)</code>","text":"<p>Function to reshape alpha and beta values for plotting. It renames columns and creates a new 'Parameter' column for each type of value.</p> <p>:param alpha_values: :param beta_values:</p> <p>:returns: - pd.DataFrame: Reshaped DataFrame containing 'GeneID', 'Value', and 'Parameter' columns.</p> Source code in <code>kinopt/fitanalysis/helpers/postfit.py</code> <pre><code>def reshape_alpha_beta(alpha_values, beta_values):\n    \"\"\"\n    Function to reshape alpha and beta values for plotting.\n    It renames columns and creates a new 'Parameter' column for each type of value.\n\n    :param alpha_values:\n    :param beta_values:\n\n    :returns:\n    - pd.DataFrame: Reshaped DataFrame containing 'GeneID', 'Value', and 'Parameter' columns.\n    \"\"\"\n    alpha_values['Gene'] = alpha_values['Gene'].astype(str)\n    alpha_values['Psite'] = alpha_values['Psite'].astype(str)\n    alpha_values['Kinase'] = alpha_values['Kinase'].astype(str)\n\n    beta_values['Kinase'] = beta_values['Kinase'].astype(str)\n    beta_values['Psite'] = beta_values['Psite'].astype(str)\n\n    alpha_values_reshaped = alpha_values[['Gene', 'Psite', 'Alpha']].rename(\n        columns={'Gene': 'GeneID', 'Alpha': 'Value'})\n    alpha_values_reshaped['Parameter'] = '\u03b1_' + alpha_values['Gene'] + '_' + alpha_values['Psite'] + '_' + \\\n                                         alpha_values['Kinase']\n\n    beta_values_reshaped = beta_values[['Kinase', 'Psite', 'Beta']].rename(\n        columns={'Kinase': 'GeneID', 'Beta': 'Value'})\n    beta_values_reshaped['Parameter'] = '\u03b2_' + beta_values['Kinase'] + '_' + beta_values['Psite']\n\n    return pd.concat([alpha_values_reshaped, beta_values_reshaped], ignore_index=True)\n</code></pre>"},{"location":"reference/#kinopt.local.config.constants.parse_args","title":"<code>parse_args()</code>","text":"<p>Parses command-line arguments for the optimization script. This function uses argparse to handle various parameters related to the optimization process. The parameters include bounds for the optimization, loss function types, estimation of missing kinases, scaling methods for time-series data, and the optimization method to be used. The function returns a tuple containing the parsed arguments.</p> <p>:return: A tuple containing the parsed arguments.     - lower_bound (float): Lower bound for the optimization.     - upper_bound (float): Upper bound for the optimization.     - loss_type (str): Type of loss function to use.     - estimate_missing (bool): Whether to estimate missing kinase-psite values.     - scaling_method (str): Method for scaling time-series data.     - split_point (int): Split point for temporal scaling.     - segment_points (list of int): Segment points for segmented scaling.     - method (str): Optimization method to use.</p> Source code in <code>kinopt/local/config/constants.py</code> <pre><code>def parse_args():\n    \"\"\"\n    Parses command-line arguments for the optimization script.\n    This function uses argparse to handle various parameters related to the optimization process.\n    The parameters include bounds for the optimization, loss function types, estimation of missing kinases,\n    scaling methods for time-series data, and the optimization method to be used.\n    The function returns a tuple containing the parsed arguments.\n\n    :return: A tuple containing the parsed arguments.\n        - lower_bound (float): Lower bound for the optimization.\n        - upper_bound (float): Upper bound for the optimization.\n        - loss_type (str): Type of loss function to use.\n        - estimate_missing (bool): Whether to estimate missing kinase-psite values.\n        - scaling_method (str): Method for scaling time-series data.\n        - split_point (int): Split point for temporal scaling.\n        - segment_points (list of int): Segment points for segmented scaling.\n        - method (str): Optimization method to use.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"PhosKinTime - SLSQP/TRUST-CONSTR Kinase Phosphorylation Optimization Problem prior to ODE Modelling.\"\n    )\n\n    # lower_bound and upper_bound are the bounds for the optimization.\n    parser.add_argument(\"--lower_bound\", type=float, default=-2, help=\"Lower Beta bound.\")\n    parser.add_argument(\"--upper_bound\", type=float, default=2, help=\"Upper Beta bound.\")\n\n    # loss_type is the type of loss function to use.\n    parser.add_argument(\"--loss_type\", type=str,\n                        choices=[\"base\", \"weighted\", \"softl1\", \"cauchy\", \"arctan\"],\n                        default=\"weighted\", help=\"Loss function to use.\")\n\n    # estimate_missing_kinases indicates whether to estimate missing kinase-psite values.\n    parser.add_argument(\"--estimate_missing_kinases\", type=str, choices=[\"yes\", \"no\"], default=\"yes\",\n                        help=\"Estimate missing kinase-psite values?\")\n\n    # scaling_method is the method for scaling time-series data.\n    parser.add_argument(\"--scaling_method\", type=str,\n                        choices=[\"min_max\", \"log\", \"temporal\", \"segmented\", \"slope\", \"cumulative\", \"none\"],\n                        default=\"None\", help=\"Scaling method for time-series data.\")\n\n    # split_point is the split point for temporal scaling.\n    parser.add_argument(\"--split_point\", type=int, default=9, help=\"Split point for temporal scaling.\")\n\n    # segment_points is a list of segment points for segmented scaling.\n    parser.add_argument(\"--segment_points\", type=str, default=\"0,3,6,9,14\",\n                        help=\"Comma-separated segment points for segmented scaling.\")\n\n    # method is the optimization method to use.\n    parser.add_argument(\"--method\", type=str, choices=[\"slsqp\", \"trust-constr\"], default=\"slsqp\",\n                        help=\"Optimization method.\")\n\n    args = parser.parse_args()\n    estimate_missing = args.estimate_missing_kinases == \"yes\"\n    seg_points = list(map(int, args.segment_points.split(\",\"))) if args.scaling_method == \"segmented\" else None\n\n    return (args.lower_bound, args.upper_bound, args.loss_type, estimate_missing,\n            args.scaling_method, args.split_point, seg_points, args.method)\n</code></pre>"},{"location":"reference/#kinopt.local.exporter.plotout.plot_autocorrelation_residuals","title":"<code>plot_autocorrelation_residuals(gene, gene_data, real_timepoints)</code>","text":"<p>Function to plot the autocorrelation of residuals for each psite of a gene. It generates a plot showing the autocorrelation values over time. The plot is saved as a PNG file in the specified output directory.</p> <p>Parameters: gene (str): The name of the gene. gene_data (dict): A dictionary containing the residuals for each psite of the gene. real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.</p> Source code in <code>kinopt/local/exporter/plotout.py</code> <pre><code>def plot_autocorrelation_residuals(gene, gene_data, real_timepoints):\n    \"\"\"\n    Function to plot the autocorrelation of residuals for each psite of a gene.\n    It generates a plot showing the autocorrelation values over time.\n    The plot is saved as a PNG file in the specified output directory.\n\n    Parameters:\n    gene (str): The name of the gene.\n    gene_data (dict): A dictionary containing the residuals for each psite of the gene.\n    real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.\n    \"\"\"\n    plt.figure(figsize=(8, 8))\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        plot_acf(gene_data[\"residuals\"][i], lags=len(real_timepoints) - 1,\n                 alpha=0.03, ax=plt.gca(), label=f\"{psite}\",)\n    plt.title(f\"{gene}\")\n    plt.xlabel(\"Lags\")\n    plt.ylabel(\"Autocorrelation\")\n    plt.tight_layout()\n    filename = f\"{OUT_DIR}/{gene}_autocorrelation_residuals_.png\"\n    plt.savefig(filename, format='png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#kinopt.local.exporter.plotout.plot_cumulative_residuals","title":"<code>plot_cumulative_residuals(gene, gene_data, real_timepoints)</code>","text":"<p>Function to plot the cumulative residuals for each psite of a gene. It generates a plot showing the cumulative residuals over time. The plot is saved as a PNG file in the specified output directory.</p> <p>Parameters: gene (str): The name of the gene. gene_data (dict): A dictionary containing the residuals for each psite of the gene. real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.</p> Source code in <code>kinopt/local/exporter/plotout.py</code> <pre><code>def plot_cumulative_residuals(gene, gene_data, real_timepoints):\n    \"\"\"\n    Function to plot the cumulative residuals for each psite of a gene.\n    It generates a plot showing the cumulative residuals over time.\n    The plot is saved as a PNG file in the specified output directory.\n\n    Parameters:\n    gene (str): The name of the gene.\n    gene_data (dict): A dictionary containing the residuals for each psite of the gene.\n    real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.\n    \"\"\"\n    cmap = plt.get_cmap(\"tab20\")\n    colors = [cmap(i % 20) for i in range(len(gene_data[\"psites\"]))]\n    plt.figure(figsize=(8, 8))\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        plt.plot(real_timepoints, np.cumsum(gene_data[\"residuals\"][i]),\n                 label=f\"{psite}\", marker='o', color=colors[i],\n                 alpha=0.8, markeredgecolor='black')\n    plt.title(f\"{gene}\")\n    plt.xlabel(\"Time (minutes)\")\n    plt.ylabel(\"Cumulative Residuals\")\n    plt.grid(True, alpha=0.2)\n    plt.legend(title=\"Residue_Position\")\n    plt.tight_layout()\n    filename = f\"{OUT_DIR}/{gene}_cumulative_residuals_.png\"\n    plt.savefig(filename, format='png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#kinopt.local.exporter.plotout.plot_fits_for_gene","title":"<code>plot_fits_for_gene(gene, gene_data, real_timepoints)</code>","text":"<p>Function to plot the observed and estimated phosphorylation levels for a gene. It generates two plots: 1. A full timepoints plot showing all timepoints. 2. A short timepoints plot showing only the first 7 timepoints. The plots are saved as PNG files in the specified output directory.</p> <p>Parameters: gene (str): The name of the gene. gene_data (dict): A dictionary containing the observed and estimated phosphorylation levels for the gene. real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.</p> Source code in <code>kinopt/local/exporter/plotout.py</code> <pre><code>def plot_fits_for_gene(gene, gene_data, real_timepoints):\n    \"\"\"\n    Function to plot the observed and estimated phosphorylation levels for a gene.\n    It generates two plots:\n    1. A full timepoints plot showing all timepoints.\n    2. A short timepoints plot showing only the first 7 timepoints.\n    The plots are saved as PNG files in the specified output directory.\n\n    Parameters:\n    gene (str): The name of the gene.\n    gene_data (dict): A dictionary containing the observed and estimated phosphorylation levels for the gene.\n    real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.\n    \"\"\"\n    # Get colors from Dark2 palette\n    cmap = mpl.cm.get_cmap(\"Dark2\")\n    # cmap = mpl.cm.get_cmap(\"Set1\")\n    # cmap = mpl.cm.get_cmap(\"Set2\")\n\n    colors = [cmap(i % 20) for i in range(len(gene_data[\"psites\"]))]\n\n    fig, axs = plt.subplots(1, 2, figsize=(18, 8), sharey=True)\n\n    # Full timepoints plot\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        axs[0].plot(real_timepoints, gene_data[\"observed\"][i],\n                    label=f\"{psite}\", marker='s', linestyle='--',\n                    color=colors[i], alpha=0.5, markeredgecolor='black')\n        axs[0].plot(real_timepoints, gene_data[\"estimated\"][i],\n                    linestyle='-', color=colors[i])\n    axs[0].set_title(f\"{gene}\")\n    axs[0].set_xlabel(\"Time (minutes)\")\n    axs[0].set_ylabel(\"Phosphorylation Level (FC)\")\n    axs[0].grid(True, alpha=0.2)\n    axs[0].set_xticks(real_timepoints[9:])\n\n    # First 7 timepoints plot\n    short_timepoints = real_timepoints[:7]\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        axs[1].plot(short_timepoints, gene_data[\"observed\"][i][:7],\n                    label=f\"{psite}\", marker='s', linestyle='--',\n                    color=colors[i], alpha=0.5, markeredgecolor='black')\n        axs[1].plot(short_timepoints, gene_data[\"estimated\"][i][:7],\n                    linestyle='-', color=colors[i])\n    # axs[1].set_title(f\"{gene}\")\n    axs[1].set_xlabel(\"Time (minutes)\")\n    axs[1].grid(True, alpha=0.2)\n    axs[1].set_xticks(short_timepoints)\n    axs[1].legend(title=\"Residue_Position\", bbox_to_anchor=(1.05, 1), loc='upper left')\n    plt.tight_layout()\n    filename = f\"{OUT_DIR}/{gene}_fit_.png\"\n    plt.savefig(filename, dpi=300, bbox_inches='tight')\n    plt.close()\n</code></pre>"},{"location":"reference/#kinopt.local.exporter.plotout.plot_histogram_residuals","title":"<code>plot_histogram_residuals(gene, gene_data, real_timepoints)</code>","text":"<p>Function to plot histograms of residuals for each psite of a gene. It generates a histogram showing the distribution of residuals. The plot is saved as a PNG file in the specified output directory.</p> <p>Parameters: gene (str): The name of the gene. gene_data (dict): A dictionary containing the residuals for each psite of the gene. real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.</p> Source code in <code>kinopt/local/exporter/plotout.py</code> <pre><code>def plot_histogram_residuals(gene, gene_data, real_timepoints):\n    \"\"\"\n    Function to plot histograms of residuals for each psite of a gene.\n    It generates a histogram showing the distribution of residuals.\n    The plot is saved as a PNG file in the specified output directory.\n\n    Parameters:\n    gene (str): The name of the gene.\n    gene_data (dict): A dictionary containing the residuals for each psite of the gene.\n    real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.\n    \"\"\"\n    cmap = plt.get_cmap(\"tab20\")\n    colors = [cmap(i % 20) for i in range(len(gene_data[\"psites\"]))]\n    plt.figure(figsize=(8, 8))\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        sns.histplot(gene_data[\"residuals\"][i], bins=20, kde=True,\n                     color=colors[i], label=f\"{psite}\", alpha=0.8)\n    plt.title(f\"{gene}\")\n    plt.xlabel(\"Residuals\")\n    plt.ylabel(\"Frequency\")\n    plt.grid(True, alpha=0.2)\n    plt.legend(title=\"Residue_Position\")\n    plt.tight_layout()\n    filename = f\"{OUT_DIR}/{gene}_histogram_residuals_.png\"\n    plt.savefig(filename, format='png', dpi=300)\n    plt.close() \n</code></pre>"},{"location":"reference/#kinopt.local.exporter.plotout.plot_qqplot_residuals","title":"<code>plot_qqplot_residuals(gene, gene_data, real_timepoints)</code>","text":"<p>Function to plot QQ plots of residuals for each psite of a gene. It generates a QQ plot showing the quantiles of the residuals against the quantiles of a normal distribution. The plot is saved as a PNG file in the specified output directory.</p> <p>Parameters: gene (str): The name of the gene. gene_data (dict): A dictionary containing the residuals for each psite of the gene. real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.</p> Source code in <code>kinopt/local/exporter/plotout.py</code> <pre><code>def plot_qqplot_residuals(gene, gene_data, real_timepoints):\n    \"\"\"\n    Function to plot QQ plots of residuals for each psite of a gene.\n    It generates a QQ plot showing the quantiles of the residuals against the quantiles of a normal distribution.\n    The plot is saved as a PNG file in the specified output directory.\n\n    Parameters:\n    gene (str): The name of the gene.\n    gene_data (dict): A dictionary containing the residuals for each psite of the gene.\n    real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.\n    \"\"\"\n    plt.figure(figsize=(8, 8))\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        qqplot(gene_data[\"residuals\"][i], line='s', ax=plt.gca())\n    plt.title(f\"{gene}\")\n    plt.tight_layout()\n    filename = f\"{OUT_DIR}/{gene}_qqplot_residuals_.png\"\n    plt.savefig(filename, format='png', dpi=300)\n    plt.close('all')\n</code></pre>"},{"location":"reference/#kinopt.local.exporter.sheetutils.output_results","title":"<code>output_results(P_initial, P_init_dense, P_estimated, residuals, alpha_values, beta_values, result, mse, rmse, mae, mape, r_squared)</code>","text":"<p>Function to output the results of the optimization process. It logs the optimized alpha and beta values, optimization summary, error metrics, and generates plots for each gene. It also writes the results to an Excel file with multiple sheets.</p> <p>The sheets include: - Alpha Values: Optimized alpha values for each gene and psite. - Beta Values: Optimized beta values for each kinase and psite. - Summary: Summary of the optimization process. - Observed: Observed time-series data for each gene and psite. - Estimated: Estimated time-series data for each gene and psite. - Residuals: Residuals for each gene and psite.</p> <p>:param P_initial: :param P_init_dense: :param P_estimated: :param residuals: :param alpha_values: :param beta_values: :param result: :param mse: :param rmse: :param mae: :param mape: :param r_squared:</p> Source code in <code>kinopt/local/exporter/sheetutils.py</code> <pre><code>def output_results(P_initial, P_init_dense, P_estimated, residuals, alpha_values, beta_values,\n                   result, mse, rmse, mae, mape, r_squared):\n    \"\"\"\n    Function to output the results of the optimization process.\n    It logs the optimized alpha and beta values, optimization summary,\n    error metrics, and generates plots for each gene.\n    It also writes the results to an Excel file with multiple sheets.\n\n    The sheets include:\n    - Alpha Values: Optimized alpha values for each gene and psite.\n    - Beta Values: Optimized beta values for each kinase and psite.\n    - Summary: Summary of the optimization process.\n    - Observed: Observed time-series data for each gene and psite.\n    - Estimated: Estimated time-series data for each gene and psite.\n    - Residuals: Residuals for each gene and psite.\n\n    :param P_initial:\n    :param P_init_dense:\n    :param P_estimated:\n    :param residuals:\n    :param alpha_values:\n    :param beta_values:\n    :param result:\n    :param mse:\n    :param rmse:\n    :param mae:\n    :param mape:\n    :param r_squared:\n    \"\"\"\n    logger.info(\"Optimized Alpha values:\")\n    for (gene, psite), kinases in alpha_values.items():\n        logger.info(f\"Protein {gene}, Psite {psite}:\")\n        for kinase, value in kinases.items():\n            logger.info(f\"  Kinase {kinase}: {value:.2f}\")\n    logger.info(\"Optimized Beta values:\")\n    for (kinase, psite), value in beta_values.items():\n        logger.info(f\"Kinase {kinase}, Psite {psite}: {value:.2f}\")\n    logger.info(\"--- Optimization Summary ---\")\n    logger.info(f\"Success: {'Success' if result.success else 'Failure'}\")\n    logger.info(f\"Message: {result.message}\")\n    logger.info(f\"Iterations: {result.nit}\")\n    logger.info(f\"Function Evaluations: {result.nfev}\")\n    logger.info(f\"SSE: {result.fun:.2f}\")\n    logger.info(\"--- Error Metrics ---\")\n    logger.info(f\"MSE: {mse:.2f}\")\n    logger.info(f\"RMSE: {rmse:.2f}\")\n    logger.info(f\"MAE: {mae:.2f}\")\n    logger.info(f\"MAPE: {mape:.2f}%\")\n    logger.info(f\"R-squared: {r_squared:.2f}\")\n\n    # Build a genes_data dictionary from computed metrics.\n    genes_data = build_genes_data(P_initial, P_init_dense, P_estimated, residuals)\n\n    # For each gene, call the plotting functions.\n    for gene, data in genes_data.items():\n        plot_fits_for_gene(gene, data, TIME_POINTS)\n        plot_cumulative_residuals(gene, data, TIME_POINTS)\n        plot_autocorrelation_residuals(gene, data, TIME_POINTS)\n        plot_histogram_residuals(gene, data, TIME_POINTS)\n        plot_qqplot_residuals(gene, data, TIME_POINTS)\n\n    # Write results to Excel.\n    output_file = OUT_FILE\n    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n        alpha_list = []\n        for (gene, psite), kinases in alpha_values.items():\n            for kinase, value in kinases.items():\n                alpha_list.append({'Gene': gene, 'Psite': psite, 'Kinase': kinase, 'Alpha': value})\n        pd.DataFrame(alpha_list).to_excel(writer, sheet_name=\"Alpha Values\", index=False)\n\n        beta_list = []\n        for (kinase, psite), value in beta_values.items():\n            beta_list.append({'Kinase': kinase, 'Psite': psite, 'Beta': value})\n        pd.DataFrame(beta_list).to_excel(writer, sheet_name=\"Beta Values\", index=False)\n\n        summary = {\n            'Metric': [\"Success\", \"Message\", \"Iterations\", \"Function Evaluations\", \"SSE\", \"MSE\", \"RMSE\", \"MAE\", \"MAPE\",\n                       \"R-squared\"],\n            'Value': [(\"Success\" if result.success else \"Failure\"), result.message, result.nit, result.nfev, result.fun,\n                      mse, rmse, mae, mape, r_squared]\n        }\n        pd.DataFrame(summary).to_excel(writer, sheet_name=\"Summary\", index=False)\n\n        timepoints = [f'x{i + 1}' for i in range(P_init_dense.shape[1])]\n\n        # For Observed sheet: use \"GeneID\" as the column name.\n        observed_keys_df = pd.DataFrame(list(P_initial.keys()), columns=[\"GeneID\", \"Psite\"])\n        observed_df = pd.DataFrame(P_init_dense, columns=timepoints)\n        observed_df = pd.concat([observed_keys_df, observed_df], axis=1)\n        observed_df.to_excel(writer, sheet_name=\"Observed\", index=False)\n\n        # For Estimated sheet: use \"gene\" as the column name.\n        estimated_keys_df = pd.DataFrame(list(P_initial.keys()), columns=[\"Gene\", \"Psite\"])\n        estimated_df = pd.DataFrame(P_estimated, columns=timepoints)\n        estimated_df = pd.concat([estimated_keys_df, estimated_df], axis=1)\n        estimated_df.to_excel(writer, sheet_name=\"Estimated\", index=False)\n\n        # For Residuals sheet: use \"gene\" as the column name.\n        residuals_keys_df = pd.DataFrame(list(P_initial.keys()), columns=[\"Gene\", \"Psite\"])\n        residuals_df = pd.DataFrame(residuals, columns=timepoints)\n        residuals_df = pd.concat([residuals_keys_df, residuals_df], axis=1)\n        residuals_df.to_excel(writer, sheet_name=\"Residuals\", index=False)\n\n    logger.info(f\"Optimization results saved for ODE modelling.\")\n</code></pre>"},{"location":"reference/#kinopt.local.exporter.sheetutils.plot_autocorrelation_residuals","title":"<code>plot_autocorrelation_residuals(gene, gene_data, real_timepoints)</code>","text":"<p>Function to plot the autocorrelation of residuals for each psite of a gene. It generates a plot showing the autocorrelation values over time. The plot is saved as a PNG file in the specified output directory.</p> <p>Parameters: gene (str): The name of the gene. gene_data (dict): A dictionary containing the residuals for each psite of the gene. real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.</p> Source code in <code>kinopt/local/exporter/plotout.py</code> <pre><code>def plot_autocorrelation_residuals(gene, gene_data, real_timepoints):\n    \"\"\"\n    Function to plot the autocorrelation of residuals for each psite of a gene.\n    It generates a plot showing the autocorrelation values over time.\n    The plot is saved as a PNG file in the specified output directory.\n\n    Parameters:\n    gene (str): The name of the gene.\n    gene_data (dict): A dictionary containing the residuals for each psite of the gene.\n    real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.\n    \"\"\"\n    plt.figure(figsize=(8, 8))\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        plot_acf(gene_data[\"residuals\"][i], lags=len(real_timepoints) - 1,\n                 alpha=0.03, ax=plt.gca(), label=f\"{psite}\",)\n    plt.title(f\"{gene}\")\n    plt.xlabel(\"Lags\")\n    plt.ylabel(\"Autocorrelation\")\n    plt.tight_layout()\n    filename = f\"{OUT_DIR}/{gene}_autocorrelation_residuals_.png\"\n    plt.savefig(filename, format='png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#kinopt.local.exporter.sheetutils.plot_cumulative_residuals","title":"<code>plot_cumulative_residuals(gene, gene_data, real_timepoints)</code>","text":"<p>Function to plot the cumulative residuals for each psite of a gene. It generates a plot showing the cumulative residuals over time. The plot is saved as a PNG file in the specified output directory.</p> <p>Parameters: gene (str): The name of the gene. gene_data (dict): A dictionary containing the residuals for each psite of the gene. real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.</p> Source code in <code>kinopt/local/exporter/plotout.py</code> <pre><code>def plot_cumulative_residuals(gene, gene_data, real_timepoints):\n    \"\"\"\n    Function to plot the cumulative residuals for each psite of a gene.\n    It generates a plot showing the cumulative residuals over time.\n    The plot is saved as a PNG file in the specified output directory.\n\n    Parameters:\n    gene (str): The name of the gene.\n    gene_data (dict): A dictionary containing the residuals for each psite of the gene.\n    real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.\n    \"\"\"\n    cmap = plt.get_cmap(\"tab20\")\n    colors = [cmap(i % 20) for i in range(len(gene_data[\"psites\"]))]\n    plt.figure(figsize=(8, 8))\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        plt.plot(real_timepoints, np.cumsum(gene_data[\"residuals\"][i]),\n                 label=f\"{psite}\", marker='o', color=colors[i],\n                 alpha=0.8, markeredgecolor='black')\n    plt.title(f\"{gene}\")\n    plt.xlabel(\"Time (minutes)\")\n    plt.ylabel(\"Cumulative Residuals\")\n    plt.grid(True, alpha=0.2)\n    plt.legend(title=\"Residue_Position\")\n    plt.tight_layout()\n    filename = f\"{OUT_DIR}/{gene}_cumulative_residuals_.png\"\n    plt.savefig(filename, format='png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#kinopt.local.exporter.sheetutils.plot_fits_for_gene","title":"<code>plot_fits_for_gene(gene, gene_data, real_timepoints)</code>","text":"<p>Function to plot the observed and estimated phosphorylation levels for a gene. It generates two plots: 1. A full timepoints plot showing all timepoints. 2. A short timepoints plot showing only the first 7 timepoints. The plots are saved as PNG files in the specified output directory.</p> <p>Parameters: gene (str): The name of the gene. gene_data (dict): A dictionary containing the observed and estimated phosphorylation levels for the gene. real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.</p> Source code in <code>kinopt/local/exporter/plotout.py</code> <pre><code>def plot_fits_for_gene(gene, gene_data, real_timepoints):\n    \"\"\"\n    Function to plot the observed and estimated phosphorylation levels for a gene.\n    It generates two plots:\n    1. A full timepoints plot showing all timepoints.\n    2. A short timepoints plot showing only the first 7 timepoints.\n    The plots are saved as PNG files in the specified output directory.\n\n    Parameters:\n    gene (str): The name of the gene.\n    gene_data (dict): A dictionary containing the observed and estimated phosphorylation levels for the gene.\n    real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.\n    \"\"\"\n    # Get colors from Dark2 palette\n    cmap = mpl.cm.get_cmap(\"Dark2\")\n    # cmap = mpl.cm.get_cmap(\"Set1\")\n    # cmap = mpl.cm.get_cmap(\"Set2\")\n\n    colors = [cmap(i % 20) for i in range(len(gene_data[\"psites\"]))]\n\n    fig, axs = plt.subplots(1, 2, figsize=(18, 8), sharey=True)\n\n    # Full timepoints plot\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        axs[0].plot(real_timepoints, gene_data[\"observed\"][i],\n                    label=f\"{psite}\", marker='s', linestyle='--',\n                    color=colors[i], alpha=0.5, markeredgecolor='black')\n        axs[0].plot(real_timepoints, gene_data[\"estimated\"][i],\n                    linestyle='-', color=colors[i])\n    axs[0].set_title(f\"{gene}\")\n    axs[0].set_xlabel(\"Time (minutes)\")\n    axs[0].set_ylabel(\"Phosphorylation Level (FC)\")\n    axs[0].grid(True, alpha=0.2)\n    axs[0].set_xticks(real_timepoints[9:])\n\n    # First 7 timepoints plot\n    short_timepoints = real_timepoints[:7]\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        axs[1].plot(short_timepoints, gene_data[\"observed\"][i][:7],\n                    label=f\"{psite}\", marker='s', linestyle='--',\n                    color=colors[i], alpha=0.5, markeredgecolor='black')\n        axs[1].plot(short_timepoints, gene_data[\"estimated\"][i][:7],\n                    linestyle='-', color=colors[i])\n    # axs[1].set_title(f\"{gene}\")\n    axs[1].set_xlabel(\"Time (minutes)\")\n    axs[1].grid(True, alpha=0.2)\n    axs[1].set_xticks(short_timepoints)\n    axs[1].legend(title=\"Residue_Position\", bbox_to_anchor=(1.05, 1), loc='upper left')\n    plt.tight_layout()\n    filename = f\"{OUT_DIR}/{gene}_fit_.png\"\n    plt.savefig(filename, dpi=300, bbox_inches='tight')\n    plt.close()\n</code></pre>"},{"location":"reference/#kinopt.local.exporter.sheetutils.plot_histogram_residuals","title":"<code>plot_histogram_residuals(gene, gene_data, real_timepoints)</code>","text":"<p>Function to plot histograms of residuals for each psite of a gene. It generates a histogram showing the distribution of residuals. The plot is saved as a PNG file in the specified output directory.</p> <p>Parameters: gene (str): The name of the gene. gene_data (dict): A dictionary containing the residuals for each psite of the gene. real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.</p> Source code in <code>kinopt/local/exporter/plotout.py</code> <pre><code>def plot_histogram_residuals(gene, gene_data, real_timepoints):\n    \"\"\"\n    Function to plot histograms of residuals for each psite of a gene.\n    It generates a histogram showing the distribution of residuals.\n    The plot is saved as a PNG file in the specified output directory.\n\n    Parameters:\n    gene (str): The name of the gene.\n    gene_data (dict): A dictionary containing the residuals for each psite of the gene.\n    real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.\n    \"\"\"\n    cmap = plt.get_cmap(\"tab20\")\n    colors = [cmap(i % 20) for i in range(len(gene_data[\"psites\"]))]\n    plt.figure(figsize=(8, 8))\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        sns.histplot(gene_data[\"residuals\"][i], bins=20, kde=True,\n                     color=colors[i], label=f\"{psite}\", alpha=0.8)\n    plt.title(f\"{gene}\")\n    plt.xlabel(\"Residuals\")\n    plt.ylabel(\"Frequency\")\n    plt.grid(True, alpha=0.2)\n    plt.legend(title=\"Residue_Position\")\n    plt.tight_layout()\n    filename = f\"{OUT_DIR}/{gene}_histogram_residuals_.png\"\n    plt.savefig(filename, format='png', dpi=300)\n    plt.close() \n</code></pre>"},{"location":"reference/#kinopt.local.exporter.sheetutils.plot_qqplot_residuals","title":"<code>plot_qqplot_residuals(gene, gene_data, real_timepoints)</code>","text":"<p>Function to plot QQ plots of residuals for each psite of a gene. It generates a QQ plot showing the quantiles of the residuals against the quantiles of a normal distribution. The plot is saved as a PNG file in the specified output directory.</p> <p>Parameters: gene (str): The name of the gene. gene_data (dict): A dictionary containing the residuals for each psite of the gene. real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.</p> Source code in <code>kinopt/local/exporter/plotout.py</code> <pre><code>def plot_qqplot_residuals(gene, gene_data, real_timepoints):\n    \"\"\"\n    Function to plot QQ plots of residuals for each psite of a gene.\n    It generates a QQ plot showing the quantiles of the residuals against the quantiles of a normal distribution.\n    The plot is saved as a PNG file in the specified output directory.\n\n    Parameters:\n    gene (str): The name of the gene.\n    gene_data (dict): A dictionary containing the residuals for each psite of the gene.\n    real_timepoints (list): A list of timepoints corresponding to the observed and estimated data.\n    \"\"\"\n    plt.figure(figsize=(8, 8))\n    for i, psite in enumerate(gene_data[\"psites\"]):\n        qqplot(gene_data[\"residuals\"][i], line='s', ax=plt.gca())\n    plt.title(f\"{gene}\")\n    plt.tight_layout()\n    filename = f\"{OUT_DIR}/{gene}_qqplot_residuals_.png\"\n    plt.savefig(filename, format='png', dpi=300)\n    plt.close('all')\n</code></pre>"},{"location":"reference/#kinopt.local.opt.optrun.run_optimization","title":"<code>run_optimization(obj_fun, params_initial, opt_method, bounds, constraints)</code>","text":"<p>Run optimization using the specified method.</p> <p>:param obj_fun: :param params_initial: :param opt_method: :param bounds: :param constraints: :return: result, optimized parameters</p> Source code in <code>kinopt/local/opt/optrun.py</code> <pre><code>def run_optimization(obj_fun, params_initial, opt_method, bounds, constraints):\n    \"\"\"\n    Run optimization using the specified method.\n\n    :param obj_fun:\n    :param params_initial:\n    :param opt_method:\n    :param bounds:\n    :param constraints:\n    :return: result, optimized parameters\n    \"\"\"\n    result = minimize(obj_fun, params_initial, method=opt_method,\n                      bounds=bounds, constraints=constraints,\n                      options={'maxiter': 20000, 'verbose': 3} if opt_method == \"trust-constr\" else {'maxiter': 20000})\n    return result, result.x\n</code></pre>"},{"location":"reference/#kinopt.local.utils.iodata.apply_scaling","title":"<code>apply_scaling(df, cols, method, split_point, seg_points)</code>","text":"<p>Apply scaling to the specified columns of a DataFrame based on the given method. The scaling methods include: - 'min_max': Min-Max scaling - 'log': Logarithmic scaling - 'temporal': Temporal scaling (two segments) - 'segmented': Segmented scaling (multiple segments) - 'slope': Slope scaling - 'cumulative': Cumulative scaling</p> <p>:param df: :param cols: :param method: :param split_point: :param seg_points: :return: df</p> Source code in <code>kinopt/local/utils/iodata.py</code> <pre><code>def apply_scaling(df, cols, method, split_point, seg_points):\n    \"\"\"\n    Apply scaling to the specified columns of a DataFrame based on the given method.\n    The scaling methods include:\n    - 'min_max': Min-Max scaling\n    - 'log': Logarithmic scaling\n    - 'temporal': Temporal scaling (two segments)\n    - 'segmented': Segmented scaling (multiple segments)\n    - 'slope': Slope scaling\n    - 'cumulative': Cumulative scaling\n\n    :param df:\n    :param cols:\n    :param method:\n    :param split_point:\n    :param seg_points:\n    :return: df\n    \"\"\"\n    if method == 'min_max':\n        scaler = MinMaxScaler()\n        df[cols] = pd.DataFrame(df[cols].apply(lambda r: scaler.fit_transform(r.values.reshape(-1, 1)).flatten(), axis=1).tolist(), index=df.index)\n    elif method == 'log':\n        df[cols] = df[cols].applymap(np.log)\n    elif method == 'temporal':\n        first, second = cols[:split_point], cols[split_point:]\n        scaler1, scaler2 = MinMaxScaler(), MinMaxScaler()\n        df[first] = scaler1.fit_transform(df[first])\n        df[second] = scaler2.fit_transform(df[second])\n    elif method == 'segmented':\n        if not seg_points:\n            raise ValueError(\"Segment points must be provided.\")\n        for seg in [cols[seg_points[i]:seg_points[i+1]] for i in range(len(seg_points)-1)]:\n            df[seg] = MinMaxScaler().fit_transform(df[seg])\n    elif method == 'slope':\n        df[cols] = MinMaxScaler().fit_transform(df[cols].diff(axis=1).fillna(0))\n    elif method == 'cumulative':\n        df[cols] = MinMaxScaler().fit_transform(df[cols].cumsum(axis=1))\n    return df\n</code></pre>"},{"location":"reference/#kinopt.local.utils.iodata.create_report","title":"<code>create_report(results_dir, output_file='report.html')</code>","text":"<p>Creates a single global report HTML file from all gene folders inside the results directory.</p> <p>For each gene folder (e.g. \"ABL2\"), the report will include:   - All PNG plots and interactive HTML plots displayed in a grid with three plots per row.   - Each plot is confined to a fixed size of 900px by 900px.   - Data tables from XLSX or CSV files in the gene folder are displayed below the plots, one per row.</p> <p>Parameters:</p> Name Type Description Default <code>results_dir</code> <code>str</code> <p>Path to the root results directory.</p> required <code>output_file</code> <code>str</code> <p>Name of the generated global report file (placed inside results_dir).</p> <code>'report.html'</code> Source code in <code>kinopt/local/utils/iodata.py</code> <pre><code>def create_report(results_dir: str, output_file: str = \"report.html\"):\n    \"\"\"\n    Creates a single global report HTML file from all gene folders inside the results directory.\n\n    For each gene folder (e.g. \"ABL2\"), the report will include:\n      - All PNG plots and interactive HTML plots displayed in a grid with three plots per row.\n      - Each plot is confined to a fixed size of 900px by 900px.\n      - Data tables from XLSX or CSV files in the gene folder are displayed below the plots, one per row.\n\n    Args:\n        results_dir (str): Path to the root results directory.\n        output_file (str): Name of the generated global report file (placed inside results_dir).\n    \"\"\"\n    # Gather gene folders (skip \"General\" and \"logs\")\n    gene_folders = [\n        d for d in os.listdir(results_dir)\n        if os.path.isdir(os.path.join(results_dir, d)) and d not in (\"General\", \"logs\")\n    ]\n\n    # Build HTML content with updated CSS for spacing.\n    html_parts = [\n        \"&lt;html&gt;\",\n        \"&lt;head&gt;\",\n        \"&lt;meta charset='UTF-8'&gt;\",\n        \"&lt;title&gt;Estimation Report&lt;/title&gt;\",\n        \"&lt;style&gt;\",\n        \"body { font-family: Arial, sans-serif; margin: 20px; }\",\n        \"h1 { color: #333; }\",\n        \"h2 { color: #555; font-size: 1.8em; border-bottom: 1px solid #ccc; padding-bottom: 5px; }\",\n        \"h3 { color: #666; font-size: 1.4em; margin-top: 10px; margin-bottom: 10px; }\",\n        # /* CSS grid for plots: two per row, fixed size 500px x 500px, extra space between rows */\n        \".plot-container {\",\n        \"  display: grid;\",\n        \"  grid-template-columns: repeat(2, 500px);\",\n        \"  column-gap: 20px;\",\n        \"  row-gap: 40px;\", # /* extra vertical gap */\n        \"  justify-content: left;\",\n        \"  margin-bottom: 20px;\",\n        \"}\",\n        \".plot-item {\",\n        \"  width: 500px;\",\n        \"  height: 500px;\",\n        \"}\",\n        \"img, iframe {\",\n        \"  width: 100%;\",\n        \"  height: 100%;\",\n        \"  object-fit: contain;\",\n        \"  border: none;\",\n        \"}\",\n        # /* Data tables: full width, one per row */\n        \".data-table {\",\n        \"  width: 50%;\",\n        \"  margin-bottom: 20px;\",\n        \"}\",\n        \"table {\",\n        \"  border-collapse: collapse;\",\n        \"  width: 100%;\",\n        \"  margin-top: 10px;\",\n        \"}\",\n        \"th, td {\",\n        \"  border: 1px solid #ccc;\",\n        \"  padding: 8px;\",\n        \"  text-align: left;\",\n        \"}\",\n        \"&lt;/style&gt;\",\n        \"&lt;/head&gt;\",\n        \"&lt;body&gt;\",\n        \"&lt;h1&gt;Kinase Optimization Report&lt;/h1&gt;\"\n    ]\n\n    # For each gene folder, create a section in the report.\n    for gene in sorted(gene_folders):\n        gene_folder = os.path.join(results_dir, gene)\n        html_parts.append(f\"&lt;h2&gt;Protein Group: {gene}&lt;/h2&gt;\")\n\n        # Create grid container for fixed-size plots.\n        html_parts.append('&lt;div class=\"plot-container\"&gt;')\n        files = sorted(os.listdir(gene_folder))\n        for filename in files:\n            file_path = os.path.join(gene_folder, filename)\n            if os.path.isfile(file_path):\n                if filename.endswith(\".png\"):\n                    rel_path = os.path.join(gene, filename)\n                    html_parts.append(\n                        f'&lt;div class=\"plot-item\"&gt;&lt;h3&gt;{filename}&lt;/h3&gt;&lt;img src=\"{rel_path}\" alt=\"{filename}\"&gt;&lt;/div&gt;'\n                    )\n        html_parts.append('&lt;/div&gt;')  # End of plot container\n\n        # Data tables: display XLSX or CSV files from the gene folder, one per row.\n        for filename in files:\n            file_path = os.path.join(gene_folder, filename)\n            if os.path.isfile(file_path) and filename.endswith(\".xlsx\"):\n                try:\n                    df = pd.read_excel(file_path)\n                    table_html = df.to_html(index=False, border=0)\n                    html_parts.append(f'&lt;div class=\"data-table\"&gt;&lt;h3&gt;Data Table: {filename}&lt;/h3&gt;{table_html}&lt;/div&gt;')\n                except Exception as e:\n                    html_parts.append(\n                        f'&lt;div class=\"data-table\"&gt;&lt;h3&gt;Data Table: {filename}&lt;/h3&gt;&lt;p&gt;Error reading {filename}: {e}&lt;/p&gt;&lt;/div&gt;'\n                    )\n\n    html_parts.append(\"&lt;/body&gt;\")\n    html_parts.append(\"&lt;/html&gt;\")\n\n    # Write the report into the results directory.\n    output_path = os.path.join(results_dir, output_file)\n    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(html_parts))\n</code></pre>"},{"location":"reference/#kinopt.local.utils.iodata.format_duration","title":"<code>format_duration(seconds)</code>","text":"<p>Formats a duration in seconds into a human-readable string. - If less than 60 seconds, returns in seconds. - If less than 3600 seconds, returns in minutes. - If more than 3600 seconds, returns in hours.</p> <p>:param seconds: :return: Formatted string</p> Source code in <code>kinopt/local/utils/iodata.py</code> <pre><code>def format_duration(seconds):\n    \"\"\"\n    Formats a duration in seconds into a human-readable string.\n    - If less than 60 seconds, returns in seconds.\n    - If less than 3600 seconds, returns in minutes.\n    - If more than 3600 seconds, returns in hours.\n\n    :param seconds:\n    :return: Formatted string\n    \"\"\"\n    if seconds &lt; 60:\n        return f\"{seconds:.2f} sec\"\n    elif seconds &lt; 3600:\n        return f\"{seconds / 60:.2f} min\"\n    else:\n        return f\"{seconds / 3600:.2f} hr\"\n</code></pre>"},{"location":"reference/#kinopt.local.utils.iodata.load_and_scale_data","title":"<code>load_and_scale_data(estimate_missing, scaling_method, split_point, seg_points)</code>","text":"<p>Load and scale the data from the specified input files.</p> <p>:param estimate_missing: :param scaling_method: :param split_point: :param seg_points: :return: Time series data, interaction data, observed data</p> Source code in <code>kinopt/local/utils/iodata.py</code> <pre><code>def load_and_scale_data(estimate_missing, scaling_method, split_point, seg_points):\n    \"\"\"\n    Load and scale the data from the specified input files.\n\n    :param estimate_missing:\n    :param scaling_method:\n    :param split_point:\n    :param seg_points:\n    :return: Time series data, interaction data, observed data\n    \"\"\"\n    full_hgnc_df = pd.read_csv(INPUT1)\n    full_hgnc_df = full_hgnc_df[full_hgnc_df['Psite'].notna() &amp; (full_hgnc_df['Psite'] != '')]\n    time_series_cols = [f'x{i}' for i in range(1, 15)]\n    full_hgnc_df = apply_scaling(full_hgnc_df, time_series_cols, scaling_method, split_point, seg_points)\n    interaction_df = pd.read_csv(INPUT2, header=0)\n    if estimate_missing:\n        observed = full_hgnc_df.merge(interaction_df.iloc[:, :2], on=[\"GeneID\", \"Psite\"])\n        interaction_df['Kinase'] = interaction_df['Kinase'].str.strip('{}').apply(lambda x: [k.strip() for k in x.split(',')])\n    else:\n        interaction_df = interaction_df[interaction_df['Kinase'].apply(\n            lambda k: all(kinase in set(full_hgnc_df['GeneID'][1:]) for kinase in k.strip('{}').split(',')))]\n        interaction_df['Kinase'] = interaction_df['Kinase'].str.strip('{}').apply(lambda x: [k.strip() for k in x.split(',')])\n        observed = full_hgnc_df.merge(interaction_df.iloc[:, :2], on=[\"GeneID\", \"Psite\"])\n    return full_hgnc_df, interaction_df, observed\n</code></pre>"},{"location":"reference/#kinopt.local.utils.iodata.organize_output_files","title":"<code>organize_output_files(*directories)</code>","text":"<p>Function to organize output files into protein-specific folders. It moves files matching the pattern 'protein_name_*.{json,svg,png,html,csv,xlsx}' into a folder named after the protein (e.g., 'ABL2') and moves all other files into a 'General' folder within the same directory.</p> <p>:param directories:</p> Source code in <code>kinopt/local/utils/iodata.py</code> <pre><code>def organize_output_files(*directories):\n    \"\"\"\n    Function to organize output files into protein-specific folders.\n    It moves files matching the pattern 'protein_name_*.{json,svg,png,html,csv,xlsx}'\n    into a folder named after the protein (e.g., 'ABL2') and moves all other files\n    into a 'General' folder within the same directory.\n\n    :param directories:\n    \"\"\"\n    protein_regex = re.compile(r'([A-Za-z0-9]+)_.*\\.(json|svg|png|html|csv|xlsx)$')\n\n    for directory in directories:\n        if not os.path.isdir(directory):\n            print(f\"Warning: '{directory}' is not a valid directory. Skipping.\")\n            continue\n\n        # Move files matching the protein pattern.\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            if os.path.isfile(file_path):\n                match = protein_regex.search(filename)\n                if match:\n                    protein = match.group(1)\n                    protein_folder = os.path.join(directory, protein)\n                    os.makedirs(protein_folder, exist_ok=True)\n                    destination_path = os.path.join(protein_folder, filename)\n                    shutil.move(file_path, destination_path)\n\n        # After protein files have been moved, move remaining files to a \"General\" folder.\n        general_folder = os.path.join(directory, \"General\")\n        os.makedirs(general_folder, exist_ok=True)\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            if os.path.isfile(file_path):\n                destination_path = os.path.join(general_folder, filename)\n                shutil.move(file_path, destination_path)\n</code></pre>"},{"location":"reference/#kinopt.local.utils.params.compute_metrics","title":"<code>compute_metrics(optimized_params, P_init_dense, t_max, gene_alpha_starts, gene_kinase_counts, gene_kinase_idx, total_alpha, kinase_beta_starts, kinase_beta_counts, K_data, K_indices, K_indptr)</code>","text":"<p>Computes the estimated series and various metrics based on the optimized parameters.</p> <p>:param optimized_params: :param P_init_dense: :param t_max: :param gene_alpha_starts: :param gene_kinase_counts: :param gene_kinase_idx: :param total_alpha: :param kinase_beta_starts: :param kinase_beta_counts: :param K_data: :param K_indices: :param K_indptr: :return: Estimated series, residuals, MSE, RMSE, MAE, MAPE, R-squared</p> Source code in <code>kinopt/local/utils/params.py</code> <pre><code>def compute_metrics(optimized_params, P_init_dense, t_max, gene_alpha_starts, gene_kinase_counts,\n                    gene_kinase_idx, total_alpha, kinase_beta_starts, kinase_beta_counts,\n                    K_data, K_indices, K_indptr):\n    \"\"\"\n    Computes the estimated series and various metrics based on the optimized parameters.\n\n    :param optimized_params:\n    :param P_init_dense:\n    :param t_max:\n    :param gene_alpha_starts:\n    :param gene_kinase_counts:\n    :param gene_kinase_idx:\n    :param total_alpha:\n    :param kinase_beta_starts:\n    :param kinase_beta_counts:\n    :param K_data:\n    :param K_indices:\n    :param K_indptr:\n    :return: Estimated series, residuals, MSE, RMSE, MAE, MAPE, R-squared\n    \"\"\"\n    P_est = estimated_series(optimized_params, t_max, P_init_dense.shape[0],\n                                 gene_alpha_starts, gene_kinase_counts, gene_kinase_idx,\n                                 total_alpha, kinase_beta_starts, kinase_beta_counts,\n                                 K_data, K_indices, K_indptr)\n    residuals = P_init_dense - P_est\n    mse = np.sum(residuals**2) / P_init_dense.size\n    rmse = np.sqrt(mse)\n    mae = np.mean(np.abs(residuals))\n    mape = np.mean(np.abs(residuals / (P_init_dense + 1e-12))) * 100\n    r_squared = 1 - (np.sum(residuals**2) / np.sum((P_init_dense - np.mean(P_init_dense))**2))\n    return P_est, residuals, mse, rmse, mae, mape, r_squared\n</code></pre>"},{"location":"reference/#kinopt.local.utils.params.extract_parameters","title":"<code>extract_parameters(P_initial, gene_kinase_counts, total_alpha, unique_kinases, K_index, optimized_params)</code>","text":"<p>Extracts the alpha and beta parameters from the optimized parameters.</p> <p>:param P_initial: :param gene_kinase_counts: :param total_alpha: :param unique_kinases: :param K_index: :param optimized_params: :return: Alpha and beta values as dictionaries</p> Source code in <code>kinopt/local/utils/params.py</code> <pre><code>def extract_parameters(P_initial, gene_kinase_counts, total_alpha, unique_kinases, K_index, optimized_params):\n    \"\"\"\n    Extracts the alpha and beta parameters from the optimized parameters.\n\n    :param P_initial:\n    :param gene_kinase_counts:\n    :param total_alpha:\n    :param unique_kinases:\n    :param K_index:\n    :param optimized_params:\n    :return: Alpha and beta values as dictionaries\n    \"\"\"\n    alpha_values = {}\n    alpha_start = 0\n    for key, count in zip(P_initial.keys(), gene_kinase_counts):\n        kinases = P_initial[key]['Kinases']\n        alpha_values[key] = dict(zip(kinases, optimized_params[alpha_start:alpha_start+count]))\n        alpha_start += count\n    beta_values = {}\n    beta_start = total_alpha\n    for kinase in unique_kinases:\n        for (psite, _) in K_index[kinase]:\n            beta_values[(kinase, psite)] = optimized_params[beta_start]\n            beta_start += 1\n    return alpha_values, beta_values\n</code></pre>"},{"location":"reference/#kinopt.optimality.KKT.generate_latex_table","title":"<code>generate_latex_table(summary_dict, table_caption, table=None)</code>","text":"<p>Function to generate a LaTeX table from a summary dictionary. The table is formatted for use in a LaTeX document.</p> <p>:param summary_dict: Dictionary containing summary data. :param table_caption: Caption for the LaTeX table. :param table: Optional table object to format. :return: LaTeX table as a string.</p> Source code in <code>kinopt/optimality/KKT.py</code> <pre><code>def generate_latex_table(summary_dict, table_caption, table=None):\n    \"\"\"\n    Function to generate a LaTeX table from a summary dictionary.\n    The table is formatted for use in a LaTeX document.\n\n    :param summary_dict: Dictionary containing summary data.\n    :param table_caption: Caption for the LaTeX table.\n    :param table: Optional table object to format.\n    :return: LaTeX table as a string.\n    \"\"\"\n    latex_table = \"\\n\\\\begin{table}[H]\\n\\\\centering\\n\\\\begin{tabular}{|l|c|}\\\\hline\\n\"\n    latex_table += \"Metric &amp; Value \\\\\\\\ \\\\hline\\n\"\n    for key, value in summary_dict.items():\n        latex_table += f\"{key} &amp; {value} \\\\\\\\ \\\\hline\\n\"\n    latex_table += \"\\\\end{tabular}\\n\"\n    latex_table += f\"\\\\caption{{{table_caption}}}\\n\\\\end{table}\\n\"\n    return latex_table\n</code></pre>"},{"location":"reference/#kinopt.optimality.KKT.plot_constraint_violations","title":"<code>plot_constraint_violations(alpha_violations, beta_violations, out_dir)</code>","text":"<p>Function to plot constraint violations for alpha and beta values. It creates a stacked bar plot showing the violations for each protein. The top 5 proteins with the highest violations are highlighted in red.</p> <p>Parameters:</p> Name Type Description Default <code>alpha_violations</code> <code>Series</code> <p>Series containing alpha constraint violations.</p> required <code>beta_violations</code> <code>Series</code> <p>Series containing beta constraint violations.</p> required <code>out_dir</code> <code>str</code> <p>Directory to save the plot.</p> required Source code in <code>kinopt/optimality/KKT.py</code> <pre><code>def plot_constraint_violations(alpha_violations, beta_violations, out_dir):\n    \"\"\"\n    Function to plot constraint violations for alpha and beta values.\n    It creates a stacked bar plot showing the violations for each protein.\n    The top 5 proteins with the highest violations are highlighted in red.\n\n    Args:\n        alpha_violations (pd.Series): Series containing alpha constraint violations.\n        beta_violations (pd.Series): Series containing beta constraint violations.\n        out_dir (str): Directory to save the plot.\n    \"\"\"\n    # Group and combine violations\n    alpha_violations_abs = alpha_violations.abs().groupby('Gene').sum()\n    beta_violations_abs = beta_violations.abs().reindex(alpha_violations_abs.index, fill_value=0)\n    combined = pd.DataFrame({\n        \"Alpha Violations\": alpha_violations_abs,\n        \"Beta Violations\": beta_violations_abs\n    })\n    combined['Total Violations'] = combined.sum(axis=1)\n    combined = combined.sort_values(by=\"Total Violations\", ascending=True)\n    top_proteins = combined.tail(5).index\n\n    plt.figure(figsize=(8, 8))\n    bar_alpha = plt.bar(combined.index, combined[\"Alpha Violations\"], color='dodgerblue', label=r'$\\alpha$')\n    bar_beta = plt.bar(combined.index, combined[\"Beta Violations\"], bottom=combined[\"Alpha Violations\"],\n                       color='lightgreen', label=r'$\\beta$')\n\n    # Highlight top violations in red\n    for bar in bar_alpha:\n        if bar.get_x() in top_proteins:\n            bar.set_color('red')\n    for bar in bar_beta:\n        if bar.get_x() in top_proteins:\n            bar.set_color('red')\n\n    plt.xlabel(\"Proteins\")\n    plt.ylabel(\"Constraint Violations\")\n    plt.xticks(rotation=45, ha='right')\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(str(Path(out_dir) / \"constraint_violations.png\"), dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#kinopt.optimality.KKT.plot_sensitivity_analysis","title":"<code>plot_sensitivity_analysis(sensitivity_analysis, out_dir)</code>","text":"<p>Function to plot sensitivity analysis results. It creates a horizontal bar plot showing the mean, max, and min sensitivity for each protein.</p> <p>Parameters:</p> Name Type Description Default <code>sensitivity_analysis</code> <code>DataFrame</code> <p>DataFrame containing sensitivity analysis results.</p> required <code>out_dir</code> <code>str</code> <p>Directory to save the plot.</p> required Source code in <code>kinopt/optimality/KKT.py</code> <pre><code>def plot_sensitivity_analysis(sensitivity_analysis, out_dir):\n    \"\"\"\n    Function to plot sensitivity analysis results.\n    It creates a horizontal bar plot showing the mean, max, and min sensitivity for each protein.\n\n    Args:\n        sensitivity_analysis (pd.DataFrame): DataFrame containing sensitivity analysis results.\n        out_dir (str): Directory to save the plot.\n    \"\"\"\n    summary = sensitivity_analysis.groupby(\"GeneID\")[[\"Sensitivity Mean\", \"Max Sensitivity\", \"Min Sensitivity\"]].mean()\n    summary = summary.sort_values(by=\"Sensitivity Mean\", ascending=True)\n\n    plt.figure(figsize=(8, 8))\n    bar_min = plt.barh(summary.index, summary[\"Min Sensitivity\"], color='lightgreen', label='Min')\n    bar_mean = plt.barh(summary.index, summary[\"Sensitivity Mean\"],\n                        left=summary[\"Min Sensitivity\"], color='dodgerblue', label='Mean')\n    bar_max = plt.barh(summary.index, summary[\"Max Sensitivity\"],\n                       left=summary[\"Min Sensitivity\"] + summary[\"Sensitivity Mean\"],\n                       color='coral', label='Max')\n    plt.xlabel(\"Sensitivity\")\n    plt.ylabel(\"Proteins\")\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(str(Path(out_dir) / \"sensitivity.png\"), dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#kinopt.optimality.KKT.post_optimization_results","title":"<code>post_optimization_results()</code>","text":"<p>Function to process and visualize the results of the optimization. It reads the results from an Excel file, processes the data, and generates plots for constraint violations and sensitivity analysis. It also prints the primal feasibility results and sensitivity summaries. The results are returned as a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary containing the processed results, including alpha and beta values,   estimated and observed values, constraint violations, residuals summary,   sensitivity summary, and high sensitivity sites.</p> Source code in <code>kinopt/optimality/KKT.py</code> <pre><code>def post_optimization_results():\n    \"\"\"\n    Function to process and visualize the results of the optimization.\n    It reads the results from an Excel file, processes the data,\n    and generates plots for constraint violations and sensitivity analysis.\n    It also prints the primal feasibility results and sensitivity summaries.\n    The results are returned as a dictionary.\n\n    Returns:\n        dict: Dictionary containing the processed results, including alpha and beta values,\n              estimated and observed values, constraint violations, residuals summary,\n              sensitivity summary, and high sensitivity sites.\n    \"\"\"\n    results = process_excel_results()\n    # Plot violation and sensitivity figures\n    plot_constraint_violations(results[\"alpha_constraint_violations\"], results[\"beta_constraint_violations\"], OUT_DIR)\n    plot_sensitivity_analysis(results[\"sensitivity_analysis\"], OUT_DIR)\n\n    # For demonstration, call the printing functions (you may pass in appropriate summaries)\n    print_primal_feasibility_results(results[\"alpha_constraint_violations\"],\n                                     results[\"alpha_constraint_violations\"],\n                                     results[\"beta_constraint_violations\"])\n    print_sensitivity_and_active_constraints(results[\"sensitivity_summary\"],\n                                             results[\"sensitivity_summary\"])\n    return results\n</code></pre>"},{"location":"reference/#kinopt.optimality.KKT.print_primal_feasibility_results","title":"<code>print_primal_feasibility_results(primal_summary, alpha_violations, beta_violations, logger_obj=None)</code>","text":"<p>Logs the primal feasibility summary and violation details.</p> Source code in <code>kinopt/optimality/KKT.py</code> <pre><code>def print_primal_feasibility_results(primal_summary, alpha_violations, beta_violations, logger_obj=None):\n    \"\"\"\n    Logs the primal feasibility summary and violation details.\n    \"\"\"\n    if logger_obj is None:\n        logger_obj = logger\n    logger_obj.info(\"Primal Feasibility Summary:\")\n    for key, value in primal_summary.items():\n        logger_obj.info(f\"{key}: {value}\")\n\n    logger_obj.info(\"Alpha Violations:\")\n    for index, value in alpha_violations.items():\n        logger_obj.info(f\"{index}: {value}\")\n\n    logger_obj.info(\"Beta Violations:\")\n    for index, value in beta_violations.items():\n        logger_obj.info(f\"{index}: {value}\")\n</code></pre>"},{"location":"reference/#kinopt.optimality.KKT.print_sensitivity_and_active_constraints","title":"<code>print_sensitivity_and_active_constraints(sensitivity_summary, active_constraints_summary, logger_obj=None)</code>","text":"<p>Logs the sensitivity summary and active constraints summary.</p> Source code in <code>kinopt/optimality/KKT.py</code> <pre><code>def print_sensitivity_and_active_constraints(sensitivity_summary, active_constraints_summary, logger_obj=None):\n    \"\"\"\n    Logs the sensitivity summary and active constraints summary.\n    \"\"\"\n    if logger_obj is None:\n        logger_obj = logger\n    logger_obj.info(\"Sensitivity Summary:\")\n    for key, value in sensitivity_summary.items():\n        logger_obj.info(f\"{key}: {value}\")\n    logger_obj.info(\"Active Constraints Summary:\")\n    for key, value in active_constraints_summary.items():\n        logger_obj.info(f\"{key}: {value}\")\n</code></pre>"},{"location":"reference/#kinopt.optimality.KKT.process_excel_results","title":"<code>process_excel_results(file_path=OUT_FILE)</code>","text":"<p>Function to process the Excel results file. It reads the alpha and beta values, estimated and observed values, validates normalization constraints, computes residuals and gradients, and generates LaTeX tables for the residuals and sensitivity summaries. It also performs sensitivity analysis and identifies high sensitivity sites. The results are returned as a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the Excel file containing results.</p> <code>OUT_FILE</code> <p>Returns:     dict: Dictionary containing the processed results, including alpha and beta values,           estimated and observed values, constraint violations, residuals summary,           sensitivity summary, and high sensitivity sites.</p> Source code in <code>kinopt/optimality/KKT.py</code> <pre><code>def process_excel_results(file_path=OUT_FILE):\n    \"\"\"\n    Function to process the Excel results file.\n    It reads the alpha and beta values, estimated and observed values,\n    validates normalization constraints, computes residuals and gradients,\n    and generates LaTeX tables for the residuals and sensitivity summaries.\n    It also performs sensitivity analysis and identifies high sensitivity sites.\n    The results are returned as a dictionary.\n\n    Args:\n        file_path (str): Path to the Excel file containing results.\n    Returns:\n        dict: Dictionary containing the processed results, including alpha and beta values,\n              estimated and observed values, constraint violations, residuals summary,\n              sensitivity summary, and high sensitivity sites.\n    \"\"\"\n    alpha_values = pd.read_excel(file_path, sheet_name='Alpha Values')\n    beta_values = pd.read_excel(file_path, sheet_name='Beta Values')\n    estimated_values = pd.read_excel(file_path, sheet_name='Estimated')\n    observed_values = pd.read_excel(file_path, sheet_name='Observed')\n\n    # Validate normalization constraints\n    alpha_sum = alpha_values.groupby(['Gene', 'Psite'])['Alpha'].sum()\n    alpha_violations = alpha_sum[alpha_sum != 1]\n    beta_sum = beta_values.groupby(['Kinase'])['Beta'].sum()\n    beta_violations = beta_sum[beta_sum != 1]\n\n    # Compute residuals and gradients\n    observed_matrix = observed_values.iloc[:, 2:].values\n    estimated_matrix = estimated_values.iloc[:, 2:].values\n    residuals = observed_matrix - estimated_matrix\n    gradients = np.gradient(residuals, axis=1)\n    residuals_summary = {\n        \"Max Residual\": round(np.max(residuals), 2),\n        \"Min Residual\": round(np.min(residuals), 2),\n        \"Mean Residual\": round(np.mean(residuals), 2),\n        \"Max Gradient\": round(np.max(gradients), 2),\n        \"Min Gradient\": round(np.min(gradients), 2),\n        \"Mean Gradient\": round(np.mean(gradients), 2)\n    }\n    sensitivity_summary = {\n        \"Max Sensitivity\": round(np.max(observed_matrix), 2),\n        \"Min Sensitivity\": round(np.min(observed_matrix), 2),\n        \"Mean Sensitivity\": round(np.mean(observed_matrix), 2)\n    }\n\n    latex_res_table = generate_latex_table(residuals_summary, \"Residual Summary\")\n    latex_sens_table = generate_latex_table(sensitivity_summary, \"Sensitivity Summary\")\n    logger.info(latex_res_table)\n    logger.info(latex_sens_table)\n\n    sensitivity_analysis = pd.DataFrame({\n        \"GeneID\": observed_values.iloc[:, 0],\n        \"Psite\": observed_values.iloc[:, 1],\n        \"Sensitivity Mean\": observed_matrix.mean(axis=1),\n        \"Max Sensitivity\": np.max(observed_matrix, axis=1),\n        \"Min Sensitivity\": np.min(observed_matrix, axis=1)\n    })\n\n    # Threshold for high sensitivity sites\n    high_thresh = 0.75\n    high_sites_idx = np.where(observed_matrix &gt;= high_thresh)[0]\n    high_sites = [\n        (observed_values.iloc[i, 0], observed_values.iloc[i, 1])\n        for i in high_sites_idx\n    ]\n\n    results = {\n        \"alpha_values\": alpha_values,\n        \"beta_values\": beta_values,\n        \"estimated_values\": estimated_values,\n        \"observed_values\": observed_values,\n        \"alpha_constraint_violations\": alpha_violations,\n        \"beta_constraint_violations\": beta_violations,\n        \"residuals_summary\": residuals_summary,\n        \"sensitivity_summary\": sensitivity_summary,\n        \"sensitivity_analysis\": sensitivity_analysis,\n        \"high_sensitivity_sites\": high_sites,\n    }\n    return results\n</code></pre>"},{"location":"reference/#kinopt.powell.runpowell.run_powell","title":"<code>run_powell()</code>","text":"<p>Run the Powell optimization algorithm using Julia. It sets the number of threads to half of the available threads and logs the output in real time.</p> Source code in <code>kinopt/powell/runpowell.py</code> <pre><code>def run_powell():\n    \"\"\"\n    Run the Powell optimization algorithm using Julia.\n    It sets the number of threads to half of the available threads\n    and logs the output in real time.\n    \"\"\"\n    # Run the command to get the number of threads (as a string)\n    result = subprocess.run(\"lscpu -p | grep -v '^#' | wc -l\", shell=True, capture_output=True, text=True)\n    num_threads_str = result.stdout.strip()\n\n    # Convert to integer, compute half, and round it\n    num_threads_int = int(num_threads_str)\n    half_threads = round(num_threads_int / 2)\n\n    # Set up the environment variable (convert back to string)\n    env = os.environ.copy()\n    env[\"JULIA_NUM_THREADS\"] = str(half_threads)\n\n    # Start the Julia script and log output in real time\n    process = subprocess.Popen(\n        [\"julia\", \"kinopt/powell/powell.jl\"],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        env=env,\n        text=True,\n        bufsize=1\n    )\n\n    # Read each line\n    with process.stdout:\n        for line in iter(process.stdout.readline, ''):\n            logger.info(line.rstrip())\n\n    process.wait()\n</code></pre>"},{"location":"reference/#models.diagram.helpers.create_distributive_diagram","title":"<code>create_distributive_diagram(x, num_sites, output_filename)</code>","text":"<p>Create a distributive phosphorylation diagram. This model shows single-step phosphorylation and dephosphorylation transitions for each site, along with production/degradation edges.</p> Source code in <code>models/diagram/helpers.py</code> <pre><code>def create_distributive_diagram(x, num_sites, output_filename):\n    \"\"\"\n    Create a distributive phosphorylation diagram.\n    This model shows single-step phosphorylation and dephosphorylation transitions\n    for each site, along with production/degradation edges.\n    \"\"\"\n    dot = Digraph(engine='neato')\n    dot.attr(rankdir='LR')\n    dot.attr(label=\"Distributive\", labelloc=\"t\", fontsize=\"15\",\n             fontname=\"Helvetica\", fontcolor=\"black\")\n    dot.attr('graph', bgcolor=\"white\", dpi='300')\n    dot.attr('node', shape='ellipse', style='filled,rounded', fontname='Helvetica', fontsize='12')\n    dot.attr('edge', fontname='Helvetica', fontsize='10')\n\n    # --- mRNA (R) and its null state ---\n    dot.node('NULL_R', '\u03c6', shape='plaintext', fontcolor='gray')\n    dot.node('R', 'R', style='filled', fillcolor='lightcoral', fontcolor='white')\n    dot.edge('NULL_R', 'R', label='A', color='red', fontcolor='red', penwidth='2')\n    dot.edge('R', 'NULL_R', label='B', color='forestgreen', fontcolor='forestgreen', penwidth='2')\n\n    # --- Protein (P) and its null state ---\n    dot.node('NULL_P', '\u03c6', shape='plaintext', fontcolor='gray')\n    dot.node('P', 'P', style='filled', fillcolor='dodgerblue', fontcolor='white')\n    dot.edge('R', 'P', label='C', color='goldenrod', fontcolor='goldenrod', penwidth='2')\n    dot.edge('P', 'NULL_P', label='D', color='dimgray', fontcolor='dimgray', penwidth='2')\n\n    # --- Phosphorylation sites ---\n    for i in range(1, num_sites + 1):\n        p_node = f'P{i}'\n        null_p_node = f'NULL_P{i}'\n        dot.node(p_node, p_node, style='filled', fillcolor='turquoise3', fontcolor='black')\n        dot.node(null_p_node, '\u03c6', shape='plaintext', fontcolor='gray')\n        dot.edge('P', p_node, label=f'S{i}', color='mediumvioletred', fontcolor='mediumvioletred',\n                 style='bold', penwidth='1.5')\n        dot.edge(p_node, 'P', label='1', color='slateblue', fontcolor='slateblue',\n                 style='dashed', penwidth='1.5')\n        dot.edge(p_node, null_p_node, label=f'D{i}', color='dimgray', fontcolor='dimgray',\n                 style='dotted', penwidth='1.5')\n\n    dot.render(f\"{OUT_DIR}/{output_filename}\", format='png', cleanup=True)\n</code></pre>"},{"location":"reference/#models.diagram.helpers.create_random_diagram","title":"<code>create_random_diagram(x, num_sites, output_filename)</code>","text":"<p>Create a random phosphorylation diagram. The diagram displays mRNA production/degradation, protein production, phosphorylation transitions (addition) and dephosphorylation transitions, as well as degradation edges for each state.</p> Source code in <code>models/diagram/helpers.py</code> <pre><code>def create_random_diagram(x, num_sites, output_filename):\n    \"\"\"\n    Create a random phosphorylation diagram.\n    The diagram displays mRNA production/degradation, protein production,\n    phosphorylation transitions (addition) and dephosphorylation transitions,\n    as well as degradation edges for each state.\n    \"\"\"\n    dot = Digraph(engine='neato')\n    dot.attr(rankdir='LR')\n    # Global graph attributes: title and overall styling.\n    dot.attr(label=\"Random\", labelloc=\"t\", fontsize=\"15\",\n             fontname=\"Helvetica\", fontcolor=\"black\")\n    dot.attr('graph', bgcolor=\"white\", dpi='300')\n\n    # Global node and edge attributes for a modern, clean look.\n    dot.attr('node', shape='ellipse', style='filled,rounded', fontname='Helvetica',\n             fontsize='12', fixedsize='false')\n    dot.attr('edge', fontname='Helvetica', fontsize='10')\n\n    # --- mRNA (R) Production and Degradation ---\n    dot.node('NULL_R', '\u03c6', shape='plaintext', fontcolor='gray')\n    dot.node('R', 'R', style='filled', fillcolor='lightcoral', fontcolor='white')\n    dot.edge('NULL_R', 'R', label='A', color='red', fontcolor='red', penwidth='2')\n    dot.edge('R', 'NULL_R', label='B', color='forestgreen', fontcolor='forestgreen', penwidth='2')\n\n    # --- Protein (P) and its phosphorylation states ---\n    dot.node('NULL_P', '\u03c6', shape='plaintext', fontcolor='gray')\n    sites = [str(i) for i in range(1, num_sites + 1)]\n    all_states = powerset(sites)\n\n    # Create nodes for each phosphorylation state with custom colors.\n    state_nodes = {}\n    for state in all_states:\n        label = state_label(state)\n        state_nodes[state] = label\n        if label == \"P\":\n            dot.node(label, label, fillcolor='dodgerblue', fontcolor='white')\n        else:\n            dot.node(label, label, fillcolor='turquoise3', fontcolor='black')\n        # Create corresponding NULL node for degradation of this state.\n        dot.node('NULL_' + label, '\u03c6', shape='plaintext', fontcolor='gray')\n\n    # --- Production of protein P ---\n    dot.edge('R', state_nodes[frozenset()], label='C', color='goldenrod', fontcolor='goldenrod', penwidth='2')\n\n    # --- Phosphorylation transitions (Addition) ---\n    all_sites_set = set(sites)\n    for state in all_states:\n        current_label = state_nodes[state]\n        missing_sites = all_sites_set - state\n        for site in missing_sites:\n            new_state = state.union({site})\n            new_label = state_nodes[new_state]\n            dot.edge(current_label, new_label, label='S' + site, color='mediumvioletred',\n                     fontcolor='mediumvioletred', style='bold', penwidth='1.5')\n\n    # --- Dephosphorylation transitions (Removal) ---\n    for state in all_states:\n        if state:  # Only states with at least one phosphorylation can dephosphorylate.\n            current_label = state_nodes[state]\n            for site in state:\n                new_state = state.difference({site})\n                new_label = state_nodes[new_state]\n                dot.edge(current_label, new_label, label='1', color='slateblue',\n                         fontcolor='slateblue', style='dashed', penwidth='1.5')\n\n    # --- Degradation transitions for all protein states ---\n    for state in all_states:\n        label = state_nodes[state]\n        deg_label = 'D' if label == \"P\" else 'D' + label[1:]\n        dot.edge(label, 'NULL_' + label, label=deg_label, color='dimgray',\n                 fontcolor='dimgray', style='dotted', penwidth='1.5')\n\n    dot.render(f\"{OUT_DIR}/{output_filename}\", format='png', cleanup=True)\n</code></pre>"},{"location":"reference/#models.diagram.helpers.create_successive_model","title":"<code>create_successive_model(x, num_sites, output_filename)</code>","text":"<p>Create a successive phosphorylation diagram. In this model, phosphorylation occurs in a sequential order from P to P1 to P2, etc., with corresponding dephosphorylation and degradation transitions.</p> Source code in <code>models/diagram/helpers.py</code> <pre><code>def create_successive_model(x, num_sites, output_filename):\n    \"\"\"\n    Create a successive phosphorylation diagram.\n    In this model, phosphorylation occurs in a sequential order from P to P1 to P2, etc.,\n    with corresponding dephosphorylation and degradation transitions.\n    \"\"\"\n    dot = Digraph(engine='neato')\n    dot.attr(rankdir='LR')\n    dot.attr(label=\"Successive\", labelloc=\"t\", fontsize=\"15\",\n             fontname='Helvetica', fontcolor='black')\n    dot.attr('graph', bgcolor=\"white\", dpi='300')\n    dot.attr('node', shape='ellipse', style='filled,rounded', fontname='Helvetica', fontsize='12')\n    dot.attr('edge', fontname='Helvetica', fontsize='10')\n\n    # --- mRNA (R) Production and Degradation ---\n    dot.node('NULL_R', '\u03c6', shape='plaintext', fontcolor='gray')\n    dot.node('R', 'R', style='filled', fillcolor='lightcoral', fontcolor='white')\n    dot.edge('NULL_R', 'R', label='A', color='red', fontcolor='red', penwidth='2')\n    dot.edge('R', 'NULL_R', label='B', color='forestgreen', fontcolor='forestgreen', penwidth='2')\n\n    # --- Protein (P) and its null state ---\n    dot.node('NULL_P', '\u03c6', shape='plaintext', fontcolor='gray')\n    dot.node('P', 'P', style='filled', fillcolor='dodgerblue', fontcolor='white')\n    dot.edge('R', 'P', label='C', color='goldenrod', fontcolor='goldenrod', penwidth='2')\n    dot.edge('P', 'NULL_P', label='D', color='dimgray', fontcolor='dimgray', penwidth='2')\n\n    # --- Successive Phosphorylation States ---\n    for i in range(1, num_sites + 1):\n        state = f'P{i}'\n        null_state = f'NULL_P{i}'\n        dot.node(state, state, style='filled', fillcolor='turquoise3', fontcolor='black')\n        dot.node(null_state, '\u03c6', shape='plaintext', fontcolor='gray')\n    # First phosphorylation: P -&gt; P1\n    if num_sites &gt;= 1:\n        dot.edge('P', 'P1', label='S1', color='mediumvioletred', fontcolor='mediumvioletred',\n                 style='bold', penwidth='1.5')\n    # Subsequent phosphorylations: P{i-1} -&gt; P{i}\n    for i in range(2, num_sites + 1):\n        dot.edge(f'P{i - 1}', f'P{i}', label=f'S{i}', color='mediumvioletred', fontcolor='mediumvioletred',\n                 style='bold', penwidth='1.5')\n    # Dephosphorylation (reverse reactions)\n    if num_sites &gt;= 1:\n        dot.edge('P1', 'P', label='1', color='slateblue', fontcolor='slateblue', style='dashed', penwidth='1.5')\n    for i in range(2, num_sites + 1):\n        dot.edge(f'P{i}', f'P{i - 1}', label='1', color='slateblue', fontcolor='slateblue',\n                 style='dashed', penwidth='1.5')\n    # Degradation for phosphorylated states\n    for i in range(1, num_sites + 1):\n        dot.edge(f'P{i}', f'NULL_P{i}', label=f'D{i}', color='dimgray', fontcolor='dimgray',\n                 style='dotted', penwidth='1.5')\n\n    dot.render(f\"{OUT_DIR}/{output_filename}\", format='png', cleanup=True)\n</code></pre>"},{"location":"reference/#models.diagram.helpers.powerset","title":"<code>powerset(iterable)</code>","text":"<p>Return the list of all subsets (as frozensets) of the given iterable. For example, for [1,2] returns:   [frozenset(), frozenset({1}), frozenset({2}), frozenset({1,2})]</p> Source code in <code>models/diagram/helpers.py</code> <pre><code>def powerset(iterable):\n    \"\"\"\n    Return the list of all subsets (as frozensets) of the given iterable.\n    For example, for [1,2] returns:\n      [frozenset(), frozenset({1}), frozenset({2}), frozenset({1,2})]\n    \"\"\"\n    s = list(iterable)\n    all_subsets = []\n    for r in range(len(s) + 1):\n        for combo in combinations(s, r):\n            all_subsets.append(frozenset(combo))\n    return all_subsets\n</code></pre>"},{"location":"reference/#models.diagram.helpers.state_label","title":"<code>state_label(state)</code>","text":"<p>Convert a set of phosphorylation sites into a node label. The unphosphorylated state (empty set) is labeled \"P\". For nonempty states the label is \"P\" concatenated with the sorted site numbers.</p> Source code in <code>models/diagram/helpers.py</code> <pre><code>def state_label(state):\n    \"\"\"\n    Convert a set of phosphorylation sites into a node label.\n    The unphosphorylated state (empty set) is labeled \"P\".\n    For nonempty states the label is \"P\" concatenated with the sorted site numbers.\n    \"\"\"\n    if not state:\n        return \"P\"\n    sorted_sites = sorted(state, key=lambda x: int(x))\n    return \"P\" + ''.join(sorted_sites)\n</code></pre>"},{"location":"reference/#models.distmod.ode_core","title":"<code>ode_core(y, A, B, C, D, S_rates, D_rates)</code>","text":"<p>The core ODE system for the distributive phosphorylation model.</p> <p>The system is defined by the following equations:</p> <p>dR/dt = A - B * R dP/dt = C * R - (D + sum(S_rates)) * P + sum(P_sites) dP_sites[i]/dt = S_rates[i] * P - (1.0 + D_rates[i]) * P_sites[i]</p> <p>where:</p> <p>R: the concentration of the mRNA P: the concentration of the protein P_sites: the concentration of the phosphorylated sites A: the rate of production of the mRNA B: the rate of degradation of the mRNA C: the rate of production of the protein D: the rate of degradation of the protein S_rates: the rates of phosphorylation of each site D_rates: the rates of dephosphorylation of each site</p> <p>:param y: :param A: :param B: :param C: :param D: :param S_rates: :param D_rates: :return: Derivative of y</p> Source code in <code>models/distmod.py</code> <pre><code>@njit\ndef ode_core(y, A, B, C, D, S_rates, D_rates):\n    \"\"\"\n    The core ODE system for the distributive phosphorylation model.\n\n    The system is defined by the following equations:\n\n    dR/dt = A - B * R\n    dP/dt = C * R - (D + sum(S_rates)) * P + sum(P_sites)\n    dP_sites[i]/dt = S_rates[i] * P - (1.0 + D_rates[i]) * P_sites[i]\n\n    where:\n\n    R: the concentration of the mRNA\n    P: the concentration of the protein\n    P_sites: the concentration of the phosphorylated sites\n    A: the rate of production of the mRNA\n    B: the rate of degradation of the mRNA\n    C: the rate of production of the protein\n    D: the rate of degradation of the protein\n    S_rates: the rates of phosphorylation of each site\n    D_rates: the rates of dephosphorylation of each site\n\n    :param y:\n    :param A:\n    :param B:\n    :param C:\n    :param D:\n    :param S_rates:\n    :param D_rates:\n    :return: Derivative of y\n    \"\"\"\n    # y[0] is the concentration of the mRNA\n    R = y[0]\n    # y[1] is the concentration of the protein\n    P = y[1]\n    # Number of phosphorylation sites\n    n = S_rates.shape[0]\n    # Derivative of y\n    dydt = np.empty_like(y)\n    # dydt[0] is the rate of change of R\n    dydt[0] = A - B * R\n    # S_rates\n    sum_S = 0.0\n    # sum_S is the sum of S_rates\n    for i in range(n):\n        # S_rates[i] is the rate of phosphorylation of site i\n        sum_S += S_rates[i]\n    # sum_P_sites is the sum of P sites\n    sum_P_sites = 0.0\n    # Loop over the number of phosphorylation sites\n    for i in range(n):\n        # y[2:] are the concentrations of the phosphorylated sites\n        sum_P_sites += y[2 + i]\n    # dydt[1] is the rate of change of P\n    dydt[1] = C * R - (D + sum_S) * P + sum_P_sites\n    # Loop over the number of phosphorylation sites\n    for i in range(n): \n        # dydt[2 + i] is the rate of change of each P site\n        dydt[2 + i] = S_rates[i] * P - (1.0 + D_rates[i]) * y[2 + i]\n    return dydt\n</code></pre>"},{"location":"reference/#models.distmod.ode_system","title":"<code>ode_system(y, t, params, num_psites)</code>","text":"<p>The ODE system for the distributive phosphorylation model which calls the core ODE system.</p> <p>:param y: :param t: :param params: :param num_psites: :return: ode_core(y, A, B, C, D, S_rates, D_rates)</p> Source code in <code>models/distmod.py</code> <pre><code>def ode_system(y, t, params, num_psites):\n    \"\"\"\n    The ODE system for the distributive phosphorylation model which calls the core ODE system.\n\n    :param y:\n    :param t:\n    :param params:\n    :param num_psites:\n    :return: ode_core(y, A, B, C, D, S_rates, D_rates)\n    \"\"\"\n    # Unpack the parameters\n    # params[0] is A\n    # params[1] is B\n    # params[2] is C\n    # params[3] is D\n    A, B, C, D = params[0], params[1], params[2], params[3]\n    # params[4 + i] is the S_rate for site i\n    S_rates = np.array([params[4 + i] for i in range(num_psites)])\n    # params[4 + num_psites + i] is the D_rate for site i\n    D_rates = np.array([params[4 + num_psites + i] for i in range(num_psites)])\n    return ode_core(y, A, B, C, D, S_rates, D_rates)\n</code></pre>"},{"location":"reference/#models.distmod.solve_ode","title":"<code>solve_ode(params, init_cond, num_psites, t)</code>","text":"<p>Solve the ODE system for the distributive phosphorylation model.</p> <p>:param params: :param init_cond: :param num_psites: :param t: :return: solution of the ODE system, solution of phosphorylated sites</p> Source code in <code>models/distmod.py</code> <pre><code>def solve_ode(params, init_cond, num_psites, t):\n    \"\"\"\n    Solve the ODE system for the distributive phosphorylation model.\n\n    :param params:\n    :param init_cond:\n    :param num_psites:\n    :param t:\n    :return: solution of the ODE system, solution of phosphorylated sites\n    \"\"\"\n    # Call the odeint function to solve the ODE system\n    sol = np.asarray(odeint(ode_system, init_cond, t, args=(params, num_psites)))\n    # Clip the solution to be non-negative\n    np.clip(sol, 0, None, out=sol)\n    # Normalize the solution if NORMALIZE_MODEL_OUTPUT is True\n    if NORMALIZE_MODEL_OUTPUT:\n        # Normalize the solution to the initial condition\n        norm_init = np.array(init_cond, dtype=sol.dtype)\n        # Calculate the reciprocal of the norm_init\n        recip = 1.0 / norm_init\n        # Normalize the solution by multiplying by the reciprocal of the norm_init\n        sol *= recip[np.newaxis, :]\n    # Extract the phosphorylated sites from the solution\n    P_fitted = sol[:, 2:].T\n    # Return the solution and the phosphorylated sites\n    return sol, P_fitted\n</code></pre>"},{"location":"reference/#models.randmod.ode_system","title":"<code>ode_system(y, t, A, B, C, D, num_sites, binary_states, PHOSPHO_TARGET, DEPHOSPHO_TARGET, *params)</code>","text":"<p>The ODE system for the random phosphorylation model. This function computes the derivatives of the variables R, P, and X at each time step.</p> <ul> <li>R is the concentration of the receptor</li> <li>P is the concentration of the protein</li> <li>X is the concentration of the phosphorylated states</li> <li>S is the phosphorylation rate for each site</li> <li>D_deg is the degradation rate for each state</li> <li>A, B, C, D are parameters for the system</li> <li>num_sites is the number of phosphorylation sites</li> <li>binary_states is a 2D array representing the binary states of the system</li> <li>PHOSPHO_TARGET is a 2D array representing the phosphorylation targets</li> <li>DEPHOSPHO_TARGET is a 2D array representing the dephosphorylation targets</li> </ul> <p>:param y:     y[0] = R     y[1] = P     y[2:] = X :param t: :param A: :param B: :param C: :param D: :param num_sites: :param binary_states: :param PHOSPHO_TARGET: :param DEPHOSPHO_TARGET: :param params: :return:</p> Source code in <code>models/randmod.py</code> <pre><code>@njit\ndef ode_system(y, t, A, B, C, D, num_sites, binary_states, PHOSPHO_TARGET, DEPHOSPHO_TARGET, *params):\n    \"\"\"\n    The ODE system for the random phosphorylation model. This function computes the derivatives of the\n    variables R, P, and X at each time step.\n\n    - R is the concentration of the receptor\n    - P is the concentration of the protein\n    - X is the concentration of the phosphorylated states\n    - S is the phosphorylation rate for each site\n    - D_deg is the degradation rate for each state\n    - A, B, C, D are parameters for the system\n    - num_sites is the number of phosphorylation sites\n    - binary_states is a 2D array representing the binary states of the system\n    - PHOSPHO_TARGET is a 2D array representing the phosphorylation targets\n    - DEPHOSPHO_TARGET is a 2D array representing the dephosphorylation targets\n\n    :param y:\n        y[0] = R\n        y[1] = P\n        y[2:] = X\n    :param t:\n    :param A:\n    :param B:\n    :param C:\n    :param D:\n    :param num_sites:\n    :param binary_states:\n    :param PHOSPHO_TARGET:\n    :param DEPHOSPHO_TARGET:\n    :param params:\n    :return:\n    \"\"\"\n    # Number of states\n    num_states = 2 ** num_sites - 1\n    # Phosphorylation rates\n    S = np.empty(num_sites)\n    for j in range(num_sites):\n        # Convert the j-th parameter to a phosphorylation rate\n        S[j] = params[j]\n    # Dephosphorylation rates\n    D_deg = np.empty(num_states)\n    for i in range(num_states):\n        # Convert the i-th parameter to a dephosphorylation rate\n        D_deg[i] = params[num_sites + i]\n    # Initialize the derivatives\n    R = y[0]\n    P = y[1]\n    X = y[2:]\n    dR_dt = A - B * R\n    sum_S = 0.0\n    for j in range(num_sites):\n        sum_S += S[j]\n    # Gain from phosphorylation\n    gain_1site = 0.0\n    # Loop over all states\n    for i in range(num_states):\n        cnt = 0\n        # Count the number of phosphorylated sites in the state\n        for j in range(num_sites):\n            # Check if the j-th site is phosphorylated in the state\n            cnt += binary_states[i, j]\n        # If the state has only one phosphorylated site, add the gain to the total\n        if cnt == 1:\n            gain_1site += X[i]\n    # Protein dynamics\n    dP_dt = C * R - D * P - sum_S * P + gain_1site\n    # Initialize the derivative of X\n    dX_dt = np.zeros(num_states)\n    for i in range(num_states):\n        for j in range(num_sites):\n            # Check if the j-th site is not phosphorylated in the i-th state\n            if binary_states[i, j] == 0:\n                # Get the phosphorylation target for the i-th state and j-th site\n                target = PHOSPHO_TARGET[i, j]\n                # If the target state is valid, add the phosphorylation rate to the derivative\n                if target &gt;= 0:\n                    dX_dt[target] += S[j] * X[i]\n\n    for i in range(num_states):\n        # Check if the i-th state is phosphorylated\n        loss = 0.0\n        for j in range(num_sites):\n            # Check if the j-th site is phosphorylated in the i-th state\n            if binary_states[i, j] == 0:\n                # Add loss to the total\n                loss += S[j]\n        # If the state has only one phosphorylated site, add the loss to the derivative\n        dX_dt[i] -= loss * X[i]\n\n    for i in range(num_states):\n        cnt = 0\n        for j in range(num_sites):\n            # Count the number of phosphorylated sites in the state\n            cnt += binary_states[i, j]\n        # Add the dephosphorylation rate to the derivative\n        dX_dt[i] -= cnt * X[i]\n\n    for i in range(num_states):\n        # Check if the i-th state is phosphorylated\n        for j in range(num_sites):\n            # Check if the j-th site is phosphorylated in the i-th state\n            if binary_states[i, j] == 1:\n                # Get the dephosphorylation target for the i-th state and j-th site\n                lower = DEPHOSPHO_TARGET[i, j]\n                # If the target state is valid, add the dephosphorylation rate to the derivative of P\n                if lower == -2:\n                    dP_dt += S[j] * X[i]\n                # If the target state is valid, add the dephosphorylation rate to the derivative of X\n                elif lower &gt;= 0:\n                    dX_dt[lower] += S[j] * X[i]\n\n    for i in range(num_states):\n        # Add the degradation rates to the derivative of X\n        dX_dt[i] -= D_deg[i] * X[i]\n    # Pack the derivatives into a single array\n    dydt = np.empty(2 + num_states)\n    dydt[0] = dR_dt\n    dydt[1] = dP_dt\n    # Pack the derivatives of X into the array\n    for i in range(num_states):\n        dydt[2 + i] = dX_dt[i]\n    # Return the derivatives\n    return dydt\n</code></pre>"},{"location":"reference/#models.randmod.prepare_vectorized_arrays","title":"<code>prepare_vectorized_arrays(num_sites)</code>","text":"<p>Prepare vectorized arrays for the Random ODE system. It creates binary states, phosphorylation targets, and dephosphorylation targets.</p> <p>Binary states are represented as a 2D array where each row corresponds to a state and each column corresponds to a phosphorylation site.</p> <p>Phosphorylation and Dephosphorylation targets are represented as 2D arrays where each row corresponds to a state and each column corresponds to a phosphorylation site.</p> <p>Target values indicate the resulting state after phosphorylation or dephosphorylation.</p> <p>:param num_sites: Number of phosphorylation sites :return: binary_states, PHOSPHO_TARGET, DEPHOSPHO_TARGET</p> Source code in <code>models/randmod.py</code> <pre><code>def prepare_vectorized_arrays(num_sites):\n    \"\"\"\n    Prepare vectorized arrays for the Random ODE system.\n    It creates binary states, phosphorylation targets, and dephosphorylation targets.\n\n    Binary states are represented as a 2D array where each row corresponds to a state\n    and each column corresponds to a phosphorylation site.\n\n    Phosphorylation and Dephosphorylation targets are represented as 2D arrays where\n    each row corresponds to a state and each column corresponds to a phosphorylation site.\n\n    Target values indicate the resulting state after phosphorylation or dephosphorylation.\n\n    :param num_sites: Number of phosphorylation sites\n    :return: binary_states, PHOSPHO_TARGET, DEPHOSPHO_TARGET\n    \"\"\"\n    # Calculate the number of states\n    num_states = 2 ** num_sites - 1\n    # Create binary states\n    binary_states = np.empty((num_states, num_sites), dtype=np.int32)\n    # Fill the binary states array\n    for i in range(num_states):\n        # Convert the state number to binary representation\n        state = i + 1\n        # Fill the binary states array\n        for j in range(num_sites):\n            # Check if the j-th bit is set in the state number\n            binary_states[i, j] = 1 if (state &amp; (1 &lt;&lt; j)) != 0 else 0\n    # Create phosphorylation target arrays\n    PHOSPHO_TARGET = -np.ones((num_states, num_sites), dtype=np.int32)\n    # Fill the phosphorylation target array\n    for i in range(num_states):\n        # Convert the state number to binary representation\n        state = i + 1\n        # Fill the phosphorylation target array\n        for j in range(num_sites):\n            # Check if the j-th bit is not set in the state number\n            if binary_states[i, j] == 0:\n                # Set the j-th bit in the state number\n                target_state = state | (1 &lt;&lt; j)\n                # Check if the target state is within the valid range\n                if target_state &lt;= num_states:\n                    # Set the target state in the phosphorylation target array\n                    PHOSPHO_TARGET[i, j] = target_state - 1\n                else:\n                    # Set the target state to -1 if out of range\n                    PHOSPHO_TARGET[i, j] = -1\n            else:\n                # If the j-th bit is set, set the target state to -1\n                PHOSPHO_TARGET[i, j] = -1\n    # Create dephosphorylation target array\n    DEPHOSPHO_TARGET = -np.ones((num_states, num_sites), dtype=np.int32)\n    # Fill the dephosphorylation target array\n    for i in range(num_states):\n        # Convert the state number to binary representation\n        state = i + 1\n        # Fill the dephosphorylation target array\n        for j in range(num_sites):\n            # Check if the j-th bit is set in the state number\n            if binary_states[i, j] == 1:\n                # Set the j-th bit to 0 in the state number\n                lower_state = state &amp; ~(1 &lt;&lt; j)\n                # Check if the lower state is within the valid range\n                if lower_state == 0:\n                    # Set the target state to -2 if the lower state is 0\n                    DEPHOSPHO_TARGET[i, j] = -2\n                else:\n                    # Set the target state in the dephosphorylation target array\n                    DEPHOSPHO_TARGET[i, j] = lower_state - 1\n            else:\n                # If the j-th bit is not set, set the target state to -1\n                DEPHOSPHO_TARGET[i, j] = -1\n\n    return binary_states, PHOSPHO_TARGET, DEPHOSPHO_TARGET\n</code></pre>"},{"location":"reference/#models.randmod.solve_ode","title":"<code>solve_ode(popt, initial_conditions, num_psites, time_points)</code>","text":"<p>Solve the Random ODE system using the provided parameters and initial conditions. The function integrates the ODE system over the specified time points and returns the solution.</p> <p>:param popt: :param initial_conditions: :param num_psites: :param time_points: :return: solution, solution of phosphorylated states for each site</p> Source code in <code>models/randmod.py</code> <pre><code>def solve_ode(popt, initial_conditions, num_psites, time_points):\n    \"\"\"\n    Solve the Random ODE system using the provided parameters and initial conditions.\n    The function integrates the ODE system over the specified time points and returns\n    the solution.\n\n    :param popt:\n    :param initial_conditions:\n    :param num_psites:\n    :param time_points:\n    :return: solution, solution of phosphorylated states for each site\n    \"\"\"\n    binary_states, PHOSPHO_TARGET, DEPHOSPHO_TARGET = prepare_vectorized_arrays(num_psites)\n    ode_params = popt\n    A_val, B_val, C_val, D_val = ode_params[:4]\n    remaining = ode_params[4:]\n    sol = np.asarray(odeint(ode_system, initial_conditions, time_points,\n                 args=(A_val, B_val, C_val, D_val, num_psites,\n                       binary_states, PHOSPHO_TARGET, DEPHOSPHO_TARGET, *remaining)))\n    np.clip(sol, 0, None, out=sol)\n    if NORMALIZE_MODEL_OUTPUT:\n        norm_ic = np.array(initial_conditions, dtype=sol.dtype)\n        recip = 1.0 / norm_ic\n        sol *= recip[np.newaxis, :]\n    if num_psites &gt; 1:\n        P_fitted = sol[:, 2:2 + num_psites].T\n    else:\n        P_fitted = sol[:, 2]\n    return sol, P_fitted\n</code></pre>"},{"location":"reference/#models.succmod.ode_core","title":"<code>ode_core(y, A, B, C, D, S_rates, D_rates)</code>","text":"<p>The core of the ODE system for the successive ODE model.</p> <p>The system is defined by the following equations: dR/dt = A - B * R dP/dt = C * R - D * P - S_rates[0] * P + sum(P_sites) dP_sites[i]/dt = S_rates[i] * P - (1.0 + D_rates[i]) * P_sites[i]</p> <p>where: R: the concentration of the mRNA P: the concentration of the protein P_sites: the concentration of the phosphorylated sites A: the rate of production of the mRNA B: the rate of degradation of the mRNA C: the rate of production of the protein D: the rate of degradation of the protein S_rates: the rates of phosphorylation of each site D_rates: the rates of dephosphorylation of each site</p> <p>:param y: :param A: :param B: :param C: :param D: :param S_rates: :param D_rates: :return: derivative of y</p> Source code in <code>models/succmod.py</code> <pre><code>@njit\ndef ode_core(y, A, B, C, D, S_rates, D_rates):\n    \"\"\"\n    The core of the ODE system for the successive ODE model.\n\n    The system is defined by the following equations:\n    dR/dt = A - B * R\n    dP/dt = C * R - D * P - S_rates[0] * P + sum(P_sites)\n    dP_sites[i]/dt = S_rates[i] * P - (1.0 + D_rates[i]) * P_sites[i]\n\n    where:\n    R: the concentration of the mRNA\n    P: the concentration of the protein\n    P_sites: the concentration of the phosphorylated sites\n    A: the rate of production of the mRNA\n    B: the rate of degradation of the mRNA\n    C: the rate of production of the protein\n    D: the rate of degradation of the protein\n    S_rates: the rates of phosphorylation of each site\n    D_rates: the rates of dephosphorylation of each site\n\n    :param y:\n    :param A:\n    :param B:\n    :param C:\n    :param D:\n    :param S_rates:\n    :param D_rates:\n    :return: derivative of y\n    \"\"\"\n    # mRNA\n    R = y[0]\n    # Protein\n    P = y[1]\n    # Number of phosphorylated sites\n    num_psites = S_rates.shape[0]\n\n    # mRNA dynamics\n    dR_dt = A - B * R\n    # Protein dynamics\n    dP_dt = C * R - D * P\n\n    # Adjust protein dynamics by phosphorylation/dephosphorylation of the first site if exists\n    if num_psites &gt; 0:\n        # Subtract phosphorylation contribution from the protein at site 0\n        dP_dt -= S_rates[0] * P\n        # Add dephosphorylation feedback from the first phosphorylated site\n        dP_dt += y[2]\n\n    # Prepare output array for derivatives\n    dydt = np.empty_like(y)\n    dydt[0] = dR_dt\n    dydt[1] = dP_dt\n\n    # Phosphorylated sites dynamics loop\n    for i in range(num_psites):\n        # When there is only one site, handle it separately\n        if num_psites == 1:\n            # For one phosphorylated site:\n            # Calculate the site's rate: phosphorylation from the protein minus its degradation (combined rate).\n            dydt[2] = S_rates[0] * P - (1 + D_rates[0]) * y[2]\n        else:\n            if i == 0:\n                # For the first site:\n                # Phosphorylation of the protein contributes to the site dynamics.\n                # Site feedback: rate from the second site affects the current site.\n                # The term y[3] provides dephosphorylation feedback.\n                dydt[2] = S_rates[0] * P - (1 + S_rates[1] + D_rates[0]) * y[2] + y[3]\n            elif i &lt; num_psites - 1:\n                # For intermediate sites:\n                # Phosphorylation from the preceding phosphorylated species (y[1+i]) drives the site.\n                # The degradation rate is increased by the phosphorylation rate of the next site (S_rates[i+1]).\n                # The term y[3+i] provides dephosphorylation feedback from the next site.\n                dydt[2 + i] = S_rates[i] * y[1 + i] - (1 + S_rates[i + 1] + D_rates[i]) * y[2 + i] + y[3 + i]\n            else:\n                # For the last site:\n                # Phosphorylation from the preceding site (y[1+i]) drives the site.\n                # There is no next phosphorylation term, so only include the dephosphorylation degradation.\n                dydt[2 + i] = S_rates[i] * y[1 + i] - (1 + D_rates[i]) * y[2 + i]\n    return dydt\n</code></pre>"},{"location":"reference/#models.succmod.ode_system","title":"<code>ode_system(y, t, params, num_psites)</code>","text":"<p>The ODE system for the successive ODE model.</p> <p>:param y: :param t: :param params: :param num_psites: :return: ode_core(y, A, B, C, D, S_rates, D_rates)</p> Source code in <code>models/succmod.py</code> <pre><code>def ode_system(y, t, params, num_psites):\n    \"\"\"\n    The ODE system for the successive ODE model.\n\n    :param y:\n    :param t:\n    :param params:\n    :param num_psites:\n    :return: ode_core(y, A, B, C, D, S_rates, D_rates)\n    \"\"\"\n    A, B, C, D = params[0], params[1], params[2], params[3]\n    S_rates = np.array([params[4 + i] for i in range(num_psites)])\n    D_rates = np.array([params[4 + num_psites + i] for i in range(num_psites)])\n    return ode_core(y, A, B, C, D, S_rates, D_rates)\n</code></pre>"},{"location":"reference/#models.succmod.solve_ode","title":"<code>solve_ode(params, init_cond, num_psites, t)</code>","text":"<p>Solve the ODE system using the given parameters and initial conditions. The function integrates the ODE system over time and returns the solution.</p> <p>:param params: :param init_cond: :param num_psites: :param t: :return: solution, solution of phosphorylated sites</p> Source code in <code>models/succmod.py</code> <pre><code>def solve_ode(params, init_cond, num_psites, t):\n    \"\"\"\n    Solve the ODE system using the given parameters and initial conditions.\n    The function integrates the ODE system over time and returns the solution.\n\n    :param params:\n    :param init_cond:\n    :param num_psites:\n    :param t:\n    :return: solution, solution of phosphorylated sites\n    \"\"\"\n    sol = np.asarray(odeint(ode_system, init_cond, t, args=(params, num_psites)))\n    np.clip(sol, 0, None, out=sol)\n    if NORMALIZE_MODEL_OUTPUT:\n        norm_init = np.array(init_cond, dtype=sol.dtype)\n        recip = 1.0 / norm_init\n        sol *= recip[np.newaxis, :]\n    P_fitted = sol[:, 2:].T\n    return sol, P_fitted\n</code></pre>"},{"location":"reference/#models.weights.early_emphasis","title":"<code>early_emphasis(p_data, time_points, num_psites)</code>","text":"<p>Function that calculates custom weights for early time points in a dataset. The weights are based on the data values and the time differences between points.</p> <p>The weights are calculated in a way that emphasizes early time points, while also considering the data values and time intervals.</p> <p>:param p_data: :param time_points: :param num_psites: :return: flattened array of custom weights</p> Source code in <code>models/weights.py</code> <pre><code>@njit\ndef early_emphasis(p_data, time_points, num_psites):\n    \"\"\"\n    Function that calculates custom weights for early time points in a dataset.\n    The weights are based on the data values and the time differences between points.\n\n    The weights are calculated in a way that emphasizes early time points,\n    while also considering the data values and time intervals.\n\n    :param p_data:\n    :param time_points:\n    :param num_psites:\n    :return: flattened array of custom weights\n    \"\"\"\n    if p_data.ndim == 1:\n        p_data = p_data.reshape(1, p_data.size)\n\n    n_times = len(time_points)\n    custom_weights = np.ones((num_psites, n_times))\n\n    time_diffs = np.empty(n_times)\n    time_diffs[0] = 0.0\n\n    # Calculate time differences\n    for j in range(1, n_times):\n        # Subtract the previous time point from the current one\n        time_diffs[j] = time_points[j] - time_points[j - 1]\n\n    for i in range(num_psites):\n        # Emphasize early time points - first five\n        limit = min(5, n_times)\n        # Compute weights for early time points\n        for j in range(1, limit):\n            # Calculate the data-based and time-based weights\n            data_based_weight = 1.0 / (abs(p_data[i, j]) + 1e-5)\n            time_based_weight = 1.0 / (time_diffs[j] + 1e-5)\n            # Combine the weights\n            custom_weights[i, j] = data_based_weight * time_based_weight\n        for j in range(5, n_times):\n            # For later time points, use a fixed weight\n            custom_weights[i, j] = 1.0\n\n    return custom_weights.ravel()\n</code></pre>"},{"location":"reference/#models.weights.get_weight_options","title":"<code>get_weight_options(target, t_target, num_psites, use_regularization, reg_len, early_weights)</code>","text":"<p>Function to calculate weights for parameter estimation based on the target data and time points. The weights are designed to emphasize early time points and account for noise in the data. The function also includes options for regularization and custom early point emphasis.</p> <p>The following are the weighting schemes: - Inverse data: 1 / abs(target) - Exponential decay: exp(-0.5 * target) - Log scale: 1 / log(1 + abs(target)) - Time difference: 1 / abs(time_diff) - Moving average: 1 / abs(target - moving_avg) - Sigmoid time decay: 1 / (1 + exp(time_indices - 5)) - Exponential early emphasis: exp(-0.5 * time_indices) - Polynomial decay: 1 / (1 + 0.5 * time_indices) - MS SNR model: 1 / sqrt(signal) - MS inverse variance: 1 / (abs(target) ** 0.7) - Flat region penalty: 1 / abs(grad) - Steady state decay: exp(-0.1 * time_indices) - Combined data time: 1 / (abs(target) * (1 + 0.5 * time_indices)) - Inverse sqrt data: 1 / sqrt(abs(target)) - Early emphasis moderate: ones - Early emphasis steep decay: ones - Custom early points emphasis: early_weights</p> <p>:param target: :param t_target: :param num_psites: :param use_regularization: :param reg_len: :param early_weights: :return: dictionary of weights for parameter estimation</p> Source code in <code>models/weights.py</code> <pre><code>def get_weight_options(target, t_target, num_psites, use_regularization, reg_len, early_weights):\n    \"\"\"\n    Function to calculate weights for parameter estimation based on the target data and time points.\n    The weights are designed to emphasize early time points and account for noise in the data.\n    The function also includes options for regularization and custom early point emphasis.\n\n    The following are the weighting schemes:\n    - Inverse data: 1 / abs(target)\n    - Exponential decay: exp(-0.5 * target)\n    - Log scale: 1 / log(1 + abs(target))\n    - Time difference: 1 / abs(time_diff)\n    - Moving average: 1 / abs(target - moving_avg)\n    - Sigmoid time decay: 1 / (1 + exp(time_indices - 5))\n    - Exponential early emphasis: exp(-0.5 * time_indices)\n    - Polynomial decay: 1 / (1 + 0.5 * time_indices)\n    - MS SNR model: 1 / sqrt(signal)\n    - MS inverse variance: 1 / (abs(target) ** 0.7)\n    - Flat region penalty: 1 / abs(grad)\n    - Steady state decay: exp(-0.1 * time_indices)\n    - Combined data time: 1 / (abs(target) * (1 + 0.5 * time_indices))\n    - Inverse sqrt data: 1 / sqrt(abs(target))\n    - Early emphasis moderate: ones\n    - Early emphasis steep decay: ones\n    - Custom early points emphasis: early_weights\n\n    :param target:\n    :param t_target:\n    :param num_psites:\n    :param use_regularization:\n    :param reg_len:\n    :param early_weights:\n    :return: dictionary of weights for parameter estimation\n    \"\"\"\n    time_indices = np.tile(np.arange(1, len(t_target) + 1), num_psites)\n    log_scale = np.log1p(np.abs(target))\n    sqrt_signal = np.sqrt(np.maximum(np.abs(target), 1e-5))\n\n    # Noise-aware weights\n    signal_noise_model = 1 / sqrt_signal  # MS-like error model\n    inverse_variance_model = 1 / (np.maximum(np.abs(target), 1e-5) ** 0.7)  # empirical fit\n\n    # Biological modeling\n    early_sigmoid = 1 / (1 + np.exp((time_indices - 5)))\n    steady_state_decay = np.exp(-0.1 * time_indices)  # Less weight to late points\n    # fallback for flat region penalty\n    if len(target) &gt;= 2:\n        grad = np.gradient(target)\n        flat_region_penalty = 1 / np.maximum(np.abs(grad), 1e-5)\n    else:\n        # Early time points\u2014biologically inspired\n        flat_region_penalty = 1 / np.maximum(np.abs(target), 1e-5)  # inverse signal intensity\n\n    base_weights = {\n        \"inverse_data\": 1 / np.maximum(np.abs(target), 1e-5),\n        \"exp_decay\": np.exp(-0.5 * target),\n        \"log_scale\": 1 / np.maximum(log_scale, 1e-5),\n        \"time_diff\": 1 / np.maximum(np.abs(np.diff(target, prepend=target[0])), 1e-5),\n        \"moving_avg\": 1 / np.maximum(np.abs(target - uniform_filter1d(target, 3)), 1e-5),\n\n        \"sigmoid_time_decay\": early_sigmoid,\n        \"exponential_early_emphasis\": np.exp(-0.5 * time_indices),\n        \"polynomial_decay\": 1 / (1 + 0.5 * time_indices),\n\n        \"ms_snr_model\": signal_noise_model,\n        \"ms_inverse_variance\": inverse_variance_model,\n        \"flat_region_penalty\": flat_region_penalty,\n        \"steady_state_decay\": steady_state_decay,\n\n        \"combined_data_time\": 1 / (np.maximum(np.abs(target), 1e-5) * (1 + 0.5 * time_indices)),\n        \"inverse_sqrt_data\": 1 / sqrt_signal,\n\n        \"early_emphasis_moderate\": np.ones_like(target),\n        \"early_emphasis_steep_decay\": (\n            np.tile(np.concatenate([\n                np.full(8, 0.05), np.full(2, 0.2), np.ones(max(0, len(t_target) * num_psites - 10))]), 1)\n            if len(t_target) * num_psites &gt;= 10 else np.ones(len(target))\n        ),\n        \"custom_early_points_emphasis\": early_weights\n    }\n\n    if use_regularization:\n        base_weights = {\n            k: np.concatenate([v, np.ones(reg_len)])\n            for k, v in base_weights.items()\n        }\n\n    return base_weights\n</code></pre>"},{"location":"reference/#paramest.adapest.adaptive_estimation","title":"<code>adaptive_estimation(p_data, init_cond, num_psites, time_points, t, bounds, fixed_params, gene, bootstraps=0, extra_fixed=None, use_regularization=USE_REGULARIZATION, lambda_reg=LAMBDA_REG)</code>","text":"<p>Adaptive estimation of parameters using curve fitting. This function estimates the parameters of the model using curve fitting. Parameter will be fixed at certain time points.</p> <p>:param p_data: :param init_cond: :param num_psites: :param time_points: :param t: :param bounds: :param fixed_params: :param gene: :param bootstraps: :param extra_fixed: :param use_regularization: :param lambda_reg: :return: estimated parameters</p> Source code in <code>paramest/adapest.py</code> <pre><code>def adaptive_estimation(p_data, init_cond, num_psites, time_points, t,\n                        bounds, fixed_params, gene, bootstraps=0, extra_fixed=None,\n                        use_regularization=USE_REGULARIZATION, lambda_reg=LAMBDA_REG):\n    \"\"\"\n    Adaptive estimation of parameters using curve fitting.\n    This function estimates the parameters of the model using curve fitting.\n    Parameter will be fixed at certain time points.\n\n    :param p_data:\n    :param init_cond:\n    :param num_psites:\n    :param time_points:\n    :param t:\n    :param bounds:\n    :param fixed_params:\n    :param gene:\n    :param bootstraps:\n    :param extra_fixed:\n    :param use_regularization:\n    :param lambda_reg:\n    :return: estimated parameters\n    \"\"\"\n    # Get the index of the time points that are less than or equal to t.\n    t_idx = np.where(time_points &lt;= t)[0]\n    t_target = time_points[t_idx]\n    p_interp = np.zeros((num_psites, len(t_target)))\n\n    # Interpolate the data to get the values at the target time points.\n    for i in range(num_psites):\n        # Get the values at the target time points.\n        y_vals = p_data.iloc[i, 2:].values if isinstance(p_data, pd.DataFrame) else p_data[i, 2:]\n        # Interpolate the values at the target time points.\n        interp_func = PchipInterpolator(time_points, y_vals)\n        # Get the values at the target time points.\n        p_interp[i, :] = interp_func(t_target)\n\n    full_fixed = fixed_params.copy()\n    if extra_fixed:\n        full_fixed.update(extra_fixed)\n\n    # Get model function and bounds.\n    model_func, free_idx, free_bounds, fixed_vals, total_params = prepare_model_func(\n        num_psites, init_cond, bounds,\n        full_fixed, use_regularization, lambda_reg\n    )\n\n    # Initial values for the free parameters.\n    p0 = np.array([(l + u) / 2 for l, u in zip(*free_bounds)])\n    target = p_interp.flatten()\n\n    # Make the fitting vector the same size as the model.\n    target_fit = np.concatenate([target, np.zeros(len(p0))]) if use_regularization else target\n    default_sigma = 1 / np.maximum(np.abs(target_fit), 1e-5)\n\n    try:\n        # Perform initial fit to get starting values.\n        result = cast(Tuple[np.ndarray, np.ndarray],\n                      curve_fit(model_func, t_target, target_fit, p0=p0,\n                                bounds=free_bounds, sigma=default_sigma,\n                                absolute_sigma=True, maxfev=20000))\n        popt_init, _ = result\n    except Exception as e:\n        logger.warning(f\"[{gene}] T={t} init fit failed: {e}\")\n        popt_init = p0\n\n    # Get weight options for the fit.\n    early_weights = early_emphasis(p_interp, t_target, num_psites)\n    weight_options = get_weight_options(target, t_target, num_psites, use_regularization, len(p0), early_weights)\n\n    # Make a dictionary of the weights, and parameters.\n    scores, popts = {}, {}\n    for wname, sigma in weight_options.items():\n        try:\n            # Perform the fit with the weights.\n            result = cast(Tuple[np.ndarray, np.ndarray],\n                          curve_fit(model_func, t_target, target_fit, p0=popt_init,\n                                    bounds=free_bounds, sigma=sigma,\n                                    absolute_sigma=True, maxfev=20000))\n            popt_weight, _ = result\n        except Exception as e:\n            logger.warning(f\"[{gene}] T={t} fit failed for {wname}: {e}\")\n            popt_weight = popt_init\n        popts[wname] = popt_weight\n        pred = model_func(t_target, *popt_weight)\n        # Calculate the score for the fit.\n        scores[wname] = score_fit(target_fit, pred, popt_weight)\n\n    # Get the best weight and score.\n    best_weight = min(scores, key=scores.get)\n    best_score = scores[best_weight]\n    # Get the best parameters.\n    popt_best = popts[best_weight]\n    # Display the best weight and score for time points.\n    logger.info(f\"[{gene}] Time = {t} Best Weight = {best_weight} Score: {best_score:.2f}\")\n\n    if bootstraps &gt; 0:\n        logger.info(f\"[{gene}] Bootstrapping {bootstraps}x at T = {t}\")\n        # Perform bootstrapping to get the final parameters.\n        est_list = []\n\n        for _ in range(bootstraps):\n            # Generate bootstrap samples.\n            noise = np.random.normal(0, 0.05, size=target_fit.shape)\n            noisy_target = target_fit * (1 + noise)\n            try:\n                # Perform the fit with the bootstrap samples.\n                result = cast(Tuple[np.ndarray, np.ndarray],\n                              curve_fit(model_func, t_target, noisy_target, p0=popt_best,\n                                        bounds=free_bounds, sigma=weight_options[best_weight],\n                                        absolute_sigma=True, maxfev=20000))\n                popt_weight_bootstrap, _ = result\n            except (RuntimeError, ValueError) as e:\n                logger.warning(f\"[{gene}] Bootstrap fit failed: {e}\")\n                popt_weight_bootstrap = popt_best\n            est_list.append(popt_weight_bootstrap)\n\n        # Get the best parameters from bootstrap samples.\n        popt_best = np.mean(est_list, axis=0)\n\n    p_full = np.zeros(total_params)\n    free_iter = iter(popt_best)\n\n    # Fill in the fixed values.\n    for i in range(total_params):\n        # If the index is in the fixed values, use the fixed value.\n        p_full[i] = fixed_vals[i] if i in fixed_vals else next(free_iter)\n\n    return p_full\n</code></pre>"},{"location":"reference/#paramest.adapest.estimate_profiles","title":"<code>estimate_profiles(gene, p_data, init_cond, num_psites, time_points, desired_times, bounds, fixed_params, bootstraps, time_fixed_dict)</code>","text":"<p>Estimate adaptive profiles for a given gene at specified time points. This function estimates the parameters of the model using adaptive estimation. The parameters are estimated at the specified time points and stored in a DataFrame. The function also plots the profiles.</p> <p>:param gene: :param p_data: :param init_cond: :param num_psites: :param time_points: :param desired_times: :param bounds: :param fixed_params: :param bootstraps: :param time_fixed_dict: :return: dataframe, profiles</p> Source code in <code>paramest/adapest.py</code> <pre><code>def estimate_profiles(gene, p_data, init_cond, num_psites, time_points, desired_times,\n                      bounds, fixed_params, bootstraps, time_fixed_dict):\n    \"\"\"\n    Estimate adaptive profiles for a given gene at specified time points.\n    This function estimates the parameters of the model using adaptive estimation.\n    The parameters are estimated at the specified time points and stored in a DataFrame.\n    The function also plots the profiles.\n\n    :param gene:\n    :param p_data:\n    :param init_cond:\n    :param num_psites:\n    :param time_points:\n    :param desired_times:\n    :param bounds:\n    :param fixed_params:\n    :param bootstraps:\n    :param time_fixed_dict:\n    :return: dataframe, profiles\n    \"\"\"\n    profiles = {}\n    for T in desired_times:\n        # logger.info(f\"[{gene}] Estimating Adaptive Profile at T = {T}\")\n        extra_fixed = time_fixed_dict.get(str(T), {})\n        profiled_params = adaptive_estimation(p_data, init_cond, num_psites, time_points, T,\n                                              bounds, fixed_params, gene, bootstraps, extra_fixed)\n        profiles[T] = profiled_params\n\n    param_names = get_param_names(num_psites)\n    data = {\"Time\": list(profiles.keys())}\n    for i, name in enumerate(param_names):\n        data[name] = [profiles[T][i] for T in desired_times]\n    df = pd.DataFrame(data)\n    plotter = Plotter(gene)\n    plotter.plot_profiles(df)\n    return df, profiles\n</code></pre>"},{"location":"reference/#paramest.adapest.prepare_model_func","title":"<code>prepare_model_func(num_psites, init_cond, bounds, fixed_params, use_regularization=USE_REGULARIZATION, lambda_reg=LAMBDA_REG)</code>","text":"<p>Prepares the model function for curve fitting. Adaptive Estimation is used to estimate the parameters of the model.</p> <p>:param num_psites: :param init_cond: :param bounds: :param fixed_params: :param use_regularization: :param lambda_reg: :return: model function, free indices, free bounds, fixed values, total params</p> Source code in <code>paramest/adapest.py</code> <pre><code>def prepare_model_func(num_psites, init_cond, bounds, fixed_params,\n                       use_regularization=USE_REGULARIZATION, lambda_reg=LAMBDA_REG):\n    \"\"\"\n    Prepares the model function for curve fitting.\n    Adaptive Estimation is used to estimate the parameters of the model.\n\n    :param num_psites:\n    :param init_cond:\n    :param bounds:\n    :param fixed_params:\n    :param use_regularization:\n    :param lambda_reg:\n    :return: model function, free indices, free bounds, fixed values, total params\n    \"\"\"\n    if ODE_MODEL == 'randmod':\n        # Build lower and upper bounds from config.\n        lower_bounds_full = [\n            bounds[\"A\"][0], bounds[\"B\"][0], bounds[\"C\"][0], bounds[\"D\"][0]\n        ]\n        upper_bounds_full = [\n            bounds[\"A\"][1], bounds[\"B\"][1], bounds[\"C\"][1], bounds[\"D\"][1]\n        ]\n        # For phosphorylation parameters: use Ssite bounds.\n        lower_bounds_full += [bounds[\"Ssite\"][0]] * num_psites\n        upper_bounds_full += [bounds[\"Ssite\"][1]] * num_psites\n        # For dephosphorylation parameters: for each combination, use Dsite bounds.\n        for r in range(1, num_psites + 1):\n            for _ in combinations(range(1, num_psites + 1), r):\n                lower_bounds_full.append(bounds[\"Dsite\"][0])\n                upper_bounds_full.append(bounds[\"Dsite\"][1])\n        num_total_params = len(lower_bounds_full)\n    else:\n        # Existing approach for distributive or successive models.\n        num_total_params = 4 + 2 * num_psites\n        lower_bounds_full = (\n            [bounds[\"A\"][0], bounds[\"B\"][0], bounds[\"C\"][0], bounds[\"D\"][0]] +\n            [bounds[\"Ssite\"][0]] * num_psites +\n            [bounds[\"Dsite\"][0]] * num_psites\n        )\n        upper_bounds_full = (\n            [bounds[\"A\"][1], bounds[\"B\"][1], bounds[\"C\"][1], bounds[\"D\"][1]] +\n            [bounds[\"Ssite\"][1]] * num_psites +\n            [bounds[\"Dsite\"][1]] * num_psites\n        )\n    # Create a dictionary of fixed parameters.\n    fixed_values = {}\n    # Create a dictionary of fixed values.\n    free_indices = []\n    # Create a list of free indices.\n    param_names = get_param_names(num_psites)\n    for p, name in enumerate(param_names):\n        val = fixed_params.get(name)\n        if val is not None:\n            fixed_values[p] = val\n        else:\n            free_indices.append(p)\n\n    def model_func(t, *p_free):\n        \"\"\"\n        Model function for curve fitting.\n\n        :param t:\n        :param p_free:\n        :return: model\n        \"\"\"\n        p_full = np.zeros(num_total_params)\n        # Fill in the fixed values.\n        free_iter = iter(p_free)\n        # Fill in the free values.\n        for i in range(num_total_params):\n            # If the index is in the fixed values, use the fixed value.\n            p_full[i] = fixed_values[i] if i in fixed_values else next(free_iter)\n\n        _, p_fitted = solve_ode(p_full, init_cond, num_psites, np.atleast_1d(t))\n        y_model = p_fitted.flatten()\n        # If using regularization, add the regularization term.\n        if use_regularization:\n            # Add the regularization term.\n            reg = np.sqrt(lambda_reg) * np.array(p_free)\n            # Add the regularization term to the model.\n            return np.concatenate([y_model, reg])\n        # Return the model.\n        return y_model\n\n    # Create the free bounds.\n    free_bounds = ([lower_bounds_full[i] for i in free_indices],\n                   [upper_bounds_full[i] for i in free_indices])\n\n    # logger.info(\"Model built\")\n    return model_func, free_indices, free_bounds, fixed_values, num_total_params\n</code></pre>"},{"location":"reference/#paramest.core.process_gene","title":"<code>process_gene(gene, measurement_data, time_points, bounds, fixed_params, desired_times=None, time_fixed=None, bootstraps=0, out_dir=OUT_DIR)</code>","text":"<p>Process a single gene by estimating its parameters and generating plots. This function extracts gene-specific data, estimates parameters using the specified estimation mode, and generates plots for the estimated parameters and the model fits. It also calculates error metrics and saves the results to Excel files.</p> <p>:param gene: :param measurement_data: :param time_points: :param bounds: :param fixed_params: :param desired_times: :param time_fixed: :param bootstraps: :param out_dir: :return:     - gene: The gene being processed.     - estimated_params: Estimated parameters for the gene.     - model_fits: Model fits for the gene.     - seq_model_fit: Sequential model fit for the gene.     - errors: Error metrics (MSE, MAE).     - final_params: Final estimated parameters.     - profiles: Adaptive profile estimates (if applicable).     - profiles_df: DataFrame of adaptive profile estimates (if applicable).     - param_df: DataFrame of estimated parameters.     - gene_psite_data: Dictionary of gene-specific data.</p> Source code in <code>paramest/core.py</code> <pre><code>def process_gene(\n    gene,\n    measurement_data,\n    time_points,\n    bounds,\n    fixed_params,\n    desired_times=None,\n    time_fixed=None,\n    bootstraps=0,\n    out_dir=OUT_DIR\n):\n    \"\"\"\n    Process a single gene by estimating its parameters and generating plots.\n    This function extracts gene-specific data, estimates parameters using the\n    specified estimation mode, and generates plots for the estimated parameters\n    and the model fits. It also calculates error metrics and saves the results\n    to Excel files.\n\n    :param gene:\n    :param measurement_data:\n    :param time_points:\n    :param bounds:\n    :param fixed_params:\n    :param desired_times:\n    :param time_fixed:\n    :param bootstraps:\n    :param out_dir:\n    :return:\n        - gene: The gene being processed.\n        - estimated_params: Estimated parameters for the gene.\n        - model_fits: Model fits for the gene.\n        - seq_model_fit: Sequential model fit for the gene.\n        - errors: Error metrics (MSE, MAE).\n        - final_params: Final estimated parameters.\n        - profiles: Adaptive profile estimates (if applicable).\n        - profiles_df: DataFrame of adaptive profile estimates (if applicable).\n        - param_df: DataFrame of estimated parameters.\n        - gene_psite_data: Dictionary of gene-specific data.\n    \"\"\"\n    # 1. Extract Gene-specific Data\n    gene_data = measurement_data[measurement_data['Gene'] == gene]\n    num_psites = gene_data.shape[0]\n    psite_values = gene_data['Psite'].values\n    init_cond = initial_condition(num_psites)\n    P_data = gene_data.iloc[:, 2:].values\n\n    # 2. Choose estimation mode\n    estimation_mode = ESTIMATION_MODE\n\n    model_fits, estimated_params, seq_model_fit, errors = estimate_parameters(\n        estimation_mode, gene, P_data, init_cond, num_psites, time_points, bounds, fixed_params, bootstraps\n    )\n\n    # 7. Error Metrics\n    mse = mean_squared_error(P_data.flatten(), seq_model_fit.flatten())\n    mae = mean_absolute_error(P_data.flatten(), seq_model_fit.flatten())\n    logger.info(f\"{gene} \u2192 MSE: {mse:.4f}, MAE: {mae:.4f}\")\n\n    # 3. Adaptive Profile Estimation (Optional)\n    profiles_df, profiles_dict = None, None\n    if desired_times is not None and time_fixed is not None:\n        profiles_df, profiles_dict = estimate_profiles(\n            gene, measurement_data, init_cond, num_psites,\n            time_points, desired_times, bounds, fixed_params,\n            bootstraps, time_fixed\n        )\n        # Save profile Excel\n        profile_path = os.path.join(out_dir, f\"{gene}_profiles.xlsx\")\n        profiles_df.to_excel(profile_path, index=False)\n        # logger.info(f\"Profiled Estimates: {profile_path}\")\n\n    # 4. Solve Full ODE with Final Params\n    final_params = estimated_params[-1]\n    gene_psite_dict_local = {'Protein': gene}\n    for i, name in enumerate(get_param_names(num_psites)):\n        gene_psite_dict_local[name] = [final_params[i]]\n\n    sol_full, _ = solve_ode(final_params, init_cond, num_psites, time_points)\n\n    # 5. Plotting Outputs\n    labels = generate_labels(num_psites)\n    illustrate(gene, num_psites)\n    # Create a single Plotter instance.\n    plotter = Plotter(gene, out_dir)\n    # Call plot_all with all necessary data.\n    plotter.plot_all(solution=sol_full, labels=labels,\n                     estimated_params=estimated_params, time_points=time_points,\n                     P_data=P_data, seq_model_fit=seq_model_fit,\n                     psite_labels=psite_values, perplexity=5, components=3, target_variance=0.99)\n\n    # 6. Save Sequential Parameters to Excel\n    df_params = pd.DataFrame(estimated_params, columns=get_param_names(num_psites))\n    df_params.insert(0, \"Time\", time_points[:len(estimated_params)])\n    param_path = os.path.join(out_dir, f\"{gene}_parameters.xlsx\")\n    df_params.to_excel(param_path, index=False)\n    # logger.info(f\"Estimated Parameters: {param_path}\")\n\n    # 8. Return Results\n    return {\n        \"gene\": gene,\n        \"estimated_params\": estimated_params,\n        \"model_fits\": model_fits,\n        \"seq_model_fit\": seq_model_fit,\n        \"errors\": errors,\n        \"final_params\": final_params,\n        \"profiles\": profiles_dict,\n        \"profiles_df\": profiles_df,\n        \"param_df\": df_params,\n        \"gene_psite_data\": gene_psite_dict_local,\n        \"mse\": mse,\n        \"mae\": mae\n    }\n</code></pre>"},{"location":"reference/#paramest.core.process_gene_wrapper","title":"<code>process_gene_wrapper(gene, measurement_data, time_points, bounds, fixed_params, desired_times, time_fixed, bootstraps, out_dir=OUT_DIR)</code>","text":"<p>Wrapper function to process a gene. This function is a placeholder for any additional processing or modifications needed before calling the main processing function.</p> <p>:param gene: :param measurement_data: :param time_points: :param bounds: :param fixed_params: :param desired_times: :param time_fixed: :param bootstraps: :param out_dir: :return:     - result: Dictionary containing the results of the gene processing.</p> Source code in <code>paramest/core.py</code> <pre><code>def process_gene_wrapper(gene, measurement_data, time_points, bounds, fixed_params,\n                         desired_times, time_fixed, bootstraps, out_dir=OUT_DIR):\n    \"\"\"\n    Wrapper function to process a gene. This function is a placeholder for\n    any additional processing or modifications needed before calling the\n    main processing function.\n\n    :param gene:\n    :param measurement_data:\n    :param time_points:\n    :param bounds:\n    :param fixed_params:\n    :param desired_times:\n    :param time_fixed:\n    :param bootstraps:\n    :param out_dir:\n    :return:\n        - result: Dictionary containing the results of the gene processing.\n    \"\"\"\n    return process_gene(\n        gene=gene,\n        measurement_data=measurement_data,\n        time_points=time_points,\n        bounds=bounds,\n        fixed_params=fixed_params,\n        desired_times=desired_times,\n        time_fixed=time_fixed,\n        bootstraps=bootstraps,\n        out_dir=out_dir\n    )\n</code></pre>"},{"location":"reference/#paramest.identifiability.ci.confidence_intervals","title":"<code>confidence_intervals(popt, pcov, target, alpha_val=0.05)</code>","text":"<p>Computes the confidence intervals for parameter estimates using a linearization approach.</p> <p>Parameters:</p> Name Type Description Default <code>-</code> <code>popt</code> <p>1D numpy array of best-fit parameter estimates.</p> required <code>-</code> <code>pcov</code> <p>Square covariance matrix (numpy array) corresponding to popt.</p> required <code>-</code> <code>target</code> <p>1D numpy array of observed data (used to compute degrees of freedom).</p> required <code>-</code> <code>alpha_val</code> <p>Significance level (default 0.05 for a 95% confidence interval).</p> required <p>Returns:</p> Type Description <p>A dictionary with the following keys: 'beta_hat': Best-fit parameter estimates. 'se_lin': Standard errors (sqrt of diagonal of pcov). 'df_lin': Degrees of freedom (n_obs - n_params). 't_stat': t-statistics for each parameter. 'pval': Two-sided p-values for each parameter. 'qt_lin': t critical value for the given alpha and degrees of freedom. 'lwr_ci': Lower 95% confidence intervals. 'upr_ci': Upper 95% confidence intervals.</p> Source code in <code>paramest/identifiability/ci.py</code> <pre><code>def confidence_intervals(popt, pcov, target, alpha_val=0.05):\n    \"\"\"\n    Computes the confidence intervals for parameter estimates using a linearization approach.\n\n    Parameters:\n      - popt: 1D numpy array of best-fit parameter estimates.\n      - pcov: Square covariance matrix (numpy array) corresponding to popt.\n      - target: 1D numpy array of observed data (used to compute degrees of freedom).\n      - alpha_val: Significance level (default 0.05 for a 95% confidence interval).\n\n    Returns:\n      A dictionary with the following keys:\n        'beta_hat': Best-fit parameter estimates.\n        'se_lin': Standard errors (sqrt of diagonal of pcov).\n        'df_lin': Degrees of freedom (n_obs - n_params).\n        't_stat': t-statistics for each parameter.\n        'pval': Two-sided p-values for each parameter.\n        'qt_lin': t critical value for the given alpha and degrees of freedom.\n        'lwr_ci': Lower 95% confidence intervals.\n        'upr_ci': Upper 95% confidence intervals.\n    \"\"\"\n    if pcov is None:\n        msg = \"No covariance matrix available; cannot compute confidence intervals using linearization.\"\n        logger.info(msg)\n        return None\n\n    beta_hat = popt\n    se_lin = np.sqrt(np.diag(pcov))\n    # Degrees of freedom: number of observations (target should be 1D) minus number of parameters.\n    df_lin = target.size - beta_hat.size\n    # Compute t-statistics for each parameter.\n    t_stat = beta_hat / se_lin\n    # Two-sided p-values.\n    pval = stats.t.sf(np.abs(t_stat), df_lin) * 2\n    # t critical value for a two-tailed confidence interval.\n    qt_lin = stats.t.ppf(1 - alpha_val / 2, df_lin)\n    # Calculate confidence intervals.\n    lwr_ci = np.maximum(beta_hat - qt_lin * se_lin, 0)\n    upr_ci = beta_hat + qt_lin * se_lin\n\n    # Log the summary.\n    header = \"Parameter\\tEstimate\\tStd. Error\\tPr(&gt;|t|)\\t\\t95% CI\"\n    logger.info(\"Confidence Intervals:\")\n    logger.info(\"\")\n    logger.info(header)\n    for i, (b, se, p, lwr, upr) in enumerate(zip(beta_hat, se_lin, pval, lwr_ci, upr_ci)):\n        logger.info(f\"Param {i}:\\t {b:.2f}\\t\\t {se:.2f}\\t\\t {p:.1e}\\t\\t ({lwr:.2f} - {upr:.2f})\")\n\n    results = {\n        'beta_hat': beta_hat,\n        'se_lin': se_lin,\n        'df_lin': df_lin,\n        't_stat': t_stat,\n        'pval': pval,\n        'qt_lin': qt_lin,\n        'lwr_ci': lwr_ci,\n        'upr_ci': upr_ci\n    }\n    return results\n</code></pre>"},{"location":"reference/#paramest.normest.normest","title":"<code>normest(gene, p_data, init_cond, num_psites, time_points, bounds, bootstraps, use_regularization=USE_REGULARIZATION, lambda_reg=LAMBDA_REG)</code>","text":"<p>Perform normal parameter estimation using all provided time points at once. Uses the provided bounds (ignores fixed_params so that all parameters are estimated) and supports bootstrapping if specified.</p> <p>Parameters:</p> Name Type Description Default <code>-</code> <code>p_data</code> <p>Measurement data (DataFrame or numpy array). Assumes data starts at column index 2.</p> required <code>-</code> <code>init_cond</code> <p>Initial condition for the ODE solver.</p> required <code>-</code> <code>num_psites</code> <p>Number of phosphorylation sites.</p> required <code>-</code> <code>time_points</code> <p>Array of time points to use.</p> required <code>-</code> <code>bounds</code> <p>Dictionary of parameter bounds.</p> required <code>-</code> <code>fixed_params</code> <p>(Ignored in normest) Provided for interface consistency.</p> required <code>-</code> <code>bootstraps</code> <p>Number of bootstrapping iterations.</p> required <code>-</code> <code>use_regularization</code> <p>Flag to apply Tikhonov regularization.</p> required <code>-</code> <code>lambda_reg</code> <p>Regularization strength.</p> required <p>Returns:</p> Type Description <ul> <li>est_params: List with the full estimated parameter vector.</li> </ul> <ul> <li>model_fits: List with the ODE solution and model predictions.</li> </ul> <ul> <li>error_vals: List with the squared error (data vs. model prediction).</li> </ul> Source code in <code>paramest/normest.py</code> <pre><code>def normest(gene, p_data, init_cond, num_psites, time_points, bounds,\n            bootstraps, use_regularization=USE_REGULARIZATION, lambda_reg=LAMBDA_REG):\n    \"\"\"\n    Perform normal parameter estimation using all provided time points at once.\n    Uses the provided bounds (ignores fixed_params so that all parameters are estimated)\n    and supports bootstrapping if specified.\n\n    Parameters:\n      - p_data: Measurement data (DataFrame or numpy array). Assumes data starts at column index 2.\n      - init_cond: Initial condition for the ODE solver.\n      - num_psites: Number of phosphorylation sites.\n      - time_points: Array of time points to use.\n      - bounds: Dictionary of parameter bounds.\n      - fixed_params: (Ignored in normest) Provided for interface consistency.\n      - bootstraps: Number of bootstrapping iterations.\n      - use_regularization: Flag to apply Tikhonov regularization.\n      - lambda_reg: Regularization strength.\n\n    Returns:\n      - est_params: List with the full estimated parameter vector.\n      - model_fits: List with the ODE solution and model predictions.\n      - error_vals: List with the squared error (data vs. model prediction).\n    \"\"\"\n    est_params, model_fits, error_vals = [], [], []\n\n    if ODE_MODEL == 'randmod':\n        # Build lower and upper bounds from config.\n        lower_bounds_full = [\n            bounds[\"A\"][0], bounds[\"B\"][0], bounds[\"C\"][0], bounds[\"D\"][0]\n        ]\n        upper_bounds_full = [\n            bounds[\"A\"][1], bounds[\"B\"][1], bounds[\"C\"][1], bounds[\"D\"][1]\n        ]\n        # For phosphorylation parameters: use Ssite bounds.\n        lower_bounds_full += [bounds[\"Ssite\"][0]] * num_psites\n        upper_bounds_full += [bounds[\"Ssite\"][1]] * num_psites\n        # For dephosphorylation parameters: for each combination, use Dsite bounds.\n        for i in range(1, num_psites + 1):\n            for _ in combinations(range(1, num_psites + 1), i):\n                lower_bounds_full.append(bounds[\"Dsite\"][0])\n                upper_bounds_full.append(bounds[\"Dsite\"][1])\n        # If using log scale, transform bounds (ensure lower bounds &gt; 0)\n        eps = 1e-8  # small epsilon to avoid log(0)\n        lower_bounds_full = [np.log(max(b, eps)) for b in lower_bounds_full]\n        upper_bounds_full = [np.log(b) for b in upper_bounds_full]\n    else:\n        # Existing approach for distributive or successive models.\n        lower_bounds_full = (\n            [bounds[\"A\"][0], bounds[\"B\"][0], bounds[\"C\"][0], bounds[\"D\"][0]] +\n            [bounds[\"Ssite\"][0]] * num_psites +\n            [bounds[\"Dsite\"][0]] * num_psites\n        )\n        upper_bounds_full = (\n            [bounds[\"A\"][1], bounds[\"B\"][1], bounds[\"C\"][1], bounds[\"D\"][1]] +\n            [bounds[\"Ssite\"][1]] * num_psites +\n            [bounds[\"Dsite\"][1]] * num_psites\n        )\n\n    def model_func(tpts, *params):\n        \"\"\"\n        Define the model function for curve fitting.\n\n        :param tpts:\n        :param params:\n        :return: model predictions\n        \"\"\"\n        if ODE_MODEL == 'randmod':\n            param_vec = np.exp(np.array(params))\n        else:\n            param_vec = np.array(params)\n        _, p_fitted = solve_ode(param_vec, init_cond, num_psites, np.atleast_1d(tpts))\n        y_model = p_fitted.flatten()\n        if use_regularization:\n            reg = np.sqrt(lambda_reg) * np.array(params)\n            return np.concatenate([y_model, reg])\n        return y_model\n\n    free_bounds = (lower_bounds_full, upper_bounds_full)\n\n    # Set initial guess for all parameters (midpoint of bounds).\n    p0 = np.array([(l + u) / 2 for l, u in zip(*free_bounds)])\n\n    # Build the target vector from the measured data.\n    target = p_data.flatten()\n    target_fit = np.concatenate([target, np.zeros(len(p0))]) if use_regularization else target\n\n    default_sigma = 1 / np.maximum(np.abs(target_fit), 1e-5)\n\n    try:\n        # Attempt to get a good initial estimate using curve_fit.\n        result = cast(Tuple[np.ndarray, np.ndarray],\n                      curve_fit(model_func, time_points, target_fit, x_scale='jac',\n                      p0=p0, bounds=free_bounds, sigma=default_sigma,\n                      absolute_sigma=True, maxfev=20000))\n        popt_init, _ = result\n    except Exception as e:\n        logger.warning(f\"[{gene}] Normal initial estimation failed: {e}\")\n        popt_init = p0\n\n    # Get weights for the model fitting.\n    early_weights = early_emphasis(p_data, time_points, num_psites)\n    weight_options = get_weight_options(target, time_points, num_psites,\n                                        use_regularization, len(p0), early_weights)\n\n    scores, popts, pcovs = {}, {}, {}\n    for wname, sigma in weight_options.items():\n        try:\n            # Attempt to fit the model using the specified weights.\n            result = cast(Tuple[np.ndarray, np.ndarray],\n                          curve_fit(model_func, time_points, target_fit, p0=popt_init,\n                          bounds=free_bounds, sigma=sigma, x_scale='jac',\n                          absolute_sigma=True, maxfev=20000))\n            popt, pcov = result\n        except Exception as e:\n            logger.warning(f\"[{gene}] Fit failed for {wname}: {e}\")\n            popt = popt_init\n            pcov = None\n        popts[wname] = popt\n        pcovs[wname] = pcov\n        pred = model_func(time_points, *popt)\n        # Calculate the score for the fit.\n        scores[wname] = score_fit(target_fit, pred, popt)\n\n    # Select the best weight based on the score.\n    best_weight = min(scores, key=scores.get)\n    best_score = scores[best_weight]\n    # Get the best parameters and covariance matrix.\n    popt_best = popts[best_weight]\n    pcov_best = pcovs[best_weight]\n\n    logger.info(f\"[{gene}] Best weight: {best_weight} with score: {best_score:.4f}\")\n\n    # Get confidence intervals for the best parameters.\n    ci_results = confidence_intervals(\n        np.exp(popt_best) if ODE_MODEL == 'randmod' else popt_best,\n        pcov_best,\n        target,\n        alpha_val=ALPHA_CI\n    )\n\n    # Bootstrapping\n    boot_estimates = []\n    boot_covariances = []\n    if bootstraps &gt; 0:\n        logger.info(f\"[{gene}] Performing bootstrapping with {bootstraps} iterations\")\n        for _ in range(bootstraps):\n            noise = np.random.normal(0, 0.05, size=target_fit.shape)\n            noisy_target = target_fit * (1 + noise)\n            try:\n                # Attempt to fit the model using the noisy target.\n                result = cast(Tuple[np.ndarray, np.ndarray],\n                              curve_fit(model_func, time_points, noisy_target,\n                                        p0=popt_best, bounds=free_bounds, sigma=default_sigma,\n                                        absolute_sigma=True, maxfev=20000))\n                popt_bs, pcov_bs = result\n            except Exception as e:\n                logger.warning(f\"Bootstrapping iteration failed: {e}\")\n                popt_bs = popt_best\n                pcov_bs = None\n            boot_estimates.append(popt_bs)\n            boot_covariances.append(pcov_bs)\n\n        # Convert boot_estimates to an array and compute the mean parameter estimates.\n        popt_best = np.mean(boot_estimates, axis=0)\n\n        # Process bootstrap covariance matrices:\n        # Only include iterations where pcov_bs is not None.\n        valid_covs = [cov for cov in boot_covariances if cov is not None]\n        if valid_covs:\n            # Compute an average covariance matrix from the valid ones.\n            pcov_best = np.mean(valid_covs, axis=0)\n        else:\n            pcov_best = None\n        # Compute confidence intervals for the bootstrapped estimates.\n        ci_results = confidence_intervals(\n            np.exp(popt_best) if ODE_MODEL == 'randmod' else popt_best,\n            pcov_best,\n            target,\n            alpha_val=ALPHA_CI\n        )\n    # Since all parameters are free, param_final is simply the best-fit vector.\n    # If parameters were estimated in log-space, convert them back.\n    if ODE_MODEL == 'randmod':\n        param_final = np.exp(popt_best)\n    else:\n        param_final = popt_best\n    est_params.append(param_final)\n    sol, p_fit = solve_ode(param_final, init_cond, num_psites, time_points)\n    model_fits.append((sol, p_fit))\n    error_vals.append(np.sum(np.abs(target - p_fit.flatten()) ** 2))\n    return est_params, model_fits, error_vals #, ci_results\n</code></pre>"},{"location":"reference/#paramest.seqest.fit_parameters","title":"<code>fit_parameters(time_points, p_data, model_func, p0_free, bounds, weight_options, use_regularization=True)</code>","text":"<p>Fit the parameters of the model using curve fitting with different weighting options. This function iterates over the provided weight options, performs the curve fitting, and evaluates the goodness of fit using a scoring function. The best fitting parameters and their corresponding score are returned.</p> <p>:param time_points: :param p_data: :param model_func: :param p0_free: :param bounds: :param weight_options: :param use_regularization: :return: best_fit_params, best_weight_key, scores</p> Source code in <code>paramest/seqest.py</code> <pre><code>def fit_parameters(time_points, p_data, model_func, p0_free,\n                   bounds, weight_options,\n                   use_regularization=True):\n    \"\"\"\n    Fit the parameters of the model using curve fitting with different\n    weighting options. This function iterates over the provided\n    weight options, performs the curve fitting, and evaluates the\n    goodness of fit using a scoring function. The best fitting\n    parameters and their corresponding score are returned.\n\n    :param time_points:\n    :param p_data:\n    :param model_func:\n    :param p0_free:\n    :param bounds:\n    :param weight_options:\n    :param use_regularization:\n    :return: best_fit_params, best_weight_key, scores\n    \"\"\"\n    scores, popts = {}, {}\n    target = p_data.flatten()\n\n    if use_regularization:\n        target = np.concatenate([target, np.zeros(len(p0_free))])\n\n    for key, sigma in weight_options.items():\n        try:\n            result = cast(Tuple[np.ndarray, np.ndarray],\n                          curve_fit(model_func, time_points, target,\n                          p0=p0_free, bounds=bounds,\n                          sigma=sigma, absolute_sigma=True,\n                          maxfev=20000))\n            popt, _ = result\n        except Exception as e:\n            logger.warning(f\"Fit failed with {key}: {e}\")\n            popt = p0_free\n\n        popts[key] = popt\n        prediction = model_func(time_points, *popt)\n        score = score_fit(target, prediction, popt)\n        scores[key] = score\n        logger.debug(f\"[{key}] Score: {score:.4f}\")\n\n    best_key = min(scores, key=scores.get)\n    best_score = scores[best_key]\n    logger.info(f\"Score: {best_score:.2f}\")\n    return popts[best_key], best_key, scores\n</code></pre>"},{"location":"reference/#paramest.seqest.prepare_model_func","title":"<code>prepare_model_func(num_psites, init_cond, bounds, fixed_params, use_regularization=True, lambda_reg=0.001)</code>","text":"<p>Prepare the model function for sequential parameter estimation.</p> <p>This function builds the model function based on the specified ODE model type and the number of phosphorylation sites. It also sets up the bounds for the free parameters and handles fixed parameters. The model function is used for curve fitting to estimate the parameters of the ODE model.</p> <p>:param num_psites: :param init_cond: :param bounds: :param fixed_params: :param use_regularization: :param lambda_reg: :return: model_func, free_indices, free_bounds, fixed_values, num_total_params</p> Source code in <code>paramest/seqest.py</code> <pre><code>def prepare_model_func(num_psites, init_cond, bounds, fixed_params,\n                       use_regularization=True, lambda_reg=1e-3):\n    \"\"\"\n    Prepare the model function for sequential parameter estimation.\n\n    This function builds the model function based on the specified\n    ODE model type and the number of phosphorylation sites. It also\n    sets up the bounds for the free parameters and handles fixed\n    parameters. The model function is used for curve fitting to\n    estimate the parameters of the ODE model.\n\n    :param num_psites:\n    :param init_cond:\n    :param bounds:\n    :param fixed_params:\n    :param use_regularization:\n    :param lambda_reg:\n    :return: model_func, free_indices, free_bounds, fixed_values, num_total_params\n    \"\"\"\n    if ODE_MODEL == 'randmod':\n        # Build lower and upper bounds from config.\n        lower_bounds_full = [\n            bounds[\"A\"][0], bounds[\"B\"][0], bounds[\"C\"][0], bounds[\"D\"][0]\n        ]\n        upper_bounds_full = [\n            bounds[\"A\"][1], bounds[\"B\"][1], bounds[\"C\"][1], bounds[\"D\"][1]\n        ]\n        # For phosphorylation parameters: use Ssite bounds.\n        lower_bounds_full += [bounds[\"Ssite\"][0]] * num_psites\n        upper_bounds_full += [bounds[\"Ssite\"][1]] * num_psites\n        # For dephosphorylation parameters: for each combination, use Dsite bounds.\n        for i in range(1, num_psites + 1):\n            for _ in combinations(range(1, num_psites + 1), i):\n                lower_bounds_full.append(bounds[\"Dsite\"][0])\n                upper_bounds_full.append(bounds[\"Dsite\"][1])\n        num_total_params = len(lower_bounds_full)\n    else:\n        # Existing approach for distributive or successive models.\n        num_total_params = 4 + 2 * num_psites\n        lower_bounds_full = (\n            [bounds[\"A\"][0], bounds[\"B\"][0], bounds[\"C\"][0], bounds[\"D\"][0]] +\n            [bounds[\"Ssite\"][0]] * num_psites +\n            [bounds[\"Dsite\"][0]] * num_psites\n        )\n        upper_bounds_full = (\n            [bounds[\"A\"][1], bounds[\"B\"][1], bounds[\"C\"][1], bounds[\"D\"][1]] +\n            [bounds[\"Ssite\"][1]] * num_psites +\n            [bounds[\"Dsite\"][1]] * num_psites\n        )\n\n    fixed_values = {}\n    free_indices = []\n    param_names = get_param_names(num_psites)\n\n    for i, name in enumerate(param_names):\n        val = fixed_params.get(name)\n        if val is not None:\n            fixed_values[i] = val\n        else:\n            free_indices.append(i)\n\n    def model_func(t, *p_free):\n        p_full = np.zeros(num_total_params)\n        free_iter = iter(p_free)\n        for p in range(num_total_params):\n            p_full[p] = fixed_values[i] if i in fixed_values else next(free_iter)\n        _, p_fitted = solve_ode(p_full, init_cond, num_psites, np.atleast_1d(t))\n        y_model = p_fitted.flatten()\n        if use_regularization:\n            reg = np.sqrt(lambda_reg) * np.array(p_free)\n            return np.concatenate([y_model, reg])\n        return y_model\n\n    free_bounds = ([lower_bounds_full[i] for i in free_indices],\n                   [upper_bounds_full[i] for i in free_indices])\n    # logger.info(f\"Model Built\")\n    return model_func, free_indices, free_bounds, fixed_values, num_total_params\n</code></pre>"},{"location":"reference/#paramest.seqest.sequential_estimation","title":"<code>sequential_estimation(p_data, time_points, init_cond, bounds, fixed_params, num_psites, gene, use_regularization=USE_REGULARIZATION, lambda_reg=LAMBDA_REG)</code>","text":"<p>Perform sequential parameter estimation for a given gene using the specified model function. This function iteratively fits the model to the data at each time point, updating the initial guess for the parameters based on the previous fit. The estimated parameters, model fits, and error values are returned.</p> <p>:param p_data: :param time_points: :param init_cond: :param bounds: :param fixed_params: :param num_psites: :param gene: :param use_regularization: :param lambda_reg: :return:</p> Source code in <code>paramest/seqest.py</code> <pre><code>def sequential_estimation(p_data, time_points, init_cond, bounds,\n                          fixed_params, num_psites, gene,\n                          use_regularization=USE_REGULARIZATION, lambda_reg=LAMBDA_REG):\n    \"\"\"\n    Perform sequential parameter estimation for a given gene using\n    the specified model function. This function iteratively fits the\n    model to the data at each time point, updating the initial guess\n    for the parameters based on the previous fit. The estimated\n    parameters, model fits, and error values are returned.\n\n    :param p_data:\n    :param time_points:\n    :param init_cond:\n    :param bounds:\n    :param fixed_params:\n    :param num_psites:\n    :param gene:\n    :param use_regularization:\n    :param lambda_reg:\n    :return:\n    \"\"\"\n    est_params, model_fits, error_vals = [], [], []\n\n    model_func, free_indices, free_bounds, fixed_values, num_total_params = (\n        prepare_model_func(num_psites, init_cond, bounds, fixed_params,\n                           use_regularization, lambda_reg)\n    )\n\n    p0_free = np.array([(lb + ub) / 2 for lb, ub in zip(*free_bounds)])\n\n    for i in range(1, len(time_points) + 1):\n        t_now = time_points[:i]\n        y_now = p_data[:, :i] if p_data.ndim &gt; 1 else p_data[:i].reshape(1, -1)\n        y_flat = y_now.flatten()\n\n        if use_regularization:\n            target_fit = np.concatenate([y_flat, np.zeros(len(p0_free))])\n        else:\n            target_fit = y_flat\n\n        try:\n            # Attempt to get a good initial estimate using curve_fit.\n            result = cast(Tuple[np.ndarray, np.ndarray],\n                          curve_fit(model_func, t_now, target_fit,\n                          p0=p0_free, bounds=free_bounds,\n                          maxfev=20000))\n            popt_init, _ = result\n        except Exception as e:\n            logger.warning(f\"Initial fit failed at time index {i} for gene {gene}: {e}\")\n            popt_init = p0_free\n\n        # Get weights for the model fitting.\n        early_emphasis_weights = early_emphasis(y_now, t_now, num_psites)\n        weights = get_weight_options(y_flat, t_now, num_psites,\n                                     use_regularization, len(p0_free), early_emphasis_weights)\n\n        # Perform the fit with the best weights.\n        best_fit, weight_key, _ = fit_parameters(t_now, y_now, model_func, popt_init,\n                                                 free_bounds, weights,\n                                                 use_regularization)\n        p_full = np.zeros(num_total_params)\n        # Fill in the fixed parameters and free parameters.\n        free_iter = iter(best_fit)\n        # Iterate over the total parameters and assign values.\n        for j in range(num_total_params):\n            # If the parameter is fixed, use the fixed value.\n            p_full[j] = fixed_values[j] if j in fixed_values else next(free_iter)\n        # Append the estimated parameters and model fit.\n        est_params.append(p_full)\n        # Solve the ODE with the estimated parameters.\n        sol, p_fit = solve_ode(p_full, init_cond, num_psites, t_now)\n        # Flatten the model fit for error calculation.\n        model_fits.append((sol, p_fit))\n        # Calculate the mean square error value.\n        error_vals.append(np.sum(np.abs(y_flat - p_fit.flatten()) ** 2))\n        # Update the initial guess for the next iteration.\n        p0_free = best_fit\n\n        logger.info(f\"[{gene}] Time Index {i} Best Weight = {weight_key}\")\n\n    return est_params, model_fits, error_vals\n</code></pre>"},{"location":"reference/#paramest.toggle.estimate_parameters","title":"<code>estimate_parameters(mode, gene, p_data, init_cond, num_psites, time_points, bounds, fixed_params, bootstraps)</code>","text":"<p>Toggle between sequential and normal (all timepoints) estimation.</p> <p>This function allows for the selection of the estimation mode and handles the parameter estimation process accordingly.</p> <p>It uses the sequential estimation method for \"sequential\" mode and the normal estimation method for \"normal\" mode.</p> <p>Parameters:</p> Name Type Description Default <code>-</code> <code>mode</code> <p>The estimation mode, either \"sequential\" or \"normal\".</p> required <code>-</code> <code>gene</code> <p>The gene name.</p> required <code>-</code> <code>p_data</code> <p>Measurement data (DataFrame or numpy array).</p> required <code>-</code> <code>init_cond</code> <p>Initial condition for the ODE solver.</p> required <code>-</code> <code>num_psites</code> <p>Number of phosphorylation sites.</p> required <code>-</code> <code>time_points</code> <p>Array of time points to use.</p> required <code>-</code> <code>bounds</code> <p>Dictionary of parameter bounds.</p> required <code>-</code> <code>fixed_params</code> <p>Dictionary of fixed parameters.</p> required <code>-</code> <code>bootstraps</code> <p>Number of bootstrapping iterations (only used in normal mode).</p> required <p>:returns:     - model_fits: List with the ODE solution and model predictions.     - estimated_params: List with the full estimated parameter vector.     - seq_model_fit: Sequential model fit for the gene.     - errors: Error metrics (MSE, MAE).</p> Source code in <code>paramest/toggle.py</code> <pre><code>def estimate_parameters(mode, gene, p_data, init_cond, num_psites, time_points, bounds, fixed_params, bootstraps):\n    \"\"\"\n    Toggle between sequential and normal (all timepoints) estimation.\n\n    This function allows for the selection of the estimation mode\n    and handles the parameter estimation process accordingly.\n\n    It uses the sequential estimation method for \"sequential\" mode\n    and the normal estimation method for \"normal\" mode.\n\n    Args:\n        - mode: The estimation mode, either \"sequential\" or \"normal\".\n        - gene: The gene name.\n        - p_data: Measurement data (DataFrame or numpy array).\n        - init_cond: Initial condition for the ODE solver.\n        - num_psites: Number of phosphorylation sites.\n        - time_points: Array of time points to use.\n        - bounds: Dictionary of parameter bounds.\n        - fixed_params: Dictionary of fixed parameters.\n        - bootstraps: Number of bootstrapping iterations (only used in normal mode).\n    :returns:\n        - model_fits: List with the ODE solution and model predictions.\n        - estimated_params: List with the full estimated parameter vector.\n        - seq_model_fit: Sequential model fit for the gene.\n        - errors: Error metrics (MSE, MAE).\n    \"\"\"\n\n    if mode == \"sequential\":\n\n        # For sequential estimation, we need to set up the model function\n        estimated_params, model_fits, errors = sequential_estimation(\n            p_data, time_points, init_cond, bounds, fixed_params, num_psites, gene\n        )\n\n        # For sequential estimation, assemble the fitted predictions at each time point:\n        seq_model_fit = np.zeros((num_psites, len(time_points)))\n\n        # Iterate over the model fits and extract the last column (predictions)\n\n        for i, (_, P_fitted) in enumerate(model_fits):\n            # P_fitted is expected to be of shape (num_psites, len(time_points))\n            seq_model_fit[:, i] = P_fitted[:, -1]\n\n    elif mode == \"normal\":\n\n        # For normal estimation, we use the provided bounds and fixed parameters\n        estimated_params, model_fits, errors = normest(\n            gene, p_data, init_cond, num_psites, time_points, bounds, bootstraps\n        )\n\n        # For normal estimation, model_fits[0][1] is already an array of shape (num_psites, len(time_points))\n        seq_model_fit = model_fits[0][1]\n\n    else:\n        raise ValueError(\"Invalid estimation mode. Choose 'sequential' or 'normal'.\")\n\n    return model_fits, estimated_params, seq_model_fit, errors\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter","title":"<code>Plotter</code>","text":"<p>A class to encapsulate plotting functionalities for ODE model analysis.</p> <p>Attributes:</p> Name Type Description <code>gene</code> <code>str</code> <p>The gene or experiment name.</p> <code>out_dir</code> <code>str</code> <p>The directory where plots will be saved.</p> <code>color_palette</code> <code>list</code> <p>List of color codes used for plotting.</p> Source code in <code>plotting/plotting.py</code> <pre><code>class Plotter:\n    \"\"\"\n    A class to encapsulate plotting functionalities for ODE model analysis.\n\n    Attributes:\n        gene (str): The gene or experiment name.\n        out_dir (str): The directory where plots will be saved.\n        color_palette (list): List of color codes used for plotting.\n    \"\"\"\n\n    def __init__(self, gene: str, out_dir: str = OUT_DIR):\n        self.gene = gene\n        self.out_dir = out_dir\n        self.color_palette = COLOR_PALETTE\n\n    def _save_fig(self, fig, filename: str, dpi: int = 300):\n        \"\"\"\n        Saves and closes the given matplotlib figure.\n        \"\"\"\n        path = os.path.join(self.out_dir, filename)\n        fig.savefig(path, dpi=dpi)\n        plt.close(fig)\n\n    def plot_parallel(self, solution: np.ndarray, labels: list):\n        \"\"\"\n        Plots a parallel coordinates plot for the given solution.\n\n        :param solution: 2D numpy array of shape (sampels, features)\n        :param labels: list of labels\n        \"\"\"\n        df = pd.DataFrame(solution, columns=labels)\n        df['Time'] = range(1, len(df) + 1)\n        fig, ax = plt.subplots(figsize=(8, 8))\n        parallel_coordinates(df, class_column='Time', colormap=plt.get_cmap(\"tab20\"), ax=ax)\n        ax.set_title(self.gene)\n        ax.set_xlabel(\"States\")\n        ax.set_ylabel(\"Values\")\n        ax.legend(title=\"Time Points\", loc=\"upper right\", labels=df['Time'].astype(str).tolist())\n        self._save_fig(fig, f\"{self.gene}_parallel_coordinates_.png\")\n\n    def pca_components(self, solution: np.ndarray, target_variance: float = 0.99):\n        \"\"\"\n        Plots a scree plot showing the explained variance ratio for PCA components.\n\n        :param solution: 2D numpy array of shape (samples, features) representing the data.\n        :param target_variance: The target cumulative explained variance to determine the required number of components.\n        :return: A tuple containing the number of required components and the explained variance ratio.\n        \"\"\"\n\n        pca = PCA(n_components=min(solution.shape))\n        pca.fit(solution)\n        explained_variance = pca.explained_variance_ratio_\n        cumulative_explained_variance = np.cumsum(explained_variance)\n        required_components = np.argmax(cumulative_explained_variance &gt;= target_variance) + 1\n\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.bar(range(1, len(explained_variance) + 1), explained_variance * 100,\n               alpha=0.6, color='b', label='Individual')\n        ax.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance * 100,\n                marker='o', color='r', label='Cumulative')\n        ax.axvline(x=required_components, color='g', linestyle='--',\n                   label=f'{required_components} Components')\n        ax.set_title(self.gene)\n        ax.set_xlabel('Principal Component')\n        ax.set_ylabel('Explained Variance (%)')\n        ax.legend()\n        ax.grid(True)\n        self._save_fig(fig, f\"{self.gene}_scree_plot_.png\")\n        return required_components, explained_variance\n\n    def plot_pca(self, solution: np.ndarray, components: int = 3):\n        \"\"\"\n        Plots the PCA results for the given solution.\n\n        :param solution: 2D numpy array of shape (samples, features) representing the data.\n        :param components: Number of PCA components to plot. Defaults to 3.\n        \"\"\"\n        pca = PCA(n_components=components)\n        pca_result = pca.fit_transform(solution)\n        ev = pca.explained_variance_ratio_ * 100\n        indices = np.arange(len(solution))\n        if components == 3:\n            x, y, z = pca_result[:, 0], pca_result[:, 1], pca_result[:, 2]\n            cs_x, cs_y, cs_z = CubicSpline(indices, x), CubicSpline(indices, y), CubicSpline(indices, z)\n            si = np.linspace(0, len(solution) - 1, 1000)\n            fig = plt.figure(figsize=(8, 8))\n            ax = fig.add_subplot(111, projection='3d')\n            sc = ax.scatter(x, y, z, c=indices, cmap='tab20')\n            fig.colorbar(sc, label=\"Time Index\")\n            ax.plot(cs_x(si), cs_y(si), cs_z(si), color='blue', alpha=0.7, label='Temporal Path')\n            for i, (xi, yi, zi) in enumerate(zip(x, y, z)):\n                ax.text(xi, yi, zi, str(i + 1), fontsize=10, color=\"black\")\n            ax.set_xlabel(f\"PC1 ({ev[0]:.1f}%)\")\n            ax.set_ylabel(f\"PC2 ({ev[1]:.1f}%)\")\n            ax.set_zlabel(f\"PC3 ({ev[2]:.1f}%)\")\n            ax.set_title(self.gene)\n            ax.legend()\n            self._save_fig(fig, f\"{self.gene}_pca_plot_.png\")\n        else:\n            # Optionally handle non-3D cases here\n            pass\n\n    def plot_tsne(self, solution: np.ndarray, perplexity: int = 30):\n        \"\"\"\n        Plots a t-SNE visualization of the given solution.\n\n        :param solution: 2D numpy array of shape (samples, features) representing the data.\n        :param perplexity: Perplexity parameter for t-SNE. Defaults to 30.\n        \"\"\"\n        perplexity = min(perplexity, len(solution) - 1)\n        tsne_result = TSNE(n_components=2, perplexity=perplexity, random_state=42).fit_transform(solution)\n        x, y = tsne_result[:, 0], tsne_result[:, 1]\n        indices = np.arange(len(solution))\n        cs_x, cs_y = CubicSpline(indices, x), CubicSpline(indices, y)\n        si = np.linspace(0, len(solution) - 1, 1000)\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.scatter(x, y, c=indices, cmap='tab20')\n        ax.plot(cs_x(si), cs_y(si), color='blue', alpha=0.7, label='Temporal Path')\n        for i, (xi, yi) in enumerate(zip(x, y)):\n            ax.text(xi, yi, str(i + 1), fontsize=10, color=\"black\")\n        ax.set_xlabel(\"t-SNE 1\")\n        ax.set_ylabel(\"t-SNE 2\")\n        ax.set_title(self.gene)\n        ax.grid(True)\n        ax.legend()\n        self._save_fig(fig, f\"{self.gene}_tsne_plot_.png\")\n\n    def plot_param_bar(self, params_df: pd.DataFrame, s_df: pd.DataFrame):\n        \"\"\"\n        Plots a bar chart of parameter values for the given gene.\n\n        This method visualizes the estimated parameter values for a specific gene\n        and its phosphorylation sites. It uses color coding to distinguish between\n        different phosphorylation sites and other parameters.\n\n        :param params_df: DataFrame containing parameter values.\n        :param s_df: DataFrame containing phosphorylation site information.\n        \"\"\"\n        fig, ax = plt.subplots(figsize=(8, 8))\n        unique_psites = s_df.loc[s_df['GeneID'] == self.gene, 'Psite'].tolist()\n        color_map = {psite: plt.cm.tab20(i / len(unique_psites)) for i, psite in enumerate(unique_psites)}\n\n        if len(unique_psites) == 1:\n            single_psite = unique_psites[0]\n            color = color_map[single_psite]\n            if 'S' in params_df.columns and not params_df['S'].isna().all():\n                ax.bar('S', params_df['S'].mean(), color=color, label=f\"{single_psite}\")\n\n        for i, psite in enumerate(unique_psites):\n            color = color_map[psite]\n            for param in [f\"S{i + 1}\", f\"D{i + 1}\"]:\n                if param in params_df.columns and not params_df[param].isna().all():\n                    ax.bar(param, params_df[param].mean(), color=color,\n                           label=f\"{psite}\" if psite not in [h.get_label() for h in\n                                                             ax.get_legend_handles_labels()[0]] else None)\n\n        other_params = [col for col in params_df.columns\n                        if col not in ['Protein', 'S'] + [f\"S{i + 1}\" for i in range(len(unique_psites))] + [f\"D{i + 1}\"\n                                                                                                             for i in\n                                                                                                             range(\n                                                                                                                 len(unique_psites))]]\n        for i, param in enumerate(other_params):\n            if param in params_df.columns and not params_df[param].isna().all():\n                ax.bar(param, params_df[param].mean(), color=plt.cm.Paired(i / len(other_params)), alpha=0.6)\n\n        ax.set_title(self.gene)\n        ax.set_ylabel('Estimated Values')\n        ax.set_xlabel('Parameters')\n        plt.xticks(rotation=45)\n        ax.legend(title=\"Residue_Position\", loc='upper right', ncol=2)\n        plt.tight_layout()\n        self._save_fig(fig, f\"{self.gene}_params_bar_.png\")\n\n\n    def plot_param_series(self, estimated_params: list, param_names: list, time_points: np.ndarray):\n        \"\"\"\n        Plots the time series of estimated parameters over the given time points.\n\n        This method visualizes the evolution of kinetic rates or parameters\n        over time for a specific gene.\n\n        :param estimated_params: List of estimated parameter values at each time point.\n        :param param_names: List of parameter names corresponding to the estimated parameters.\n        :param time_points: 1D numpy array of time points.\n        \"\"\"\n        arr = np.array(estimated_params)\n        fig, ax = plt.subplots(figsize=(8, 8))\n        for i in range(arr.shape[1]):\n            ax.plot(time_points, arr[:, i], label=param_names[i])\n        ax.set_title(self.gene)\n        ax.set_xlabel(\"Time\")\n        ax.set_ylabel(\"Kinetic Rates\")\n        ax.grid(True)\n        ax.legend(loc=\"best\")\n        plt.tight_layout()\n        self._save_fig(fig, f\"{self.gene}_params_series_.png\")\n\n\n    def plot_profiles(self, data: pd.DataFrame):\n        \"\"\"\n        Plots the profiles of estimated parameters over time.\n\n        :param data: DataFrame containing the estimated parameters and time points.\n        \"\"\"\n        fig, ax = plt.subplots(figsize=(8, 8))\n        for col in data.columns:\n            if col != \"Time\":\n                ax.plot(data[\"Time\"], data[col], marker='o', label=col)\n        ax.set_xlabel(\"Time (min)\")\n        ax.set_ylabel(\"Kinetic Rates\")\n        ax.set_title(self.gene)\n        ax.legend()\n        ax.grid(True)\n        plt.tight_layout()\n        self._save_fig(fig, f\"{self.gene}_params_profiles.png\")\n\n    def plot_model_fit(self, model_fit: np.ndarray, P_data: np.ndarray, sol: np.ndarray,\n                       num_psites: int, psite_labels: list, time_points: np.ndarray):\n        \"\"\"\n        Plots the model fit for the given data.\n\n        :param model_fit: Estimated model fit values.\n        :param P_data: Observed data for phosphorylation levels.\n        :param sol: ODE solution for mRNA and protein levels.\n        :param num_psites: number of phosphorylation sites.\n        :param psite_labels: labels for the phosphorylation sites.\n        :param time_points: time points for the data.\n        :return:\n        \"\"\"\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.plot(time_points, sol[:, 0], '-', color='black', alpha=0.7, label='mRNA (R)')\n        ax.plot(time_points, sol[:, 1], '-', color='red', alpha=0.7, label='Protein (P)')\n        for i in range(num_psites):\n            ax.plot(time_points, P_data[i, :], '-', marker='s',\n                    color=self.color_palette[i], label=f'P+{psite_labels[i]}')\n            ax.plot(time_points, model_fit[i, :], '-', color=self.color_palette[i],\n                    label=f'P+{psite_labels[i]} (model)')\n        ax.set_xlabel(\"Time (minutes)\")\n        ax.set_ylabel(\"Phosphorylation level (FC)\")\n        ax.set_title(self.gene)\n        ax.grid(True)\n        ax.legend()\n        plt.tight_layout()\n        self._save_fig(fig, f\"{self.gene}_model_fit_.png\")\n\n        # Plot using Plotly for an interactive version.\n        fig_plotly = go.Figure()\n        fig_plotly.add_trace(go.Scatter(\n            x=time_points,\n            y=sol[:, 0],\n            mode='lines+markers',\n            name='mRNA(R)(model)',\n            line=dict(color='black')\n        ))\n        fig_plotly.add_trace(go.Scatter(\n            x=time_points,\n            y=sol[:, 1],\n            mode='lines+markers',\n            name='Protein(P)(model)',\n            line=dict(color='red')\n        ))\n        for i in range(num_psites):\n            fig_plotly.add_trace(go.Scatter(\n                x=time_points,\n                y=P_data[i, :] if num_psites &gt; 1 else P_data.flatten(),\n                mode='lines+markers',\n                name=f'P+{psite_labels[i]}',\n                line=dict(dash='dash', color=self.color_palette[i])\n            ))\n            fig_plotly.add_trace(go.Scatter(\n                x=time_points,\n                y=model_fit[i, :],\n                mode='lines+markers',\n                name=f'P+{psite_labels[i]} (model)',\n                line=dict(color=self.color_palette[i])\n            ))\n        fig_plotly.update_layout(title=self.gene,\n                                 xaxis_title=\"Time (minutes)\",\n                                 yaxis_title=\"Phosphorylation level (FC)\",\n                                 template=\"plotly_white\",\n                                 width=900, height=900)\n        fig_plotly.write_html(os.path.join(self.out_dir, f\"{self.gene}_model_fit_.html\"))\n\n    def plot_A_S(self, est_arr: np.ndarray, num_psites: int, time_vals: np.ndarray):\n        \"\"\"\n        Plots the scatter plot of A vs S and the density contour plot.\n\n        :param est_arr: Estimated parameters array.\n        :param num_psites: Number of phosphorylation sites.\n        :param time_vals: Time values for the data.\n        :return:\n        \"\"\"\n        est_arr = np.array(est_arr)\n        A_vals = est_arr[:, 0]\n        cmap = plt.get_cmap(\"viridis\")\n        norm = mcolors.Normalize(vmin=min(time_vals), vmax=max(time_vals))\n        fig, ax = plt.subplots(figsize=(8, 8))\n        legend_handles = []\n        for i in range(num_psites):\n            S_vals = est_arr[:, 4 + i]\n            sc = ax.scatter(A_vals, S_vals, c=time_vals, cmap=cmap, norm=norm,\n                            s=50, alpha=0.8, marker=available_markers[i])\n            slope, intercept = np.polyfit(A_vals, S_vals, 1)\n            x_fit = np.linspace(A_vals.min(), A_vals.max(), 100)\n            y_fit = slope * x_fit + intercept\n            line_color = f\"C{i}\"\n            ax.plot(x_fit, y_fit, color=line_color, lw=1)\n            legend_handles.append(Line2D([0], [0],\n                                         marker=available_markers[i],\n                                         color='w',\n                                         markerfacecolor=line_color,\n                                         markeredgecolor='k',\n                                         markersize=8,\n                                         label=f\"S{i + 1}\"))\n        ax.set_xlabel(\"A (mRNA production rate)\")\n        ax.set_ylabel(\"S (Phosphorylation rate)\")\n        ax.set_title(self.gene)\n        cbar = plt.colorbar(sc, ax=ax)\n        cbar.set_label(\"Time (min)\")\n        ax.grid(True)\n        ax.legend(handles=legend_handles)\n        plt.tight_layout()\n        self._save_fig(fig, f\"{self.gene}_scatter_A_S_.png\")\n\n        # Density contour plot for A and S.\n        all_points = np.vstack([np.column_stack((A_vals, est_arr[:, 4 + i])) for i in range(num_psites)])\n        kde = gaussian_kde(all_points.T)\n        A_lin = np.linspace(A_vals.min(), A_vals.max(), 100)\n        all_S = all_points[:, 1]\n        S_lin = np.linspace(all_S.min(), all_S.max(), 100)\n        A_grid, S_grid = np.meshgrid(A_lin, S_lin)\n        grid_coords = np.vstack([A_grid.ravel(), S_grid.ravel()])\n        density = kde(grid_coords).reshape(A_grid.shape)\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.scatter(all_points[:, 0], all_points[:, 1], c='black', s=30, alpha=0.5)\n        contourf = ax.contourf(A_grid, S_grid, density, levels=10, cmap=\"inferno\", alpha=0.7)\n        ax.contour(A_grid, S_grid, density, levels=CONTOUR_LEVELS, colors='white', linewidths=0.5)\n        ax.set_xlabel(\"A\")\n        ax.set_ylabel(\"S\")\n        ax.set_title(self.gene)\n        cbar = plt.colorbar(contourf, ax=ax)\n        cbar.set_label(\"Density\")\n        plt.tight_layout()\n        self._save_fig(fig, f\"{self.gene}_density_A_S_.png\")\n\n    def plot_all(self, solution: np.ndarray, labels: list, estimated_params: list,\n                 time_points: np.ndarray, P_data: np.ndarray, seq_model_fit: np.ndarray,\n                 psite_labels: list, perplexity: int = 5, components: int = 3, target_variance: float = 0.99):\n        \"\"\"\n        Function that calls parallel, t-SNE, PCA, and model fit plots.\n        If mode is sequential, it also calls parameter series and A-S plots.\n\n        :param solution: 2D numpy array of shape (samples, features) representing the data.\n        :param labels: List of labels for the solution.\n        :param estimated_params: List of estimated parameter values.\n        :param time_points: 1D numpy array of time points.\n        :param P_data: Observed data for phosphorylation levels.\n        :param seq_model_fit: Estimated model fit values.\n        :param psite_labels: Labels for the phosphorylation sites.\n        :param perplexity: Perplexity parameter for t-SNE.\n        :param components: Number of PCA components to plot.\n        :param target_variance: The target cumulative explained variance to determine the required number of components.\n        \"\"\"\n        self.plot_parallel(solution, labels)\n        self.plot_tsne(solution, perplexity=perplexity)\n        self.plot_pca(solution, components=components)\n        self.pca_components(solution, target_variance=target_variance)\n        self.plot_model_fit(seq_model_fit, P_data, solution, len(psite_labels), psite_labels, time_points)\n        if ESTIMATION_MODE == 'sequential':\n            self.plot_param_series(estimated_params, get_param_names(len(psite_labels)), time_points)\n            self.plot_A_S(estimated_params, len(psite_labels), time_points)\n\n    def plot_clusters(self, s_values_df: pd.DataFrame, cluster_labels):\n        \"\"\"\n        Plots the clusters of S values for the given gene.\n        Expects s_values_df to have columns 'S_value', 'GeneID', and 'Psite'.\n\n        :param s_values_df: DataFrame containing S values and gene information.\n        :param cluster_labels: Cluster labels for each S value.\n        \"\"\"\n        df = s_values_df.copy()\n        df['Cluster'] = cluster_labels\n        fig, ax = plt.subplots(figsize=(8, 8))\n        sns.scatterplot(x=df.index, y=df['S_value'], hue=cluster_labels, palette=\"viridis\", s=100, ax=ax)\n        for i, row in df.iterrows():\n            ax.text(i, row['S_value'], f\"{row['GeneID']}-{row['Psite']}\", fontsize=9, ha='right')\n        ax.set_title('')\n        ax.set_ylabel('S', fontstyle='italic')\n        ax.set_xticks([])\n        plt.tight_layout()\n        self._save_fig(fig, f\"{self.gene}_protein_clusters.png\")\n\n    def plot_heatmap(self, param_value_df: pd.DataFrame):\n        \"\"\"\n        Expects param_value_df to have a 'Protein' column.\n        \"\"\"\n        df = param_value_df.copy()\n        if 'Protein' in df.columns:\n            df.set_index('Protein', inplace=True)\n        correlation_matrix = df.T.corr()\n        fig, ax = plt.subplots(figsize=(8, 8))\n        sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', vmin=-1, vmax=1, square=True, ax=ax)\n        ax.set_title('')\n        plt.tight_layout()\n        self._save_fig(fig, f\"{self.gene}_heatmap_protein.png\")\n\n    def plot_error_distribution(self, error_df: pd.DataFrame):\n        \"\"\"\n        Expects error_df to have a 'MAE' column.\n        \"\"\"\n        fig, ax = plt.subplots(figsize=(8, 8))\n        sns.histplot(error_df['MAE'], kde=True, color='blue', label='MSE', ax=ax)\n        sns.histplot(error_df['MAE'], kde=True, color='orange', label='MAE', ax=ax)\n        ax.set_xlabel('Error')\n        ax.set_ylabel('Frequency')\n        ax.set_title('')\n        ax.legend()\n        plt.tight_layout()\n        self._save_fig(fig, f\"{self.gene}_model_error.png\")\n\n    def plot_gof_1(self, merged_data: pd.DataFrame):\n        \"\"\"\n        Expects merged_data to contain 'GeneID', 'Psite', and columns 'x1_obs' to 'x14_obs' and 'x1_est' to 'x14_est'.\n        \"\"\"\n        overall_std = merged_data.loc[:, 'x1_obs':'x14_obs'].values.std()\n        ci_offset_95 = 1.96 * overall_std\n        ci_offset_99 = 2.576 * overall_std\n\n        unique_genes = merged_data['GeneID'].unique()\n        palette = sns.color_palette(\"tab20\", len(unique_genes))\n        gene_color_map = {gene: palette[i] for i, gene in enumerate(unique_genes)}\n\n        fig, ax = plt.subplots(figsize=(8, 8))\n        gene_handles = []\n        obs_array = merged_data.loc[:, 'x1_obs':'x14_obs'].values\n        est_array = merged_data.loc[:, 'x1_est':'x14_est'].values\n        for gene, psite, obs_vals, est_vals in zip(merged_data['GeneID'],\n                                                   merged_data['Psite'],\n                                                   obs_array, est_array):\n            sorted_indices = np.argsort(obs_vals)\n            obs_vals_sorted = obs_vals[sorted_indices]\n            est_vals_sorted = est_vals[sorted_indices]\n            ax.scatter(obs_vals_sorted, est_vals_sorted, color=gene_color_map[gene],\n                       edgecolor='black', s=50)\n            if gene not in [handle.get_label() for handle in gene_handles]:\n                handle = plt.Line2D([], [], color=gene_color_map[gene],\n                                    marker='o', linestyle='', markersize=8, label=gene)\n                gene_handles.append(handle)\n        min_val = min(obs_array.min(), est_array.min())\n        max_val = max(obs_array.max(), est_array.max())\n        ax.plot([min_val, max_val], [min_val, max_val],\n                color='gray', linestyle='-', linewidth=1.5)\n        ax.plot([min_val, max_val],\n                [min_val + ci_offset_95, max_val + ci_offset_95],\n                color='red', linestyle='--', linewidth=1, label='95% CI')\n        ax.plot([min_val, max_val],\n                [min_val - ci_offset_95, max_val - ci_offset_95],\n                color='red', linestyle='--', linewidth=1)\n        ax.plot([min_val, max_val],\n                [min_val + ci_offset_99, max_val + ci_offset_99],\n                color='gray', linestyle='--', linewidth=1, label='99% CI')\n        ax.plot([min_val, max_val],\n                [min_val - ci_offset_99, max_val - ci_offset_99],\n                color='gray', linestyle='--', linewidth=1)\n        ax.set_xlabel(\"Observed\")\n        ax.set_ylabel(\"Fitted\")\n        ax.set_title(f\"{model_type} model\")\n        ax.legend(handles=gene_handles, loc='upper left', fontsize='small', ncol=2)\n        ax.grid(True)\n        plt.tight_layout()\n        self._save_fig(fig, f\"_gof_1.png\")\n\n    def plot_gof_2(self, merged_data: pd.DataFrame):\n        overall_std = merged_data.loc[:, 'x1_obs':'x14_obs'].values.std()\n        ci_offset_95 = 1.96 * overall_std\n        ci_offset_99 = 2.576 * overall_std\n\n        unique_genes = merged_data['GeneID'].unique()\n        palette = sns.color_palette(\"tab20\", len(unique_genes))\n        gene_color_map = {gene: palette[i] for i, gene in enumerate(unique_genes)}\n\n        fig, ax = plt.subplots(figsize=(8, 8))\n        gene_handles = []\n        obs_array = merged_data.loc[:, 'x1_obs':'x14_obs'].values\n        est_array = merged_data.loc[:, 'x1_est':'x14_est'].values\n        for gene, psite, obs_vals, est_vals in zip(merged_data['GeneID'],\n                                                   merged_data['Psite'],\n                                                   obs_array, est_array):\n            sorted_indices = np.argsort(obs_vals)\n            obs_vals_sorted = obs_vals[sorted_indices]\n            est_vals_sorted = est_vals[sorted_indices]\n            ax.scatter(obs_vals_sorted, est_vals_sorted, color=gene_color_map[gene],\n                       edgecolor='black', s=50)\n            if gene not in [handle.get_label() for handle in gene_handles]:\n                handle = plt.Line2D([], [], color=gene_color_map[gene],\n                                    marker='o', linestyle='', markersize=8, label=gene)\n                gene_handles.append(handle)\n        min_val = min(obs_array.min(), est_array.min())\n        max_val = max(obs_array.max(), est_array.max())\n        ax.plot([min_val, max_val], [min_val, max_val],\n                color='gray', linestyle='-', linewidth=1.5)\n        ax.plot([min_val, max_val],\n                [min_val + ci_offset_95, max_val + ci_offset_95],\n                color='red', linestyle='--', linewidth=1, label='95% CI')\n        ax.plot([min_val, max_val],\n                [min_val - ci_offset_95, max_val - ci_offset_95],\n                color='red', linestyle='--', linewidth=1)\n        ax.plot([min_val, max_val],\n                [min_val + ci_offset_99, max_val + ci_offset_99],\n                color='gray', linestyle='--', linewidth=1, label='99% CI')\n        ax.plot([min_val, max_val],\n                [min_val - ci_offset_99, max_val - ci_offset_99],\n                color='gray', linestyle='--', linewidth=1)\n        # Expand axis limits slightly\n        x_min = obs_array.min() - 0.1 * (obs_array.max() - obs_array.min())\n        x_max = obs_array.max() + 0.1 * (obs_array.max() - obs_array.min())\n        y_min = est_array.min() - 0.1 * (est_array.max() - est_array.min())\n        y_max = est_array.max() + 0.1 * (est_array.max() - est_array.min())\n        ax.set_xlim(x_min, x_max)\n        ax.set_ylim(y_min, y_max)\n        ax.set_xlabel(\"Observed\")\n        ax.set_ylabel(\"Fitted\")\n        ax.set_title(f\"{model_type} model\")\n        ax.legend(handles=gene_handles, loc='upper left', fontsize='small', ncol=2)\n        ax.grid(True)\n        plt.tight_layout()\n        self._save_fig(fig, f\"_gof_2.png\")\n\n    def plot_gof_3(self, merged_data: pd.DataFrame):\n        overall_std = merged_data.loc[:, 'x1_obs':'x14_obs'].values.std()\n        ci_offset_95 = 1.96 * overall_std\n        ci_offset_99 = 2.576 * overall_std\n\n        unique_genes = merged_data['GeneID'].unique()\n        palette = sns.color_palette(\"tab20\", len(unique_genes))\n        gene_color_map = {gene: palette[i] for i, gene in enumerate(unique_genes)}\n\n        fig, ax = plt.subplots(figsize=(8, 8))\n        plotted_genes = set()\n        text_annotations = []\n        obs_array = merged_data.loc[:, 'x1_obs':'x14_obs'].values\n        est_array = merged_data.loc[:, 'x1_est':'x14_est'].values\n        for gene, psite, obs_vals, est_vals in zip(merged_data['GeneID'],\n                                                   merged_data['Psite'],\n                                                   obs_array, est_array):\n            sorted_indices = np.argsort(obs_vals)\n            obs_vals_sorted = obs_vals[sorted_indices]\n            est_vals_sorted = est_vals[sorted_indices]\n            ax.scatter(obs_vals_sorted, est_vals_sorted, color=gene_color_map[gene],\n                       edgecolor='black', s=50)\n            for obs, est in zip(obs_vals_sorted, est_vals_sorted):\n                if gene not in plotted_genes and (est &gt; obs + ci_offset_95 or est &lt; obs - ci_offset_95):\n                    txt = ax.text(obs, est, gene, fontsize=10, color=gene_color_map[gene],\n                                  fontweight='bold', ha='center', va='center',\n                                  bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n                    text_annotations.append(txt)\n                    plotted_genes.add(gene)\n        min_val = min(obs_array.min(), est_array.min())\n        max_val = max(obs_array.max(), est_array.max())\n        ax.plot([min_val, max_val], [min_val, max_val],\n                color='gray', linestyle='-', linewidth=1.5)\n        ax.plot([min_val, max_val],\n                [min_val + ci_offset_95, max_val + ci_offset_95],\n                color='red', linestyle='--', linewidth=1, label='95% CI')\n        ax.plot([min_val, max_val],\n                [min_val - ci_offset_95, max_val - ci_offset_95],\n                color='red', linestyle='--', linewidth=1)\n        ax.plot([min_val, max_val],\n                [min_val + ci_offset_99, max_val + ci_offset_99],\n                color='gray', linestyle='--', linewidth=1, label='99% CI')\n        ax.plot([min_val, max_val],\n                [min_val - ci_offset_99, max_val - ci_offset_99],\n                color='gray', linestyle='--', linewidth=1)\n        ax.set_xlabel(\"Observed\")\n        ax.set_ylabel(\"Fitted\")\n        ax.set_title(f\"{model_type} model\")\n        ax.legend(loc='upper left', fontsize='small', ncol=2)\n        ax.grid(True)\n        plt.tight_layout()\n        adjust_text(text_annotations, arrowprops=dict(arrowstyle='-&gt;', color='gray', lw=0.5))\n        self._save_fig(fig, f\"gof_3.png\")\n\n    def plot_gof_4(self, merged_data: pd.DataFrame):\n        overall_std = merged_data.loc[:, 'x1_obs':'x14_obs'].values.std()\n        ci_offset_95 = 1.96 * overall_std\n        ci_offset_99 = 2.576 * overall_std\n\n        unique_genes = merged_data['GeneID'].unique()\n        palette = sns.color_palette(\"tab20\", len(unique_genes))\n        gene_color_map = {gene: palette[i] for i, gene in enumerate(unique_genes)}\n\n        fig, ax = plt.subplots(figsize=(8, 8))\n        plotted_genes = set()\n        text_annotations = []\n        obs_array = merged_data.loc[:, 'x1_obs':'x14_obs'].values\n        est_array = merged_data.loc[:, 'x1_est':'x14_est'].values\n        for gene, psite, obs_vals, est_vals in zip(merged_data['GeneID'],\n                                                   merged_data['Psite'],\n                                                   obs_array, est_array):\n            sorted_indices = np.argsort(obs_vals)\n            obs_vals_sorted = obs_vals[sorted_indices]\n            est_vals_sorted = est_vals[sorted_indices]\n            ax.scatter(obs_vals_sorted, est_vals_sorted, color=gene_color_map[gene],\n                       edgecolor='black', s=50)\n            for obs, est in zip(obs_vals_sorted, est_vals_sorted):\n                if gene not in plotted_genes and (est &gt; obs + ci_offset_95 or est &lt; obs - ci_offset_95):\n                    txt = ax.text(obs, est, gene, fontsize=10, color=gene_color_map[gene],\n                                  fontweight='bold', ha='center', va='center',\n                                  bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n                    text_annotations.append(txt)\n                    plotted_genes.add(gene)\n        min_val = min(obs_array.min(), est_array.min())\n        max_val = max(obs_array.max(), est_array.max())\n        ax.plot([min_val, max_val], [min_val, max_val],\n                color='gray', linestyle='-', linewidth=1.5)\n        ax.plot([min_val, max_val],\n                [min_val + ci_offset_95, max_val + ci_offset_95],\n                color='red', linestyle='--', linewidth=1, label='95% CI')\n        ax.plot([min_val, max_val],\n                [min_val - ci_offset_95, max_val - ci_offset_95],\n                color='red', linestyle='--', linewidth=1)\n        ax.plot([min_val, max_val],\n                [min_val + ci_offset_99, max_val + ci_offset_99],\n                color='gray', linestyle='--', linewidth=1, label='99% CI')\n        ax.plot([min_val, max_val],\n                [min_val - ci_offset_99, max_val - ci_offset_99],\n                color='gray', linestyle='--', linewidth=1)\n        # Expand axis limits\n        x_min = obs_array.min() - 0.1 * (obs_array.max() - obs_array.min())\n        x_max = obs_array.max() + 0.1 * (obs_array.max() - obs_array.min())\n        y_min = est_array.min() - 0.1 * (est_array.max() - est_array.min())\n        y_max = est_array.max() + 0.1 * (est_array.max() - est_array.min())\n        ax.set_xlim(x_min, x_max)\n        ax.set_ylim(y_min, y_max)\n        ax.set_xlabel(\"Observed\")\n        ax.set_ylabel(\"Fitted\")\n        ax.set_title(f\"{model_type} model\")\n        ax.legend(loc='upper left', fontsize='small', ncol=2)\n        ax.grid(True)\n        plt.tight_layout()\n        adjust_text(text_annotations, arrowprops=dict(arrowstyle='-&gt;', color='gray', lw=0.5))\n        self._save_fig(fig, f\"_gof_4.png\")\n\n    def plot_gof_5(self, merged_data: pd.DataFrame):\n        \"\"\"\n        Uses the row means of observed (x1_obs:x14_obs) and estimated (x1_est:x14_est) values.\n        \"\"\"\n        df = merged_data.copy()\n        if 'Observed_Mean' not in df.columns or 'Estimated_Mean' not in df.columns:\n            df['Observed_Mean'] = df.loc[:, 'x1_obs':'x14_obs'].mean(axis=1)\n            df['Estimated_Mean'] = df.loc[:, 'x1_est':'x14_est'].mean(axis=1)\n        overall_std = df['Observed_Mean'].std()\n        ci_offset_95 = 1.96 * overall_std\n        ci_offset_99 = 2.576 * overall_std\n\n        unique_genes = df['GeneID'].unique()\n        palette = sns.color_palette(\"tab20\", len(unique_genes))\n        colors = {gene: palette[i] for i, gene in enumerate(unique_genes)}\n\n        fig, ax = plt.subplots(figsize=(8, 8))\n        plotted_genes = set()\n        for obs, est, gene in zip(df['Observed_Mean'], df['Estimated_Mean'], df['GeneID']):\n            ax.scatter(obs, est, color=colors[gene], edgecolor='black', s=100, marker='o')\n            if gene not in plotted_genes and (est &gt; obs + ci_offset_95 or est &lt; obs - ci_offset_95):\n                ax.text(obs, est, gene, fontsize=10, color=colors[gene],\n                        fontweight='bold', ha='center', va='center',\n                        bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n                plotted_genes.add(gene)\n        x_vals = [min(df['Observed_Mean'].min(), df['Estimated_Mean'].min()),\n                  max(df['Observed_Mean'].max(), df['Estimated_Mean'].max())]\n        ax.plot(x_vals, x_vals, color='grey', linestyle='-', linewidth=1.5)\n        ax.plot(x_vals, [x + ci_offset_95 for x in x_vals],\n                color='red', linestyle='--', linewidth=1, label='95% CI')\n        ax.plot(x_vals, [x - ci_offset_95 for x in x_vals],\n                color='red', linestyle='--', linewidth=1)\n        ax.plot(x_vals, [x + ci_offset_99 for x in x_vals],\n                color='gray', linestyle='--', linewidth=1, label='99% CI')\n        ax.plot(x_vals, [x - ci_offset_99 for x in x_vals],\n                color='gray', linestyle='--', linewidth=1)\n        ax.set_xlabel(\"Observed\")\n        ax.set_ylabel(\"Fitted\")\n        ax.set_title(f\"{model_type} model\")\n        ax.legend(loc='upper left', fontsize='small', ncol=2)\n        ax.grid(True)\n        plt.tight_layout()\n        self._save_fig(fig, f\"_gof_5.png\")\n\n    def plot_gof_6(self, merged_data: pd.DataFrame):\n        df = merged_data.copy()\n        if 'Observed_Mean' not in df.columns or 'Estimated_Mean' not in df.columns:\n            df['Observed_Mean'] = df.loc[:, 'x1_obs':'x14_obs'].mean(axis=1)\n            df['Estimated_Mean'] = df.loc[:, 'x1_est':'x14_est'].mean(axis=1)\n        overall_std = df['Observed_Mean'].std()\n        ci_offset_95 = 1.96 * overall_std\n        ci_offset_99 = 2.576 * overall_std\n\n        unique_genes = df['GeneID'].unique()\n        palette = sns.color_palette(\"tab20\", len(unique_genes))\n        colors = {gene: palette[i] for i, gene in enumerate(unique_genes)}\n\n        fig, ax = plt.subplots(figsize=(8, 8))\n        plotted_genes = set()\n        sorted_indices = np.argsort(df['Observed_Mean'].values)\n        for idx in sorted_indices:\n            obs = df['Observed_Mean'].iloc[idx]\n            est = df['Estimated_Mean'].iloc[idx]\n            gene = df['GeneID'].iloc[idx]\n            ax.scatter(obs, est, color=colors[gene], edgecolor='black', s=100, marker='o')\n            if gene not in plotted_genes and (est &gt; obs + ci_offset_95 or est &lt; obs - ci_offset_95):\n                ax.text(obs, est, gene, fontsize=10, color=colors[gene],\n                        fontweight='bold', ha='center', va='center',\n                        bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n                plotted_genes.add(gene)\n        x_min = df['Observed_Mean'].min() - 0.1 * (df['Observed_Mean'].max() - df['Observed_Mean'].min())\n        x_max = df['Observed_Mean'].max() + 0.1 * (df['Observed_Mean'].max() - df['Observed_Mean'].min())\n        y_min = df['Estimated_Mean'].min() - 0.1 * (df['Estimated_Mean'].max() - df['Estimated_Mean'].min())\n        y_max = df['Estimated_Mean'].max() + 0.1 * (df['Estimated_Mean'].max() - df['Estimated_Mean'].min())\n        ax.set_xlim(x_min, x_max)\n        ax.set_ylim(y_min, y_max)\n        x_vals = [df['Observed_Mean'].min(), df['Observed_Mean'].max()]\n        ax.plot(x_vals, x_vals, color='grey', linestyle='-', linewidth=1.5)\n        ax.plot(x_vals, [x + ci_offset_95 for x in x_vals],\n                color='red', linestyle='--', linewidth=1, label='95% CI')\n        ax.plot(x_vals, [x - ci_offset_95 for x in x_vals],\n                color='red', linestyle='--', linewidth=1)\n        ax.plot(x_vals, [x + ci_offset_99 for x in x_vals],\n                color='gray', linestyle='--', linewidth=1, label='99% CI')\n        ax.plot(x_vals, [x - ci_offset_99 for x in x_vals],\n                color='gray', linestyle='--', linewidth=1)\n        ax.set_xlabel(\"Observed\")\n        ax.set_ylabel(\"Fitted\")\n        ax.set_title(f\"{model_type} model\")\n        ax.legend(loc='upper left', fontsize='small', ncol=2)\n        ax.grid(True)\n        plt.tight_layout()\n        self._save_fig(fig, f\"_gof_6.png\")\n\n    def plot_kld(self, merged_data: pd.DataFrame):\n        \"\"\"\n        Expects merged_data to have columns 'x1_obs' to 'x14_obs' and 'x1_est' to 'x14_est',\n        as well as 'GeneID' and 'Psite'.\n        \"\"\"\n        obs_data = merged_data.loc[:, 'x1_obs':'x14_obs']\n        est_data = merged_data.loc[:, 'x1_est':'x14_est']\n        normalized_obs = obs_data.div(obs_data.sum(axis=1), axis=0)\n        normalized_est = est_data.div(est_data.sum(axis=1), axis=0)\n        kl_div = normalized_obs.apply(lambda row: entropy(row, normalized_est.loc[row.name]), axis=1)\n        kl_df = merged_data[['GeneID', 'Psite']].copy()\n        kl_df['KL'] = kl_div.values\n        kl_by_gene = kl_df.groupby('GeneID')['KL'].mean().sort_values()\n\n        fig, ax = plt.subplots(figsize=(8, 8))\n        indices = kl_by_gene.index.tolist()\n        values = kl_by_gene.values\n        ax.scatter(indices, values, marker='s', color='blue', label='Mean Normalized')\n        ax.set_xticklabels(indices, rotation=45, ha='right')\n        ax.set_ylabel(\"Entropy\")\n        ax.set_title(\"Kullback-Liebler Divergence\")\n        ax.legend()\n        plt.tight_layout()\n        self._save_fig(fig, f\"_kld.png\")\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.pca_components","title":"<code>pca_components(solution, target_variance=0.99)</code>","text":"<p>Plots a scree plot showing the explained variance ratio for PCA components.</p> <p>:param solution: 2D numpy array of shape (samples, features) representing the data. :param target_variance: The target cumulative explained variance to determine the required number of components. :return: A tuple containing the number of required components and the explained variance ratio.</p> Source code in <code>plotting/plotting.py</code> <pre><code>def pca_components(self, solution: np.ndarray, target_variance: float = 0.99):\n    \"\"\"\n    Plots a scree plot showing the explained variance ratio for PCA components.\n\n    :param solution: 2D numpy array of shape (samples, features) representing the data.\n    :param target_variance: The target cumulative explained variance to determine the required number of components.\n    :return: A tuple containing the number of required components and the explained variance ratio.\n    \"\"\"\n\n    pca = PCA(n_components=min(solution.shape))\n    pca.fit(solution)\n    explained_variance = pca.explained_variance_ratio_\n    cumulative_explained_variance = np.cumsum(explained_variance)\n    required_components = np.argmax(cumulative_explained_variance &gt;= target_variance) + 1\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.bar(range(1, len(explained_variance) + 1), explained_variance * 100,\n           alpha=0.6, color='b', label='Individual')\n    ax.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance * 100,\n            marker='o', color='r', label='Cumulative')\n    ax.axvline(x=required_components, color='g', linestyle='--',\n               label=f'{required_components} Components')\n    ax.set_title(self.gene)\n    ax.set_xlabel('Principal Component')\n    ax.set_ylabel('Explained Variance (%)')\n    ax.legend()\n    ax.grid(True)\n    self._save_fig(fig, f\"{self.gene}_scree_plot_.png\")\n    return required_components, explained_variance\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_A_S","title":"<code>plot_A_S(est_arr, num_psites, time_vals)</code>","text":"<p>Plots the scatter plot of A vs S and the density contour plot.</p> <p>:param est_arr: Estimated parameters array. :param num_psites: Number of phosphorylation sites. :param time_vals: Time values for the data. :return:</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_A_S(self, est_arr: np.ndarray, num_psites: int, time_vals: np.ndarray):\n    \"\"\"\n    Plots the scatter plot of A vs S and the density contour plot.\n\n    :param est_arr: Estimated parameters array.\n    :param num_psites: Number of phosphorylation sites.\n    :param time_vals: Time values for the data.\n    :return:\n    \"\"\"\n    est_arr = np.array(est_arr)\n    A_vals = est_arr[:, 0]\n    cmap = plt.get_cmap(\"viridis\")\n    norm = mcolors.Normalize(vmin=min(time_vals), vmax=max(time_vals))\n    fig, ax = plt.subplots(figsize=(8, 8))\n    legend_handles = []\n    for i in range(num_psites):\n        S_vals = est_arr[:, 4 + i]\n        sc = ax.scatter(A_vals, S_vals, c=time_vals, cmap=cmap, norm=norm,\n                        s=50, alpha=0.8, marker=available_markers[i])\n        slope, intercept = np.polyfit(A_vals, S_vals, 1)\n        x_fit = np.linspace(A_vals.min(), A_vals.max(), 100)\n        y_fit = slope * x_fit + intercept\n        line_color = f\"C{i}\"\n        ax.plot(x_fit, y_fit, color=line_color, lw=1)\n        legend_handles.append(Line2D([0], [0],\n                                     marker=available_markers[i],\n                                     color='w',\n                                     markerfacecolor=line_color,\n                                     markeredgecolor='k',\n                                     markersize=8,\n                                     label=f\"S{i + 1}\"))\n    ax.set_xlabel(\"A (mRNA production rate)\")\n    ax.set_ylabel(\"S (Phosphorylation rate)\")\n    ax.set_title(self.gene)\n    cbar = plt.colorbar(sc, ax=ax)\n    cbar.set_label(\"Time (min)\")\n    ax.grid(True)\n    ax.legend(handles=legend_handles)\n    plt.tight_layout()\n    self._save_fig(fig, f\"{self.gene}_scatter_A_S_.png\")\n\n    # Density contour plot for A and S.\n    all_points = np.vstack([np.column_stack((A_vals, est_arr[:, 4 + i])) for i in range(num_psites)])\n    kde = gaussian_kde(all_points.T)\n    A_lin = np.linspace(A_vals.min(), A_vals.max(), 100)\n    all_S = all_points[:, 1]\n    S_lin = np.linspace(all_S.min(), all_S.max(), 100)\n    A_grid, S_grid = np.meshgrid(A_lin, S_lin)\n    grid_coords = np.vstack([A_grid.ravel(), S_grid.ravel()])\n    density = kde(grid_coords).reshape(A_grid.shape)\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.scatter(all_points[:, 0], all_points[:, 1], c='black', s=30, alpha=0.5)\n    contourf = ax.contourf(A_grid, S_grid, density, levels=10, cmap=\"inferno\", alpha=0.7)\n    ax.contour(A_grid, S_grid, density, levels=CONTOUR_LEVELS, colors='white', linewidths=0.5)\n    ax.set_xlabel(\"A\")\n    ax.set_ylabel(\"S\")\n    ax.set_title(self.gene)\n    cbar = plt.colorbar(contourf, ax=ax)\n    cbar.set_label(\"Density\")\n    plt.tight_layout()\n    self._save_fig(fig, f\"{self.gene}_density_A_S_.png\")\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_all","title":"<code>plot_all(solution, labels, estimated_params, time_points, P_data, seq_model_fit, psite_labels, perplexity=5, components=3, target_variance=0.99)</code>","text":"<p>Function that calls parallel, t-SNE, PCA, and model fit plots. If mode is sequential, it also calls parameter series and A-S plots.</p> <p>:param solution: 2D numpy array of shape (samples, features) representing the data. :param labels: List of labels for the solution. :param estimated_params: List of estimated parameter values. :param time_points: 1D numpy array of time points. :param P_data: Observed data for phosphorylation levels. :param seq_model_fit: Estimated model fit values. :param psite_labels: Labels for the phosphorylation sites. :param perplexity: Perplexity parameter for t-SNE. :param components: Number of PCA components to plot. :param target_variance: The target cumulative explained variance to determine the required number of components.</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_all(self, solution: np.ndarray, labels: list, estimated_params: list,\n             time_points: np.ndarray, P_data: np.ndarray, seq_model_fit: np.ndarray,\n             psite_labels: list, perplexity: int = 5, components: int = 3, target_variance: float = 0.99):\n    \"\"\"\n    Function that calls parallel, t-SNE, PCA, and model fit plots.\n    If mode is sequential, it also calls parameter series and A-S plots.\n\n    :param solution: 2D numpy array of shape (samples, features) representing the data.\n    :param labels: List of labels for the solution.\n    :param estimated_params: List of estimated parameter values.\n    :param time_points: 1D numpy array of time points.\n    :param P_data: Observed data for phosphorylation levels.\n    :param seq_model_fit: Estimated model fit values.\n    :param psite_labels: Labels for the phosphorylation sites.\n    :param perplexity: Perplexity parameter for t-SNE.\n    :param components: Number of PCA components to plot.\n    :param target_variance: The target cumulative explained variance to determine the required number of components.\n    \"\"\"\n    self.plot_parallel(solution, labels)\n    self.plot_tsne(solution, perplexity=perplexity)\n    self.plot_pca(solution, components=components)\n    self.pca_components(solution, target_variance=target_variance)\n    self.plot_model_fit(seq_model_fit, P_data, solution, len(psite_labels), psite_labels, time_points)\n    if ESTIMATION_MODE == 'sequential':\n        self.plot_param_series(estimated_params, get_param_names(len(psite_labels)), time_points)\n        self.plot_A_S(estimated_params, len(psite_labels), time_points)\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_clusters","title":"<code>plot_clusters(s_values_df, cluster_labels)</code>","text":"<p>Plots the clusters of S values for the given gene. Expects s_values_df to have columns 'S_value', 'GeneID', and 'Psite'.</p> <p>:param s_values_df: DataFrame containing S values and gene information. :param cluster_labels: Cluster labels for each S value.</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_clusters(self, s_values_df: pd.DataFrame, cluster_labels):\n    \"\"\"\n    Plots the clusters of S values for the given gene.\n    Expects s_values_df to have columns 'S_value', 'GeneID', and 'Psite'.\n\n    :param s_values_df: DataFrame containing S values and gene information.\n    :param cluster_labels: Cluster labels for each S value.\n    \"\"\"\n    df = s_values_df.copy()\n    df['Cluster'] = cluster_labels\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.scatterplot(x=df.index, y=df['S_value'], hue=cluster_labels, palette=\"viridis\", s=100, ax=ax)\n    for i, row in df.iterrows():\n        ax.text(i, row['S_value'], f\"{row['GeneID']}-{row['Psite']}\", fontsize=9, ha='right')\n    ax.set_title('')\n    ax.set_ylabel('S', fontstyle='italic')\n    ax.set_xticks([])\n    plt.tight_layout()\n    self._save_fig(fig, f\"{self.gene}_protein_clusters.png\")\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_error_distribution","title":"<code>plot_error_distribution(error_df)</code>","text":"<p>Expects error_df to have a 'MAE' column.</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_error_distribution(self, error_df: pd.DataFrame):\n    \"\"\"\n    Expects error_df to have a 'MAE' column.\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.histplot(error_df['MAE'], kde=True, color='blue', label='MSE', ax=ax)\n    sns.histplot(error_df['MAE'], kde=True, color='orange', label='MAE', ax=ax)\n    ax.set_xlabel('Error')\n    ax.set_ylabel('Frequency')\n    ax.set_title('')\n    ax.legend()\n    plt.tight_layout()\n    self._save_fig(fig, f\"{self.gene}_model_error.png\")\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_gof_1","title":"<code>plot_gof_1(merged_data)</code>","text":"<p>Expects merged_data to contain 'GeneID', 'Psite', and columns 'x1_obs' to 'x14_obs' and 'x1_est' to 'x14_est'.</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_gof_1(self, merged_data: pd.DataFrame):\n    \"\"\"\n    Expects merged_data to contain 'GeneID', 'Psite', and columns 'x1_obs' to 'x14_obs' and 'x1_est' to 'x14_est'.\n    \"\"\"\n    overall_std = merged_data.loc[:, 'x1_obs':'x14_obs'].values.std()\n    ci_offset_95 = 1.96 * overall_std\n    ci_offset_99 = 2.576 * overall_std\n\n    unique_genes = merged_data['GeneID'].unique()\n    palette = sns.color_palette(\"tab20\", len(unique_genes))\n    gene_color_map = {gene: palette[i] for i, gene in enumerate(unique_genes)}\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n    gene_handles = []\n    obs_array = merged_data.loc[:, 'x1_obs':'x14_obs'].values\n    est_array = merged_data.loc[:, 'x1_est':'x14_est'].values\n    for gene, psite, obs_vals, est_vals in zip(merged_data['GeneID'],\n                                               merged_data['Psite'],\n                                               obs_array, est_array):\n        sorted_indices = np.argsort(obs_vals)\n        obs_vals_sorted = obs_vals[sorted_indices]\n        est_vals_sorted = est_vals[sorted_indices]\n        ax.scatter(obs_vals_sorted, est_vals_sorted, color=gene_color_map[gene],\n                   edgecolor='black', s=50)\n        if gene not in [handle.get_label() for handle in gene_handles]:\n            handle = plt.Line2D([], [], color=gene_color_map[gene],\n                                marker='o', linestyle='', markersize=8, label=gene)\n            gene_handles.append(handle)\n    min_val = min(obs_array.min(), est_array.min())\n    max_val = max(obs_array.max(), est_array.max())\n    ax.plot([min_val, max_val], [min_val, max_val],\n            color='gray', linestyle='-', linewidth=1.5)\n    ax.plot([min_val, max_val],\n            [min_val + ci_offset_95, max_val + ci_offset_95],\n            color='red', linestyle='--', linewidth=1, label='95% CI')\n    ax.plot([min_val, max_val],\n            [min_val - ci_offset_95, max_val - ci_offset_95],\n            color='red', linestyle='--', linewidth=1)\n    ax.plot([min_val, max_val],\n            [min_val + ci_offset_99, max_val + ci_offset_99],\n            color='gray', linestyle='--', linewidth=1, label='99% CI')\n    ax.plot([min_val, max_val],\n            [min_val - ci_offset_99, max_val - ci_offset_99],\n            color='gray', linestyle='--', linewidth=1)\n    ax.set_xlabel(\"Observed\")\n    ax.set_ylabel(\"Fitted\")\n    ax.set_title(f\"{model_type} model\")\n    ax.legend(handles=gene_handles, loc='upper left', fontsize='small', ncol=2)\n    ax.grid(True)\n    plt.tight_layout()\n    self._save_fig(fig, f\"_gof_1.png\")\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_gof_5","title":"<code>plot_gof_5(merged_data)</code>","text":"<p>Uses the row means of observed (x1_obs:x14_obs) and estimated (x1_est:x14_est) values.</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_gof_5(self, merged_data: pd.DataFrame):\n    \"\"\"\n    Uses the row means of observed (x1_obs:x14_obs) and estimated (x1_est:x14_est) values.\n    \"\"\"\n    df = merged_data.copy()\n    if 'Observed_Mean' not in df.columns or 'Estimated_Mean' not in df.columns:\n        df['Observed_Mean'] = df.loc[:, 'x1_obs':'x14_obs'].mean(axis=1)\n        df['Estimated_Mean'] = df.loc[:, 'x1_est':'x14_est'].mean(axis=1)\n    overall_std = df['Observed_Mean'].std()\n    ci_offset_95 = 1.96 * overall_std\n    ci_offset_99 = 2.576 * overall_std\n\n    unique_genes = df['GeneID'].unique()\n    palette = sns.color_palette(\"tab20\", len(unique_genes))\n    colors = {gene: palette[i] for i, gene in enumerate(unique_genes)}\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n    plotted_genes = set()\n    for obs, est, gene in zip(df['Observed_Mean'], df['Estimated_Mean'], df['GeneID']):\n        ax.scatter(obs, est, color=colors[gene], edgecolor='black', s=100, marker='o')\n        if gene not in plotted_genes and (est &gt; obs + ci_offset_95 or est &lt; obs - ci_offset_95):\n            ax.text(obs, est, gene, fontsize=10, color=colors[gene],\n                    fontweight='bold', ha='center', va='center',\n                    bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n            plotted_genes.add(gene)\n    x_vals = [min(df['Observed_Mean'].min(), df['Estimated_Mean'].min()),\n              max(df['Observed_Mean'].max(), df['Estimated_Mean'].max())]\n    ax.plot(x_vals, x_vals, color='grey', linestyle='-', linewidth=1.5)\n    ax.plot(x_vals, [x + ci_offset_95 for x in x_vals],\n            color='red', linestyle='--', linewidth=1, label='95% CI')\n    ax.plot(x_vals, [x - ci_offset_95 for x in x_vals],\n            color='red', linestyle='--', linewidth=1)\n    ax.plot(x_vals, [x + ci_offset_99 for x in x_vals],\n            color='gray', linestyle='--', linewidth=1, label='99% CI')\n    ax.plot(x_vals, [x - ci_offset_99 for x in x_vals],\n            color='gray', linestyle='--', linewidth=1)\n    ax.set_xlabel(\"Observed\")\n    ax.set_ylabel(\"Fitted\")\n    ax.set_title(f\"{model_type} model\")\n    ax.legend(loc='upper left', fontsize='small', ncol=2)\n    ax.grid(True)\n    plt.tight_layout()\n    self._save_fig(fig, f\"_gof_5.png\")\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_heatmap","title":"<code>plot_heatmap(param_value_df)</code>","text":"<p>Expects param_value_df to have a 'Protein' column.</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_heatmap(self, param_value_df: pd.DataFrame):\n    \"\"\"\n    Expects param_value_df to have a 'Protein' column.\n    \"\"\"\n    df = param_value_df.copy()\n    if 'Protein' in df.columns:\n        df.set_index('Protein', inplace=True)\n    correlation_matrix = df.T.corr()\n    fig, ax = plt.subplots(figsize=(8, 8))\n    sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', vmin=-1, vmax=1, square=True, ax=ax)\n    ax.set_title('')\n    plt.tight_layout()\n    self._save_fig(fig, f\"{self.gene}_heatmap_protein.png\")\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_kld","title":"<code>plot_kld(merged_data)</code>","text":"<p>Expects merged_data to have columns 'x1_obs' to 'x14_obs' and 'x1_est' to 'x14_est', as well as 'GeneID' and 'Psite'.</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_kld(self, merged_data: pd.DataFrame):\n    \"\"\"\n    Expects merged_data to have columns 'x1_obs' to 'x14_obs' and 'x1_est' to 'x14_est',\n    as well as 'GeneID' and 'Psite'.\n    \"\"\"\n    obs_data = merged_data.loc[:, 'x1_obs':'x14_obs']\n    est_data = merged_data.loc[:, 'x1_est':'x14_est']\n    normalized_obs = obs_data.div(obs_data.sum(axis=1), axis=0)\n    normalized_est = est_data.div(est_data.sum(axis=1), axis=0)\n    kl_div = normalized_obs.apply(lambda row: entropy(row, normalized_est.loc[row.name]), axis=1)\n    kl_df = merged_data[['GeneID', 'Psite']].copy()\n    kl_df['KL'] = kl_div.values\n    kl_by_gene = kl_df.groupby('GeneID')['KL'].mean().sort_values()\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n    indices = kl_by_gene.index.tolist()\n    values = kl_by_gene.values\n    ax.scatter(indices, values, marker='s', color='blue', label='Mean Normalized')\n    ax.set_xticklabels(indices, rotation=45, ha='right')\n    ax.set_ylabel(\"Entropy\")\n    ax.set_title(\"Kullback-Liebler Divergence\")\n    ax.legend()\n    plt.tight_layout()\n    self._save_fig(fig, f\"_kld.png\")\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_model_fit","title":"<code>plot_model_fit(model_fit, P_data, sol, num_psites, psite_labels, time_points)</code>","text":"<p>Plots the model fit for the given data.</p> <p>:param model_fit: Estimated model fit values. :param P_data: Observed data for phosphorylation levels. :param sol: ODE solution for mRNA and protein levels. :param num_psites: number of phosphorylation sites. :param psite_labels: labels for the phosphorylation sites. :param time_points: time points for the data. :return:</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_model_fit(self, model_fit: np.ndarray, P_data: np.ndarray, sol: np.ndarray,\n                   num_psites: int, psite_labels: list, time_points: np.ndarray):\n    \"\"\"\n    Plots the model fit for the given data.\n\n    :param model_fit: Estimated model fit values.\n    :param P_data: Observed data for phosphorylation levels.\n    :param sol: ODE solution for mRNA and protein levels.\n    :param num_psites: number of phosphorylation sites.\n    :param psite_labels: labels for the phosphorylation sites.\n    :param time_points: time points for the data.\n    :return:\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.plot(time_points, sol[:, 0], '-', color='black', alpha=0.7, label='mRNA (R)')\n    ax.plot(time_points, sol[:, 1], '-', color='red', alpha=0.7, label='Protein (P)')\n    for i in range(num_psites):\n        ax.plot(time_points, P_data[i, :], '-', marker='s',\n                color=self.color_palette[i], label=f'P+{psite_labels[i]}')\n        ax.plot(time_points, model_fit[i, :], '-', color=self.color_palette[i],\n                label=f'P+{psite_labels[i]} (model)')\n    ax.set_xlabel(\"Time (minutes)\")\n    ax.set_ylabel(\"Phosphorylation level (FC)\")\n    ax.set_title(self.gene)\n    ax.grid(True)\n    ax.legend()\n    plt.tight_layout()\n    self._save_fig(fig, f\"{self.gene}_model_fit_.png\")\n\n    # Plot using Plotly for an interactive version.\n    fig_plotly = go.Figure()\n    fig_plotly.add_trace(go.Scatter(\n        x=time_points,\n        y=sol[:, 0],\n        mode='lines+markers',\n        name='mRNA(R)(model)',\n        line=dict(color='black')\n    ))\n    fig_plotly.add_trace(go.Scatter(\n        x=time_points,\n        y=sol[:, 1],\n        mode='lines+markers',\n        name='Protein(P)(model)',\n        line=dict(color='red')\n    ))\n    for i in range(num_psites):\n        fig_plotly.add_trace(go.Scatter(\n            x=time_points,\n            y=P_data[i, :] if num_psites &gt; 1 else P_data.flatten(),\n            mode='lines+markers',\n            name=f'P+{psite_labels[i]}',\n            line=dict(dash='dash', color=self.color_palette[i])\n        ))\n        fig_plotly.add_trace(go.Scatter(\n            x=time_points,\n            y=model_fit[i, :],\n            mode='lines+markers',\n            name=f'P+{psite_labels[i]} (model)',\n            line=dict(color=self.color_palette[i])\n        ))\n    fig_plotly.update_layout(title=self.gene,\n                             xaxis_title=\"Time (minutes)\",\n                             yaxis_title=\"Phosphorylation level (FC)\",\n                             template=\"plotly_white\",\n                             width=900, height=900)\n    fig_plotly.write_html(os.path.join(self.out_dir, f\"{self.gene}_model_fit_.html\"))\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_parallel","title":"<code>plot_parallel(solution, labels)</code>","text":"<p>Plots a parallel coordinates plot for the given solution.</p> <p>:param solution: 2D numpy array of shape (sampels, features) :param labels: list of labels</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_parallel(self, solution: np.ndarray, labels: list):\n    \"\"\"\n    Plots a parallel coordinates plot for the given solution.\n\n    :param solution: 2D numpy array of shape (sampels, features)\n    :param labels: list of labels\n    \"\"\"\n    df = pd.DataFrame(solution, columns=labels)\n    df['Time'] = range(1, len(df) + 1)\n    fig, ax = plt.subplots(figsize=(8, 8))\n    parallel_coordinates(df, class_column='Time', colormap=plt.get_cmap(\"tab20\"), ax=ax)\n    ax.set_title(self.gene)\n    ax.set_xlabel(\"States\")\n    ax.set_ylabel(\"Values\")\n    ax.legend(title=\"Time Points\", loc=\"upper right\", labels=df['Time'].astype(str).tolist())\n    self._save_fig(fig, f\"{self.gene}_parallel_coordinates_.png\")\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_param_bar","title":"<code>plot_param_bar(params_df, s_df)</code>","text":"<p>Plots a bar chart of parameter values for the given gene.</p> <p>This method visualizes the estimated parameter values for a specific gene and its phosphorylation sites. It uses color coding to distinguish between different phosphorylation sites and other parameters.</p> <p>:param params_df: DataFrame containing parameter values. :param s_df: DataFrame containing phosphorylation site information.</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_param_bar(self, params_df: pd.DataFrame, s_df: pd.DataFrame):\n    \"\"\"\n    Plots a bar chart of parameter values for the given gene.\n\n    This method visualizes the estimated parameter values for a specific gene\n    and its phosphorylation sites. It uses color coding to distinguish between\n    different phosphorylation sites and other parameters.\n\n    :param params_df: DataFrame containing parameter values.\n    :param s_df: DataFrame containing phosphorylation site information.\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(8, 8))\n    unique_psites = s_df.loc[s_df['GeneID'] == self.gene, 'Psite'].tolist()\n    color_map = {psite: plt.cm.tab20(i / len(unique_psites)) for i, psite in enumerate(unique_psites)}\n\n    if len(unique_psites) == 1:\n        single_psite = unique_psites[0]\n        color = color_map[single_psite]\n        if 'S' in params_df.columns and not params_df['S'].isna().all():\n            ax.bar('S', params_df['S'].mean(), color=color, label=f\"{single_psite}\")\n\n    for i, psite in enumerate(unique_psites):\n        color = color_map[psite]\n        for param in [f\"S{i + 1}\", f\"D{i + 1}\"]:\n            if param in params_df.columns and not params_df[param].isna().all():\n                ax.bar(param, params_df[param].mean(), color=color,\n                       label=f\"{psite}\" if psite not in [h.get_label() for h in\n                                                         ax.get_legend_handles_labels()[0]] else None)\n\n    other_params = [col for col in params_df.columns\n                    if col not in ['Protein', 'S'] + [f\"S{i + 1}\" for i in range(len(unique_psites))] + [f\"D{i + 1}\"\n                                                                                                         for i in\n                                                                                                         range(\n                                                                                                             len(unique_psites))]]\n    for i, param in enumerate(other_params):\n        if param in params_df.columns and not params_df[param].isna().all():\n            ax.bar(param, params_df[param].mean(), color=plt.cm.Paired(i / len(other_params)), alpha=0.6)\n\n    ax.set_title(self.gene)\n    ax.set_ylabel('Estimated Values')\n    ax.set_xlabel('Parameters')\n    plt.xticks(rotation=45)\n    ax.legend(title=\"Residue_Position\", loc='upper right', ncol=2)\n    plt.tight_layout()\n    self._save_fig(fig, f\"{self.gene}_params_bar_.png\")\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_param_series","title":"<code>plot_param_series(estimated_params, param_names, time_points)</code>","text":"<p>Plots the time series of estimated parameters over the given time points.</p> <p>This method visualizes the evolution of kinetic rates or parameters over time for a specific gene.</p> <p>:param estimated_params: List of estimated parameter values at each time point. :param param_names: List of parameter names corresponding to the estimated parameters. :param time_points: 1D numpy array of time points.</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_param_series(self, estimated_params: list, param_names: list, time_points: np.ndarray):\n    \"\"\"\n    Plots the time series of estimated parameters over the given time points.\n\n    This method visualizes the evolution of kinetic rates or parameters\n    over time for a specific gene.\n\n    :param estimated_params: List of estimated parameter values at each time point.\n    :param param_names: List of parameter names corresponding to the estimated parameters.\n    :param time_points: 1D numpy array of time points.\n    \"\"\"\n    arr = np.array(estimated_params)\n    fig, ax = plt.subplots(figsize=(8, 8))\n    for i in range(arr.shape[1]):\n        ax.plot(time_points, arr[:, i], label=param_names[i])\n    ax.set_title(self.gene)\n    ax.set_xlabel(\"Time\")\n    ax.set_ylabel(\"Kinetic Rates\")\n    ax.grid(True)\n    ax.legend(loc=\"best\")\n    plt.tight_layout()\n    self._save_fig(fig, f\"{self.gene}_params_series_.png\")\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_pca","title":"<code>plot_pca(solution, components=3)</code>","text":"<p>Plots the PCA results for the given solution.</p> <p>:param solution: 2D numpy array of shape (samples, features) representing the data. :param components: Number of PCA components to plot. Defaults to 3.</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_pca(self, solution: np.ndarray, components: int = 3):\n    \"\"\"\n    Plots the PCA results for the given solution.\n\n    :param solution: 2D numpy array of shape (samples, features) representing the data.\n    :param components: Number of PCA components to plot. Defaults to 3.\n    \"\"\"\n    pca = PCA(n_components=components)\n    pca_result = pca.fit_transform(solution)\n    ev = pca.explained_variance_ratio_ * 100\n    indices = np.arange(len(solution))\n    if components == 3:\n        x, y, z = pca_result[:, 0], pca_result[:, 1], pca_result[:, 2]\n        cs_x, cs_y, cs_z = CubicSpline(indices, x), CubicSpline(indices, y), CubicSpline(indices, z)\n        si = np.linspace(0, len(solution) - 1, 1000)\n        fig = plt.figure(figsize=(8, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        sc = ax.scatter(x, y, z, c=indices, cmap='tab20')\n        fig.colorbar(sc, label=\"Time Index\")\n        ax.plot(cs_x(si), cs_y(si), cs_z(si), color='blue', alpha=0.7, label='Temporal Path')\n        for i, (xi, yi, zi) in enumerate(zip(x, y, z)):\n            ax.text(xi, yi, zi, str(i + 1), fontsize=10, color=\"black\")\n        ax.set_xlabel(f\"PC1 ({ev[0]:.1f}%)\")\n        ax.set_ylabel(f\"PC2 ({ev[1]:.1f}%)\")\n        ax.set_zlabel(f\"PC3 ({ev[2]:.1f}%)\")\n        ax.set_title(self.gene)\n        ax.legend()\n        self._save_fig(fig, f\"{self.gene}_pca_plot_.png\")\n    else:\n        # Optionally handle non-3D cases here\n        pass\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_profiles","title":"<code>plot_profiles(data)</code>","text":"<p>Plots the profiles of estimated parameters over time.</p> <p>:param data: DataFrame containing the estimated parameters and time points.</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_profiles(self, data: pd.DataFrame):\n    \"\"\"\n    Plots the profiles of estimated parameters over time.\n\n    :param data: DataFrame containing the estimated parameters and time points.\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(8, 8))\n    for col in data.columns:\n        if col != \"Time\":\n            ax.plot(data[\"Time\"], data[col], marker='o', label=col)\n    ax.set_xlabel(\"Time (min)\")\n    ax.set_ylabel(\"Kinetic Rates\")\n    ax.set_title(self.gene)\n    ax.legend()\n    ax.grid(True)\n    plt.tight_layout()\n    self._save_fig(fig, f\"{self.gene}_params_profiles.png\")\n</code></pre>"},{"location":"reference/#plotting.plotting.Plotter.plot_tsne","title":"<code>plot_tsne(solution, perplexity=30)</code>","text":"<p>Plots a t-SNE visualization of the given solution.</p> <p>:param solution: 2D numpy array of shape (samples, features) representing the data. :param perplexity: Perplexity parameter for t-SNE. Defaults to 30.</p> Source code in <code>plotting/plotting.py</code> <pre><code>def plot_tsne(self, solution: np.ndarray, perplexity: int = 30):\n    \"\"\"\n    Plots a t-SNE visualization of the given solution.\n\n    :param solution: 2D numpy array of shape (samples, features) representing the data.\n    :param perplexity: Perplexity parameter for t-SNE. Defaults to 30.\n    \"\"\"\n    perplexity = min(perplexity, len(solution) - 1)\n    tsne_result = TSNE(n_components=2, perplexity=perplexity, random_state=42).fit_transform(solution)\n    x, y = tsne_result[:, 0], tsne_result[:, 1]\n    indices = np.arange(len(solution))\n    cs_x, cs_y = CubicSpline(indices, x), CubicSpline(indices, y)\n    si = np.linspace(0, len(solution) - 1, 1000)\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.scatter(x, y, c=indices, cmap='tab20')\n    ax.plot(cs_x(si), cs_y(si), color='blue', alpha=0.7, label='Temporal Path')\n    for i, (xi, yi) in enumerate(zip(x, y)):\n        ax.text(xi, yi, str(i + 1), fontsize=10, color=\"black\")\n    ax.set_xlabel(\"t-SNE 1\")\n    ax.set_ylabel(\"t-SNE 2\")\n    ax.set_title(self.gene)\n    ax.grid(True)\n    ax.legend()\n    self._save_fig(fig, f\"{self.gene}_tsne_plot_.png\")\n</code></pre>"},{"location":"reference/#processing.cleanup.format_site","title":"<code>format_site(site)</code>","text":"<p>Formats a phosphorylation site string.</p> <p>If the input is NaN or an empty string, returns an empty string. If the input contains an underscore ('_'), splits the string into two parts, converts the first part to uppercase, and appends the second part unchanged. Otherwise, converts the entire string to uppercase.</p> <p>Parameters:</p> Name Type Description Default <code>site</code> <code>str</code> <p>The phosphorylation site string to format.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The formatted phosphorylation site string.</p> Source code in <code>processing/cleanup.py</code> <pre><code>def format_site(site):\n    \"\"\"\n    Formats a phosphorylation site string.\n\n    If the input is NaN or an empty string, returns an empty string.\n    If the input contains an underscore ('_'), splits the string into two parts,\n    converts the first part to uppercase, and appends the second part unchanged.\n    Otherwise, converts the entire string to uppercase.\n\n    Args:\n        site (str): The phosphorylation site string to format.\n\n    Returns:\n        str: The formatted phosphorylation site string.\n    \"\"\"\n    if pd.isna(site) or site == '':\n        return ''\n    if '_' in site:\n        before, after = site.split('_', 1)\n        return before.upper() + '_' + after\n    else:\n        return site.upper()\n</code></pre>"},{"location":"reference/#processing.cleanup.move_processed_files","title":"<code>move_processed_files()</code>","text":"<p>Moves or copies processed files to their respective directories.</p> <p>This function organizes processed files into specific directories for transcription factor optimization (TFOpt) and kinase optimization (KinOpt). It creates the target directories if they do not exist and moves or copies the files based on whether they have already been moved.</p> Directories <ul> <li><code>../tfopt/data</code>: Target directory for TFOpt files.</li> <li><code>../kinopt/data</code>: Target directory for KinOpt files.</li> </ul> Files <ul> <li>KinOpt files: [\"input1.csv\", \"input2.csv\"]</li> <li>TFOpt files: [\"input1.csv\", \"input3.csv\", \"input4.csv\"]</li> </ul> Behavior <ul> <li>If a file has already been moved, it is copied to the target directory.</li> <li>If a file has not been moved, it is moved to the target directory.</li> <li>If a file does not exist, a message is printed.</li> </ul> Prints <ul> <li>Messages indicating whether files were moved, copied, or not found.</li> </ul> Source code in <code>processing/cleanup.py</code> <pre><code>def move_processed_files():\n    \"\"\"\n    Moves or copies processed files to their respective directories.\n\n    This function organizes processed files into specific directories for\n    transcription factor optimization (TFOpt) and kinase optimization (KinOpt).\n    It creates the target directories if they do not exist and moves or copies\n    the files based on whether they have already been moved.\n\n    Directories:\n        - `../tfopt/data`: Target directory for TFOpt files.\n        - `../kinopt/data`: Target directory for KinOpt files.\n\n    Files:\n        - KinOpt files: [\"input1.csv\", \"input2.csv\"]\n        - TFOpt files: [\"input1.csv\", \"input3.csv\", \"input4.csv\"]\n\n    Behavior:\n        - If a file has already been moved, it is copied to the target directory.\n        - If a file has not been moved, it is moved to the target directory.\n        - If a file does not exist, a message is printed.\n\n    Prints:\n        - Messages indicating whether files were moved, copied, or not found.\n    \"\"\"\n\n    # Create a new directory if it doesn't exist\n    tf_data_dir = \"../tfopt/data\"\n    kin_data_dir = \"../kinopt/data\"\n\n    os.makedirs(tf_data_dir, exist_ok=True)\n    os.makedirs(kin_data_dir, exist_ok=True)\n\n    # List of files to move\n    kinopt_files = [\n        \"input1.csv\",\n        \"input2.csv\"\n    ]\n    tfopt_files = [\n        \"input1.csv\",\n        # \"input1_wstd.csv\",\n        \"input3.csv\",\n        \"input4.csv\"\n    ]\n\n    # Track files already moved so we copy them next time\n    moved_files = set()\n\n    # Move or copy files to their respective directories\n    for file_list, target_dir in [(kinopt_files, kin_data_dir), (tfopt_files, tf_data_dir)]:\n        for f in file_list:\n            if os.path.exists(f):\n                target_path = os.path.join(target_dir, f)\n                if f in moved_files:\n                    shutil.copy(target_path, os.path.join(target_dir, f))\n                    print(f\"Copied {f} to {target_dir}\")\n                else:\n                    shutil.move(f, target_path)\n                    moved_files.add(f)\n                    print(f\"Moved {f} to {target_dir}\")\n            else:\n                print(f\"{f} does not exist in the current directory or has already been moved.\")\n</code></pre>"},{"location":"reference/#processing.cleanup.process_collecttri","title":"<code>process_collecttri()</code>","text":"<p>Processes the CollecTRI file to clean and filter mRNA-TF interactions. Removes complex interactions, filters by target genes, and saves the result.</p> Source code in <code>processing/cleanup.py</code> <pre><code>def process_collecttri():\n    \"\"\"\n    Processes the CollecTRI file to clean and filter mRNA-TF interactions.\n    Removes complex interactions, filters by target genes, and saves the result.\n    \"\"\"\n\n    # Load CollecTRI.csv and keep only the source and target columns\n    df = pd.read_csv(os.path.join(base_dir, \"CollecTRI.csv\"))\n\n    # Remove thr rows that starts with 'COMPLEX' in the source column\n    # Model doesn't support complex interactions, ony single mRNA\n    df = df[~df['source'].str.startswith('COMPLEX')]\n\n    df_readable = df[['source_genesymbol', 'target_genesymbol']].rename(\n        columns={'source_genesymbol': 'Source', 'target_genesymbol': 'Target'}\n    )\n    # Remove rows with NaN, empty strings or whitespace, and drop duplicates\n    df_readable = df_readable.dropna()\n    df_readable = df_readable[df_readable['Source'].str.strip() != '']\n    df_readable = df_readable[df_readable['Target'].str.strip() != '']\n    df_readable = df_readable.drop_duplicates()\n\n    # Load phospho-kinase interaction data and search CollectTRI for same TFs\n    df_genes = pd.read_csv(os.path.join(base_dir, \"input2.csv\"))\n    df_genes = df_genes[['GeneID']].rename(columns={'GeneID': 'Target'})\n    df_genes = df_genes.dropna()\n    df_genes = df_genes[df_genes['Target'].str.strip() != '']\n    df_genes = df_genes.drop_duplicates()\n\n    # Keep only interactions where Target (TFs) is present in input2.csv\n    df_readable = df_readable[df_readable['Target'].isin(df_genes['Target'])]\n\n    # Save the cleaned mRNA - TFs interactions to input4.csv\n    df_readable.to_csv(\"input4.csv\", index=False)\n\n    # Copy the input2.csv file to the current directory using shutil\n    shutil.copy(os.path.join(base_dir, \"input2.csv\"), \"input2.csv\")\n\n    print(\"Saved TF-mRNA interactions to input4.csv\")\n</code></pre>"},{"location":"reference/#processing.cleanup.process_msgauss","title":"<code>process_msgauss()</code>","text":"<p>Processes the MS Gaussian data file to generate time series data.</p> <p>This function performs the following steps: 1. Loads the <code>MS_Gaussian_updated_09032023.csv</code> file. 2. Computes the transformed values as 2^(predict_mean). 3. Pivots the data to create a time series for each (GeneID, Psite) pair. 4. Renames the time point columns to <code>x1</code> to <code>x14</code> and formats the <code>Psite</code> column. 5. Saves the cleaned time series to <code>input1.csv</code>. 6. Filters the data to keep only rows where <code>Psite</code> starts with <code>Y_</code>, <code>S_</code>, <code>T_</code>, or is empty. 7. Saves the filtered time series to <code>input1.csv</code>.</p> Outputs <ul> <li><code>input1.csv</code>: Cleaned and filtered time series data.</li> </ul> Prints <ul> <li>A message indicating that the time series data has been saved.</li> </ul> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the input file is not found in the specified directory.</p> Source code in <code>processing/cleanup.py</code> <pre><code>def process_msgauss():\n    \"\"\"\n    Processes the MS Gaussian data file to generate time series data.\n\n    This function performs the following steps:\n    1. Loads the `MS_Gaussian_updated_09032023.csv` file.\n    2. Computes the transformed values as 2^(predict_mean).\n    3. Pivots the data to create a time series for each (GeneID, Psite) pair.\n    4. Renames the time point columns to `x1` to `x14` and formats the `Psite` column.\n    5. Saves the cleaned time series to `input1.csv`.\n    6. Filters the data to keep only rows where `Psite` starts with `Y_`, `S_`, `T_`, or is empty.\n    7. Saves the filtered time series to `input1.csv`.\n\n    Outputs:\n        - `input1.csv`: Cleaned and filtered time series data.\n\n    Prints:\n        - A message indicating that the time series data has been saved.\n\n    Raises:\n        FileNotFoundError: If the input file is not found in the specified directory.\n    \"\"\"\n    # Load the MS_Gaussian_updated_09032023.csv file\n    df = pd.read_csv(os.path.join(base_dir, \"MS_Gaussian_updated_09032023.csv\"))\n\n    df['Psite'] = df['site'].fillna('').astype(str)\n\n    # Compute 2^(predict_mean)\n    df['predict_trans'] = 2 ** df['predict_mean']\n\n    # Pivot so that each (GeneID, Psite) pair has time series values per unit_time (0-13)\n    pivot_df = df.pivot_table(\n        index=['GeneID', 'Psite'],\n        columns='unit_time',\n        values='predict_trans',\n        aggfunc='first'\n    ).reset_index()\n\n    # Rename time point columns to x1 to x14 and format the Psite column\n    new_names = {i: f'x{i + 1}' for i in range(14)}\n    pivot_df.rename(columns=new_names, inplace=True)\n    pivot_df['Psite'] = pivot_df['Psite'].apply(format_site)\n\n    # Save the cleaned time series to input1.csv\n    pivot_df.to_csv(\"input1.csv\", index=False)\n\n    # Filter to keep only rows where 'Psite' starts with Y_, S_, T_, or is empty\n    kinopt_df = pivot_df[\n        pivot_df['Psite'].str.startswith(('Y_', 'S_', 'T_')) | (pivot_df['Psite'] == '')]\n\n    # Save the filtered time series to input1.csv\n    kinopt_df.to_csv(\"input1.csv\", index=False)\n\n    print(\"Saved MS Gaussian (predict_mean) time series to input1.csv\")\n</code></pre>"},{"location":"reference/#processing.cleanup.process_msgauss_std","title":"<code>process_msgauss_std()</code>","text":"<p>Processes the MS Gaussian data file to compute transformed means and standard deviations.</p> <p>This function performs the following steps: 1. Loads the <code>MS_Gaussian_updated_09032023.csv</code> file. 2. Computes transformed values as 2^(predict_mean) and propagates errors using the formula:    sigma_y = 2^(x) * ln(2) * sigma_x. 3. Pivots the data to create time series for each (GeneID, Psite) pair for both means and standard deviations. 4. Merges the pivoted data for means and standard deviations. 5. Filters the data to keep only rows where <code>Psite</code> starts with <code>Y_</code>, <code>S_</code>, <code>T_</code>, or is empty. 6. Saves the resulting data to <code>input1_wstd.csv</code>.</p> Outputs <ul> <li><code>input1_wstd.csv</code>: Cleaned time series data with transformed means and standard deviations.</li> </ul> Prints <ul> <li>A message indicating that the time series data with standard deviations has been saved.</li> </ul> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the input file is not found in the specified directory.</p> Source code in <code>processing/cleanup.py</code> <pre><code>def process_msgauss_std():\n    \"\"\"\n    Processes the MS Gaussian data file to compute transformed means and standard deviations.\n\n    This function performs the following steps:\n    1. Loads the `MS_Gaussian_updated_09032023.csv` file.\n    2. Computes transformed values as 2^(predict_mean) and propagates errors using the formula:\n       sigma_y = 2^(x) * ln(2) * sigma_x.\n    3. Pivots the data to create time series for each (GeneID, Psite) pair for both means and standard deviations.\n    4. Merges the pivoted data for means and standard deviations.\n    5. Filters the data to keep only rows where `Psite` starts with `Y_`, `S_`, `T_`, or is empty.\n    6. Saves the resulting data to `input1_wstd.csv`.\n\n    Outputs:\n        - `input1_wstd.csv`: Cleaned time series data with transformed means and standard deviations.\n\n    Prints:\n        - A message indicating that the time series data with standard deviations has been saved.\n\n    Raises:\n        FileNotFoundError: If the input file is not found in the specified directory.\n    \"\"\"\n    df = pd.read_csv(os.path.join(base_dir, \"MS_Gaussian_updated_09032023.csv\"))\n    df['Psite'] = df['site'].fillna('').astype(str)\n    df['predict_trans'] = 2 ** df['predict_mean']\n\n    # Error propagation: sigma_y = 2^(x) * ln(2) * sigma_x\n    df['predict_trans_std'] = df['predict_trans'] * np.log(2) * df['predict_std']\n\n    # Pivot for the transformed means\n    pivot_trans = df.pivot_table(\n        index=['GeneID', 'Psite'],\n        columns='unit_time',\n        values='predict_trans',\n        aggfunc='first'\n    ).reset_index()\n\n    pivot_trans = pivot_trans.rename(columns={i: f'x{i + 1}' for i in range(14)})\n\n    # Pivot for the transformed standard deviations\n    pivot_std = df.pivot_table(\n        index=['GeneID', 'Psite'],\n        columns='unit_time',\n        values='predict_trans_std',\n        aggfunc='first'\n    ).reset_index()\n    pivot_std = pivot_std.rename(columns={i: f'x{i + 1}_std' for i in range(14)})\n\n    # Merge the two pivot tables and format Psite\n    result = pd.merge(pivot_trans, pivot_std, on=['GeneID', 'Psite'])\n    result['Psite'] = result['Psite'].apply(format_site)\n\n    # Filter to keep only rows where 'Psite' starts with Y_, S_, T_, or is empty\n    result = result[result['Psite'].str.startswith(('Y_', 'S_', 'T_')) | (result['Psite'] == '')]\n\n    # Save to input1_wstd.csv\n    result.to_csv(\"input1_wstd.csv\", index=False)\n\n    print(\"Saved MS Gaussian time-series with standard deviations to input1_wstd.csv\")\n</code></pre>"},{"location":"reference/#processing.cleanup.process_routlimma","title":"<code>process_routlimma()</code>","text":"<p>Processes the Rout Limma table to generate time series data for mRNA.</p> <p>This function performs the following steps: 1. Loads the <code>Rout_LimmaTable.csv</code> file. 2. Selects specific columns related to time points and conditions. 3. Renames the selected columns to a standardized format (<code>x1</code> to <code>x9</code>). 4. Converts the values in the renamed columns using the formula <code>2^(value)</code>. 5. Saves the resulting time series data to <code>input3.csv</code>.</p> Outputs <ul> <li><code>input3.csv</code>: Cleaned and transformed time series data for mRNA.</li> </ul> Prints <ul> <li>A message indicating that the time series data has been saved.</li> </ul> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the input file <code>Rout_LimmaTable.csv</code> is not found in the specified directory.</p> Source code in <code>processing/cleanup.py</code> <pre><code>def process_routlimma():\n    \"\"\"\n    Processes the Rout Limma table to generate time series data for mRNA.\n\n    This function performs the following steps:\n    1. Loads the `Rout_LimmaTable.csv` file.\n    2. Selects specific columns related to time points and conditions.\n    3. Renames the selected columns to a standardized format (`x1` to `x9`).\n    4. Converts the values in the renamed columns using the formula `2^(value)`.\n    5. Saves the resulting time series data to `input3.csv`.\n\n    Outputs:\n        - `input3.csv`: Cleaned and transformed time series data for mRNA.\n\n    Prints:\n        - A message indicating that the time series data has been saved.\n\n    Raises:\n        FileNotFoundError: If the input file `Rout_LimmaTable.csv` is not found in the specified directory.\n    \"\"\"\n    # Load Rout_LimmaTable.csv and select desired columns\n    df = pd.read_csv(os.path.join(base_dir, \"Rout_LimmaTable.csv\"))\n    selected_cols = [\n        'GeneID',\n        'Min4vsCtrl', 'Min8vsCtrl', 'Min15vsCtrl', 'Min30vsCtrl',\n        'Hr1vsCtrl', 'Hr2vsCtrl', 'Hr4vsCtrl', 'Hr8vsCtrl', 'Hr16vsCtrl'\n    ]\n    df_new = df[selected_cols]\n\n    # Rename the condition columns to x1 to x9\n    rename_mapping = {\n        'Min4vsCtrl': 'x1',\n        'Min8vsCtrl': 'x2',\n        'Min15vsCtrl': 'x3',\n        'Min30vsCtrl': 'x4',\n        'Hr1vsCtrl': 'x5',\n        'Hr2vsCtrl': 'x6',\n        'Hr4vsCtrl': 'x7',\n        'Hr8vsCtrl': 'x8',\n        'Hr16vsCtrl': 'x9'\n    }\n    df_new = df_new.rename(columns=rename_mapping)\n\n    # Convert each value in x1 to x9 as 2^(value)\n    for col in rename_mapping.values():\n        df_new[col] = 2 ** df_new[col]\n\n    # Save the resulting time series to input3.csv\n    df_new.to_csv(\"input3.csv\", index=False)\n\n    print(\"Saved Rout Limma time series - mRNA to input3.csv\")\n</code></pre>"},{"location":"reference/#processing.cleanup.update_gene_symbols","title":"<code>update_gene_symbols(filename)</code>","text":"<p>Updates the GeneID column in a CSV file by mapping GeneIDs to gene/protein symbols.</p> <p>This function reads a CSV file, queries the MyGeneInfo database to map GeneIDs to their corresponding gene/protein symbols, and writes the updated DataFrame back to the same file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The path to the CSV file to be updated. The file must contain a 'GeneID' column.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified file does not exist.</p> <code>ValueError</code> <p>If the 'GeneID' column is missing in the file.</p> Outputs <ul> <li>The input file is updated in place with the 'GeneID' column replaced by gene/protein symbols.</li> </ul> Prints <ul> <li>A progress bar indicating the mapping process.</li> <li>A message confirming the update of gene symbols in the file.</li> </ul> Source code in <code>processing/cleanup.py</code> <pre><code>def update_gene_symbols(filename):\n    \"\"\"\n    Updates the GeneID column in a CSV file by mapping GeneIDs to gene/protein symbols.\n\n    This function reads a CSV file, queries the MyGeneInfo database to map GeneIDs to their\n    corresponding gene/protein symbols, and writes the updated DataFrame back to the same file.\n\n    Args:\n        filename (str): The path to the CSV file to be updated. The file must contain a 'GeneID' column.\n\n    Raises:\n        FileNotFoundError: If the specified file does not exist.\n        ValueError: If the 'GeneID' column is missing in the file.\n\n    Outputs:\n        - The input file is updated in place with the 'GeneID' column replaced by gene/protein symbols.\n\n    Prints:\n        - A progress bar indicating the mapping process.\n        - A message confirming the update of gene symbols in the file.\n    \"\"\"\n    df = pd.read_csv(filename)\n    df['GeneID'] = df['GeneID'].astype(str)\n    unique_gene_ids = list(df[\"GeneID\"].unique())\n\n    # Initialize MyGeneInfo client and query in bulk.\n    mg = mygene.MyGeneInfo()\n    query_results = mg.querymany(unique_gene_ids,\n                                 scopes='ensembl.gene,entrezgene,symbol',\n                                 species='human',\n                                 as_dataframe=True)\n\n    # Filter out not found results if available.\n    if 'notfound' in query_results.columns:\n        query_results = query_results[query_results['notfound'] != True]\n\n    # Build the mapping dictionary from queried GeneIDs to gene symbols.\n    mapping = query_results['symbol'].to_dict()\n\n    def map_geneid(geneid):\n        \"\"\"\n        Maps a single GeneID to its corresponding gene/protein symbol.\n\n        Args:\n            geneid (str): The GeneID to be mapped.\n\n        Returns:\n            str: The corresponding gene/protein symbol if found, otherwise the original GeneID.\n        \"\"\"\n        return mapping.get(str(geneid), geneid)\n\n    # Use ThreadPoolExecutor with tqdm to parallelize mapping.\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        results = list(tqdm(executor.map(map_geneid, df[\"GeneID\"]), total=len(df[\"GeneID\"]),\n                            desc=f\"Processing {filename}\"))\n\n    df[\"GeneID\"] = results\n    df.to_csv(filename, index=False)\n    print(f\"Updated gene symbols in {filename}\")\n</code></pre>"},{"location":"reference/#processing.map.create_cytoscape_table","title":"<code>create_cytoscape_table(mapping_csv_path)</code>","text":"<p>Creates a Cytoscape-compatible edge table from a mapping file.</p> <p>Parameters:</p> Name Type Description Default <code>mapping_csv_path</code> <code>str</code> <p>Path to the input CSV file with columns: TF, mRNA, Psite, Kinase</p> required <p>Returns:</p> Type Description <p>pd.DataFrame: Edge table with columns [Source, Target, Interaction]</p> Source code in <code>processing/map.py</code> <pre><code>def create_cytoscape_table(mapping_csv_path):\n    \"\"\"\n    Creates a Cytoscape-compatible edge table from a mapping file.\n\n    Parameters:\n        mapping_csv_path (str): Path to the input CSV file with columns: TF, mRNA, Psite, Kinase\n\n    Returns:\n        pd.DataFrame: Edge table with columns [Source, Target, Interaction]\n    \"\"\"\n    df = pd.read_csv(mapping_csv_path)\n\n    kinase_tf_edges = []\n    tf_mrna_edges = []\n\n    for _, row in df.iterrows():\n        tf = row[\"TF\"]\n\n        # Add Kinase -&gt; TF edges\n        if pd.notna(row[\"Kinase\"]):\n            for kinase in str(row[\"Kinase\"]).split(\",\"):\n                kinase_tf_edges.append((kinase.strip(), tf.strip(), \"phosphorylates\"))\n\n        # Add TF -&gt; mRNA edges\n        if pd.notna(row[\"mRNA\"]):\n            for gene in str(row[\"mRNA\"]).split(\",\"):\n                tf_mrna_edges.append((tf.strip(), gene.strip(), \"regulates\"))\n\n    edge_df = pd.DataFrame(kinase_tf_edges + tf_mrna_edges,\n                           columns=[\"Source\", \"Target\", \"Interaction\"])\n    return edge_df\n</code></pre>"},{"location":"reference/#processing.map.generate_nodes","title":"<code>generate_nodes(edge_df)</code>","text":"<p>Infers node types for Cytoscape visualization: - All nodes default to 'Kinase' - Nodes that are only targets of 'regulates' are labeled 'mRNA'</p> <p>Parameters:</p> Name Type Description Default <code>edge_df</code> <code>DataFrame</code> <p>Must have columns ['Source', 'Target', 'Interaction']</p> required <p>Returns:</p> Type Description <p>pd.DataFrame: DataFrame with columns ['Node', 'Type']</p> Source code in <code>processing/map.py</code> <pre><code>def generate_nodes(edge_df):\n    \"\"\"\n    Infers node types for Cytoscape visualization:\n    - All nodes default to 'Kinase'\n    - Nodes that are only targets of 'regulates' are labeled 'mRNA'\n\n    Parameters:\n        edge_df (pd.DataFrame): Must have columns ['Source', 'Target', 'Interaction']\n\n    Returns:\n        pd.DataFrame: DataFrame with columns ['Node', 'Type']\n    \"\"\"\n    node_roles = {}\n\n    for _, row in edge_df.iterrows():\n        src, tgt, interaction = row[\"Source\"], row[\"Target\"], row[\"Interaction\"]\n\n        if interaction == \"regulates\":\n            node_roles[tgt] = \"mRNA\"  # explicitly mRNA\n            node_roles[src] = node_roles.get(src, \"Kinase\")  # TFs are still Kinases here\n        else:\n            node_roles[src] = \"Kinase\"\n            if tgt not in node_roles:\n                node_roles[tgt] = \"Kinase\"\n\n    return pd.DataFrame([\n        {\"Node\": node, \"Type\": node_type}\n        for node, node_type in node_roles.items()\n    ])\n</code></pre>"},{"location":"reference/#processing.map.map_optimization_results","title":"<code>map_optimization_results(file_path)</code>","text":"<p>Reads the TF-mRNA optimization results from an Excel file and maps mRNA to each TF.</p> <p>This function processes the 'Alpha Values' sheet of the provided Excel file to extract non-zero optimization results, groups mRNA by TF, and merges the results with additional data from a CSV file containing TF, Psite, and Kinase information. The final DataFrame is cleaned and formatted for further analysis.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the Excel file containing TF-mRNA optimization results.</p> required <p>Returns:</p> Type Description <p>pd.DataFrame: A DataFrame containing the mapped TF, mRNA, Psite, and Kinase information.</p> Source code in <code>processing/map.py</code> <pre><code>def map_optimization_results(file_path):\n    \"\"\"\n    Reads the TF-mRNA optimization results from an Excel file and maps mRNA to each TF.\n\n    This function processes the 'Alpha Values' sheet of the provided Excel file to extract\n    non-zero optimization results, groups mRNA by TF, and merges the results with additional\n    data from a CSV file containing TF, Psite, and Kinase information. The final DataFrame\n    is cleaned and formatted for further analysis.\n\n    Args:\n        file_path (str): The path to the Excel file containing TF-mRNA optimization results.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the mapped TF, mRNA, Psite, and Kinase information.\n    \"\"\"\n    # Read the Excel file\n    tfopt_file = pd.ExcelFile(file_path)\n\n    # Read the 'Alpha Values' sheet\n    df = pd.read_excel(tfopt_file, sheet_name='Alpha Values')\n\n    # Filter the DataFrame for non-zero values\n    non_zero_df = df[df['Value'] != 0]\n\n    # Filter for positive values\n    # non_zero_df = df[df['Value'] &gt; 0]\n\n    # Take all values without filtering\n    # non_zero_df = df\n\n    # Filter very small values out\n    # non_zero_df = non_zero_df[non_zero_df['Value'] &gt; 0.0001]\n\n    # Extract the mRNA for each TF where Values was not zero\n    result = non_zero_df[['TF', 'mRNA']]\n\n    # Display value along with TF and mRNA\n    # result['Value'] = str(non_zero_df['Value'])\n\n    result = result.groupby('TF').agg(lambda x: ', '.join(x)).reset_index()\n\n    # List number of mRNA for each TF\n    # result['mRNA_Count'] = result['mRNA'].apply(lambda x: len(x.split(',')))\n\n    # Read another csv file which has TF aka GeneID and Psites and Kinases to merge with the result\n    kinopt_file = pd.read_csv('raw/input2.csv')\n    df2 = kinopt_file.rename(columns={'GeneID': 'TF'})\n    merged_df = pd.merge(result, df2, on='TF', how='left')\n\n    # Remove {} from the Kinases column with format {kinase1, kinase2, kinase3}\n    merged_df['Kinase'] = merged_df['Kinase'].astype(str)\n    merged_df['Kinase'] = merged_df['Kinase'].str.replace(r'{', '', regex=True)\n    merged_df['Kinase'] = merged_df['Kinase'].str.replace(r'}', '', regex=True)\n\n    # Remove any extra spaces\n    merged_df['Kinase'] = merged_df['Kinase'].str.replace(r'\\s+', '', regex=True)\n\n    # Delete the rows where Psite doesn't match Psite in input2\n    merged_df = merged_df[merged_df['Psite'].isin(df2['Psite'])]\n\n    # Empty cells in mRNA column if they are repeateed in the next row\n    merged_df['mRNA'] = merged_df['mRNA'].where(merged_df['mRNA'] != merged_df['mRNA'].shift(), '')\n\n    merged_df = merged_df.drop_duplicates()\n    merged_df = merged_df.reset_index(drop=True)\n\n    return merged_df\n</code></pre>"},{"location":"reference/#sensitivity.analysis.define_sensitivity_problem_ds","title":"<code>define_sensitivity_problem_ds(ub, num_psites)</code>","text":"<p>Defines the Morris sensitivity analysis problem for a dynamic number of parameters.</p> <p>Parameters:</p> Name Type Description Default <code>num_psites</code> <code>int</code> <p>Number of phosphorylation sites.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Problem definition for sensitivity analysis.</p> Source code in <code>sensitivity/analysis.py</code> <pre><code>def define_sensitivity_problem_ds(ub, num_psites):\n    \"\"\"\n    Defines the Morris sensitivity analysis problem for a dynamic number of parameters.\n\n    Args:\n        num_psites (int): Number of phosphorylation sites.\n\n    Returns:\n        dict: Problem definition for sensitivity analysis.\n    \"\"\"\n    num_vars = 4 + 2 * num_psites  # A, B, C, D, and S1, S2, ..., Sn, D1, D2, ..., Dn\n    param_names = ['A', 'B', 'C', 'D'] + \\\n                  [f'S{i + 1}' for i in range(num_psites)] + \\\n                  [f'D{i + 1}' for i in range(num_psites)]\n    bounds = [\n                 [0, ub],  # A\n                 [0, ub],  # B\n                 [0, ub],  # C\n                 [0, ub],  # D\n             ] + [[0, ub]] * num_psites + [[0, ub]] * num_psites  # S and D parameters\n    problem = {\n        'num_vars': num_vars,\n        'names': param_names,\n        'bounds': bounds\n    }\n    return problem\n</code></pre>"},{"location":"reference/#sensitivity.analysis.define_sensitivity_problem_rand","title":"<code>define_sensitivity_problem_rand(num_psites)</code>","text":"<p>Defines the Morris sensitivity analysis problem for a dynamic number of parameters.</p> <p>Parameters:</p> Name Type Description Default <code>num_psites</code> <code>int</code> <p>Number of phosphorylation sites.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Problem definition for sensitivity analysis.</p> Source code in <code>sensitivity/analysis.py</code> <pre><code>def define_sensitivity_problem_rand(num_psites):\n    \"\"\"\n    Defines the Morris sensitivity analysis problem for a dynamic number of parameters.\n\n    Args:\n        num_psites (int): Number of phosphorylation sites.\n\n    Returns:\n        dict: Problem definition for sensitivity analysis.\n    \"\"\"\n    num_vars = get_number_of_params_rand(num_psites)\n    param_names = get_param_names_rand(num_psites)\n    bounds = get_bounds_rand(num_psites)\n    problem = {\n        'num_vars': num_vars,\n        'names': param_names,\n        'bounds': bounds\n    }\n    return problem\n</code></pre>"},{"location":"reference/#sensitivity.analysis.sensitivity_analysis","title":"<code>sensitivity_analysis(time_points, num_psites, init_cond, gene)</code>","text":"<p>Performs sensitivity analysis using the Morris method for a given ODE model.</p> <p>This function defines the sensitivity problem based on the ODE model type, generates parameter samples, evaluates the model for each sample, and computes sensitivity indices. It also generates various plots to visualize the results.</p> <p>Parameters:</p> Name Type Description Default <code>time_points</code> <code>list or ndarray</code> <p>Time points for the ODE simulation.</p> required <code>num_psites</code> <code>int</code> <p>Number of phosphorylation sites in the model.</p> required <code>init_cond</code> <code>list or ndarray</code> <p>Initial conditions for the ODE model.</p> required <code>gene</code> <code>str</code> <p>Name of the gene or protein being analyzed.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>The function saves sensitivity analysis results and plots to the output directory.</p> Source code in <code>sensitivity/analysis.py</code> <pre><code>def sensitivity_analysis(time_points, num_psites, init_cond, gene):\n    \"\"\"\n    Performs sensitivity analysis using the Morris method for a given ODE model.\n\n    This function defines the sensitivity problem based on the ODE model type,\n    generates parameter samples, evaluates the model for each sample, and computes\n    sensitivity indices. It also generates various plots to visualize the results.\n\n    Args:\n        time_points (list or np.ndarray): Time points for the ODE simulation.\n        num_psites (int): Number of phosphorylation sites in the model.\n        init_cond (list or np.ndarray): Initial conditions for the ODE model.\n        gene (str): Name of the gene or protein being analyzed.\n\n    Returns:\n        None: The function saves sensitivity analysis results and plots to the output directory.\n    \"\"\"\n\n    if ODE_MODEL == 'randmod':\n        problem = define_sensitivity_problem_rand(num_psites=num_psites)\n    else:\n        problem = define_sensitivity_problem_ds(num_psites=num_psites)\n    N = 10000\n    num_levels = 400\n    param_values = morris.sample(problem, N=N, num_levels=num_levels, local_optimization=True)\n    Y = np.zeros(len(param_values))\n    for i, X in enumerate(param_values):\n        A, B, C, D, *rest = X\n        S_list = rest[:num_psites]\n        D_list = rest[num_psites:]\n        params = (A, B, C, D, *S_list, *D_list)\n        try:\n            sol, _ = solve_ode(params, init_cond, num_psites, time_points)\n            # Sum last time point P1, P2, ..., Pn\n            Y[i] = np.sum(sol[-1, list(range(2, 2 + num_psites))])  \\\n                if ODE_MODEL == 'randmod'  \\\n                else np.sum(sol[-1, 2:2 + num_psites])\n        except Exception:\n            Y[i] = np.nan\n    Y = np.nan_to_num(Y, nan=0.0, posinf=0.0, neginf=0.0)\n    print(f\"\\n\\nSensitivity Analysis for Protein: {gene}\\n\")\n    Si = analyze(problem, param_values, Y, num_levels=num_levels, conf_level=0.95, scaled=True, print_to_console=True)\n\n    # Absolute Mean of Elementary Effects : represents the overall importance\n    # of each parameter, reflecting its sensitivity\n    ## Bar Plot of mu* ##\n    # Standard Deviation of Elementary Effects: High standard deviation suggests\n    # that the parameter has nonlinear effects or is involved in interactions\n    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n    ax.bar(problem['names'], Si['mu_star'], yerr=Si['mu_star_conf'], color='skyblue')\n    ax.set_title(f'{gene}')\n    ax.set_ylabel('mu* (Importance)')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/bar_plot_mu_{gene}.png\", format='png', dpi=300)\n    plt.close()\n    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n    ax.bar(problem['names'], Si['sigma'], color='orange')\n    ax.set_title(f'{gene}')\n    ax.set_ylabel('\u03c3 (Standard Deviation)')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/bar_plot_sigma_{gene}.png\", format='png', dpi=300)\n    plt.close()\n\n    ## Bar Plot of sigma ##\n    # Distinguish between parameters with purely linear effects (low sigma) and\n    # those with nonlinear or interaction effects (high sigma).\n    # **--- Parameters with high mu* and high sigma ---**\n    #           &lt;particularly important to watch&gt;\n    ## Scatter Plot of mu* vs sigma ##\n    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n    ax.scatter(Si['mu_star'], Si['sigma'], color='green', s=100)\n    for i, param in enumerate(problem['names']):\n        ax.text(Si['mu_star'][i], Si['sigma'][i], param, fontsize=12, ha='right', va='bottom')\n    ax.set_title(f'{gene}')\n    ax.set_xlabel('mu* (Mean Absolute Effect)')\n    ax.set_ylabel('\u03c3 (Standard Deviation)')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/scatter_plot_musigma_{gene}.png\", format='png', dpi=300)\n    plt.close()\n\n    # A radial plot (also known as a spider or radar plot) can give a visual\n    # overview of multiple sensitivity metrics (e.g., mu*, sigma, etc.) for\n    # each parameter in a circular format.\n\n    # Each parameter gets a spoke, and the distance from the center represents\n    # the sensitivity for a given metric.\n    ## Radial Plot (Spider Plot) of Sensitivity Metrics ##\n    categories = problem['names']\n    N_cat = len(categories)\n    mu_star = Si['mu_star']\n    sigma = Si['sigma']\n    angles = np.linspace(0, 2 * np.pi, N_cat, endpoint=False).tolist()\n    mu_star = np.concatenate((mu_star, [mu_star[0]]))\n    sigma = np.concatenate((sigma, [sigma[0]]))\n    angles += angles[:1]\n    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n    ax.fill(angles, mu_star, color='skyblue', alpha=0.4, label='Mu*')\n    ax.fill(angles, sigma, color='orange', alpha=0.4, label='Sigma')\n    ax.set_yticklabels([])\n    ax.set_xticks(angles[:-1])\n    ax.set_xticklabels(categories)\n    ax.set_title(f'{gene}')\n    plt.legend(loc='upper right')\n    plt.savefig(f\"{OUT_DIR}/radial_plot_{gene}.png\", format='png', dpi=300)\n    plt.close()\n\n    # CDF can show how often the effects of certain parameters are strong or\n    # weak across the model outputs.\n    # Visualizing how many times a parameter has a strong effect across\n    # different sample runs.\n    ## Cumulative Distribution Function (CDF) of Sensitivity Indices ##\n    plt.figure(figsize=(8, 8))\n    for i, param in enumerate(problem['names']):\n        plt.plot(np.sort(Si['mu_star']), np.linspace(0, 1, len(Si['mu_star'])), label=param)\n    plt.title(f'{gene}')\n    plt.xlabel('Sensitivity Index')\n    plt.ylabel('Cumulative Probability')\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(f\"{OUT_DIR}/cdf_plot_{gene}.png\", format='png', dpi=300)\n    plt.close()\n\n    # Visualize the proportion of total sensitivity contributed by each\n    # parameter using a pie chart, showing the relative importance of each\n    # parameter's contribution to sensitivity.\n    ## Pie Chart for Sensitivity Contribution ##\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.pie(Si['mu_star'], labels=problem['names'], autopct='%1.1f%%', startangle=90, colors=plt.cm.Paired.colors,\n           textprops={'fontsize': 8})\n    ax.set_title(f'{gene}')\n    plt.tight_layout()\n    plt.savefig(f\"{OUT_DIR}/pie_chart_{gene}.png\", format='png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#steady.initdist.initial_condition","title":"<code>initial_condition(num_psites)</code>","text":"<p>Calculates the initial steady-state conditions for a given number of phosphorylation sites for distributive phosphorylation model.</p> <p>This function defines a system of equations representing the steady-state conditions of an ODE model and solves it using numerical optimization. The steady-state conditions are used as initial conditions for further simulations.</p> <p>Parameters:</p> Name Type Description Default <code>num_psites</code> <code>int</code> <p>Number of phosphorylation sites in the model.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of steady-state values for the variables [R, P, P_sites].</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the optimization fails to find a solution for the steady-state conditions.</p> Source code in <code>steady/initdist.py</code> <pre><code>def initial_condition(num_psites: int) -&gt; list:\n    \"\"\"\n    Calculates the initial steady-state conditions for a given number of phosphorylation sites\n    for distributive phosphorylation model.\n\n    This function defines a system of equations representing the steady-state conditions\n    of an ODE model and solves it using numerical optimization. The steady-state conditions\n    are used as initial conditions for further simulations.\n\n    Args:\n        num_psites (int): Number of phosphorylation sites in the model.\n\n    Returns:\n        list: A list of steady-state values for the variables [R, P, P_sites].\n\n    Raises:\n        ValueError: If the optimization fails to find a solution for the steady-state conditions.\n    \"\"\"\n    A, B, C, D = 1, 1, 1, 1\n    S_rates = np.ones(num_psites)\n    D_rates = np.ones(num_psites)\n\n    def steady_state_equations(y):\n        \"\"\"\n        Defines the system of equations for the steady-state conditions.\n\n        Args:\n            y (list or np.ndarray): Current values of the variables [R, P, P_sites].\n\n        Returns:\n            list: Residuals of the steady-state equations.\n        \"\"\"\n        R, P, *P_sites = y\n        dR_dt = A - B * R\n        dP_dt = C * R - (D + np.sum(S_rates)) * P + np.sum(P_sites)\n        dP_sites_dt = [S_rates[i] * P - (1 + D_rates[i]) * P_sites[i] for i in range(num_psites)]\n        return [dR_dt, dP_dt] + dP_sites_dt\n\n    y0_guess = np.ones(num_psites + 2)\n    bounds_local = [(1e-6, None)] * (num_psites + 2)\n    result = minimize(lambda y: 0, y0_guess, method='SLSQP', bounds=bounds_local,\n                      constraints={'type': 'eq', 'fun': steady_state_equations})\n    logger.info(\"Steady-State conditions calculated\")\n    if result.success:\n        return result.x.tolist()\n    else:\n        raise ValueError(\"Failed to find steady-state conditions\")\n</code></pre>"},{"location":"reference/#steady.initrand.initial_condition","title":"<code>initial_condition(num_psites)</code>","text":"<p>Calculates the initial steady-state conditions for a given number of phosphorylation sites for random phosphorylation model.</p> <p>This function defines a system of equations representing the steady-state conditions of an ODE model and solves it using numerical optimization. The steady-state conditions are used as initial conditions for further simulations.</p> <p>Parameters:</p> Name Type Description Default <code>num_psites</code> <code>int</code> <p>Number of phosphorylation sites in the model.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of steady-state values for the variables [R, P, P_sites].</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the optimization fails to find a solution for the steady-state conditions.</p> Source code in <code>steady/initrand.py</code> <pre><code>def initial_condition(num_psites: int) -&gt; list:\n    \"\"\"\n    Calculates the initial steady-state conditions for a given number of phosphorylation sites\n    for random phosphorylation model.\n\n    This function defines a system of equations representing the steady-state conditions\n    of an ODE model and solves it using numerical optimization. The steady-state conditions\n    are used as initial conditions for further simulations.\n\n    Args:\n        num_psites (int): Number of phosphorylation sites in the model.\n\n    Returns:\n        list: A list of steady-state values for the variables [R, P, P_sites].\n\n    Raises:\n        ValueError: If the optimization fails to find a solution for the steady-state conditions.\n    \"\"\"\n    subsets = []\n    for k in range(1, num_psites + 1):\n        for comb in combinations(range(1, num_psites + 1), k):\n            subsets.append(comb)\n    subset_to_index = {subset: i + 2 for i, subset in enumerate(subsets)}\n\n    def steady_state_equations(y):\n        \"\"\"\n        Defines the system of equations for the steady-state conditions.\n\n        Args:\n            y (list or np.ndarray): Current values of the variables [R, P, P_sites].\n\n        Returns:\n            list: Residuals of the steady-state equations.\n        \"\"\"\n        R, P, *phos = y\n        A, B, C, D = 1, 1, 1, 1\n        S_rates = np.ones(num_psites)\n        D_params = np.ones(len(subsets))\n        eq_R = A - B * R\n        gain_from_dephos = sum(phos[i] for i, subset in enumerate(subsets) if len(subset) == 1)\n        eq_P = C * R - D * P - np.sum(S_rates) * P + gain_from_dephos\n        eqs_phos = []\n        for i, subset in enumerate(subsets):\n            P_state = phos[i]\n            gain_phos = 0\n            for site in subset:\n                if len(subset) == 1:\n                    gain_phos += S_rates[site - 1] * P\n                else:\n                    reduced = tuple(sorted(set(subset) - {site}))\n                    if reduced in subset_to_index:\n                        gain_phos += S_rates[site - 1] * phos[subset_to_index[reduced] - 2]\n            loss_phos = sum(S_rates[site - 1] for site in range(1, num_psites + 1) if site not in subset) * P_state\n            basal_loss = len(subset) * P_state\n            additional_loss = D_params[i] * P_state\n            gain_from_further = 0\n            for site in range(1, num_psites + 1):\n                if site not in subset:\n                    new_state = tuple(sorted(subset + (site,)))\n                    if new_state in subset_to_index:\n                        gain_from_further += phos[subset_to_index[new_state] - 2]\n            eqs_phos.append(gain_phos - loss_phos - basal_loss - additional_loss + gain_from_further)\n        return [eq_R, eq_P] + eqs_phos\n\n    y0_guess = np.ones(len(subsets) + 2)\n    bounds_local = [(1e-6, None)] * (len(subsets) + 2)\n    result = minimize(lambda y: 0, y0_guess, method='SLSQP', bounds=bounds_local,\n                      constraints={'type': 'eq', 'fun': steady_state_equations})\n    logger.info(\"Steady-State conditions calculated\")\n    if result.success:\n        return result.x.tolist()\n    else:\n        raise ValueError(\"Failed to find steady-state conditions\")\n</code></pre>"},{"location":"reference/#steady.initsucc.initial_condition","title":"<code>initial_condition(num_psites)</code>","text":"<p>Calculates the initial steady-state conditions for a given number of phosphorylation sites for successive phosphorylation model.</p> <p>This function defines a system of equations representing the steady-state conditions of an ODE model and solves it using numerical optimization. The steady-state conditions are used as initial conditions for further simulations.</p> <p>Parameters:</p> Name Type Description Default <code>num_psites</code> <code>int</code> <p>Number of phosphorylation sites in the model.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of steady-state values for the variables [R, P, P_sites].</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the optimization fails to find a solution for the steady-state conditions.</p> Source code in <code>steady/initsucc.py</code> <pre><code>def initial_condition(num_psites: int) -&gt; list:\n    \"\"\"\n    Calculates the initial steady-state conditions for a given number of phosphorylation sites\n    for successive phosphorylation model.\n\n    This function defines a system of equations representing the steady-state conditions\n    of an ODE model and solves it using numerical optimization. The steady-state conditions\n    are used as initial conditions for further simulations.\n\n    Args:\n        num_psites (int): Number of phosphorylation sites in the model.\n\n    Returns:\n        list: A list of steady-state values for the variables [R, P, P_sites].\n\n    Raises:\n        ValueError: If the optimization fails to find a solution for the steady-state conditions.\n    \"\"\"\n    A, B, C, D = 1, 1, 1, 1\n    S_rates = np.ones(num_psites)\n    D_rates = np.ones(num_psites)\n\n    def steady_state_equations(y):\n        \"\"\"\n        Defines the system of equations for the steady-state conditions.\n\n        Args:\n            y (list or np.ndarray): Current values of the variables [R, P, P_sites].\n\n        Returns:\n            list: Residuals of the steady-state equations.\n        \"\"\"\n        R, P, *P_sites = y\n        dR_dt = A - B * R\n        dP_dt = C * R - (D + np.sum(S_rates)) * P + np.sum(P_sites)\n        dP_sites_dt = [S_rates[i] * P - (1 + D_rates[i]) * P_sites[i] for i in range(num_psites)]\n        return [dR_dt, dP_dt] + dP_sites_dt\n\n    y0_guess = np.ones(num_psites + 2)\n    bounds_local = [(1e-6, None)] * (num_psites + 2)\n    result = minimize(\n        lambda y: 0,\n        y0_guess,\n        method='SLSQP',\n        bounds=bounds_local,\n        constraints={'type': 'eq', 'fun': steady_state_equations}\n    )\n\n    logger.info(\"Steady-State conditions calculated\")\n    if result.success:\n        return result.x.tolist()\n    else:\n        raise ValueError(\"Failed to find steady-state conditions\")\n</code></pre>"},{"location":"reference/#steady.inittest.initial_condition","title":"<code>initial_condition(num_psites)</code>","text":"<p>Compute steady-state conditions for the given model.</p> Common parameters <p>A, B, C, D = 1, 1, 1, 1 S_rates = ones(num_psites) D_rates = ones(num_psites)</p> The parameter vector for the ODE models is <p>[A, B, C, D, S1, ..., S_n, D1, ..., D_n]</p> <p>Extra (hardcoded) parameters per model:   - semi_processive: p_proc = 0.8   - oscillating:      A_osc = 1.0, omega = 0.5 (steady state computed at t=0)   - noise:            noise_std = 0.01 (set to 0 for steady state)   - cooperative:      hill_n = 2, K_half = 0.5</p> Source code in <code>steady/inittest.py</code> <pre><code>def initial_condition(num_psites: int) -&gt; list:\n    \"\"\"\n    Compute steady-state conditions for the given model.\n\n    Common parameters:\n      A, B, C, D = 1, 1, 1, 1\n      S_rates = ones(num_psites)\n      D_rates = ones(num_psites)\n\n    The parameter vector for the ODE models is:\n      [A, B, C, D, S1, ..., S_n, D1, ..., D_n]\n\n    Extra (hardcoded) parameters per model:\n      - semi_processive: p_proc = 0.8\n      - oscillating:      A_osc = 1.0, omega = 0.5 (steady state computed at t=0)\n      - noise:            noise_std = 0.01 (set to 0 for steady state)\n      - cooperative:      hill_n = 2, K_half = 0.5\n    \"\"\"\n    A, B, C, D = 1, 1, 1, 1\n    S_rates = np.ones(num_psites)\n    D_rates = np.ones(num_psites)\n\n    if TEST_MODEL == 'semi_processive':\n        # Differential Equations (Semi-processive):\n        #   dR/dt = A - B\u00b7R\n        #   dP/dt = C\u00b7R - D\u00b7P - p_proc\u00b7S1\u00b7P + P1\n        #   For n = 1: dP1/dt = p_proc\u00b7S1\u00b7P - (1 + D1)\u00b7P1\n        #   For n &gt; 1:\n        #     dP1/dt = p_proc\u00b7S1\u00b7P - (1 + p_proc\u00b7S2 + D1)\u00b7P1 + P2\n        #     dP\u1d62/dt = p_proc\u00b7S\u1d62\u00b7P\u1d62\u208b\u2081 - (1 + p_proc\u00b7S\u1d62\u208a\u2081 + D\u1d62)\u00b7P\u1d62 + P\u1d62\u208a\u2081  (i=2..n-1)\n        #     dP\u2099/dt = p_proc\u00b7S\u2099\u00b7P\u2099\u208b\u2081 - (1 + D\u2099)\u00b7P\u2099\n        p_proc = PROCESSIVITY\n\n        def steady_state_equations(y):\n            R, P, *P_sites = y\n            eq_R = A - B * R\n            eq_P = C * R - D * P - p_proc * S_rates[0] * P + (P_sites[0] if num_psites &gt;= 1 else 0)\n            if num_psites == 1:\n                eq_P1 = p_proc * S_rates[0] * P - (1 + D_rates[0]) * P_sites[0]\n                return [eq_R, eq_P, eq_P1]\n            else:\n                eqs = []\n                eq_P1 = p_proc * S_rates[0] * P - (1 + p_proc * S_rates[1] + D_rates[0]) * P_sites[0] + P_sites[1]\n                eqs.append(eq_P1)\n                for i in range(1, num_psites - 1):\n                    eq_pi = p_proc * S_rates[i] * P_sites[i - 1] - (1 + p_proc * S_rates[i + 1] + D_rates[i]) * P_sites[\n                        i] + P_sites[i + 1]\n                    eqs.append(eq_pi)\n                eq_last = p_proc * S_rates[-1] * P_sites[-2] - (1 + D_rates[-1]) * P_sites[-1]\n                eqs.append(eq_last)\n                return [eq_R, eq_P] + eqs\n\n    elif TEST_MODEL == 'neg_feedback':\n        k_fb = NEGATIVE_FEEDBACK_CONSTANT\n        def steady_state_equations(y):\n            R, P, *P_sites = y\n            # Compute the feedback factor: f = 1/(1 + k_fb * (P1 + P2 + ... + Pn))\n            f = 1.0 / (1.0 + k_fb * sum(P_sites))\n            eq_R = A - B * R\n            eq_P = C * R - D * P - f * S_rates[0] * P + (P_sites[0] if num_psites &gt;= 1 else 0)\n            if num_psites == 1:\n                eq_P1 = f * S_rates[0] * P - (1 + D_rates[0]) * P_sites[0]\n                return [eq_R, eq_P, eq_P1]\n            else:\n                eqs = []\n                eq_P1 = f * S_rates[0] * P - (1 + f * S_rates[1] + D_rates[0]) * P_sites[0] + P_sites[1]\n                eqs.append(eq_P1)\n                for i in range(1, num_psites - 1):\n                    eq_pi = f * S_rates[i] * P_sites[i - 1] - (1 + f * S_rates[i + 1] + D_rates[i]) * P_sites[i] + P_sites[\n                        i + 1]\n                    eqs.append(eq_pi)\n                eq_last = f * S_rates[-1] * P_sites[-2] - (1 + D_rates[-1]) * P_sites[-1]\n                eqs.append(eq_last)\n                return [eq_R, eq_P] + eqs\n\n    elif TEST_MODEL == 'site_affinity':\n        # Differential Equations (Site-specific Binding Affinity):\n        #   dR/dt = A - B\u00b7R\n        #   dP/dt = C\u00b7R - D\u00b7P - S1\u00b7P + P1\n        #   For n = 1: dP1/dt = S1\u00b7P - (1 + D1)\u00b7P1\n        #   For n &gt; 1:\n        #     dP1/dt = S1\u00b7P - (1 + S2 + D1)\u00b7P1 + P2\n        #     dP\u1d62/dt = S\u1d62\u00b7P\u1d62\u208b\u2081 - (1 + S\u1d62\u208a\u2081 + D\u1d62)\u00b7P\u1d62 + P\u1d62\u208a\u2081, i = 2..n-1\n        #     dP\u2099/dt = S\u2099\u00b7P\u2099\u208b\u2081 - (1 + D\u2099)\u00b7P\u2099\n        def steady_state_equations(y):\n            R, P, *P_sites = y\n            eq_R = A - B * R\n            eq_P = C * R - D * P - S_rates[0] * P + (P_sites[0] if num_psites &gt;= 1 else 0)\n            if num_psites == 1:\n                eq_P1 = S_rates[0] * P - (1 + D_rates[0]) * P_sites[0]\n                return [eq_R, eq_P, eq_P1]\n            else:\n                eqs = []\n                eq_P1 = S_rates[0] * P - (1 + S_rates[1] + D_rates[0]) * P_sites[0] + P_sites[1]\n                eqs.append(eq_P1)\n                for i in range(1, num_psites - 1):\n                    eq_pi = S_rates[i] * P_sites[i - 1] - (1 + S_rates[i + 1] + D_rates[i]) * P_sites[i] + P_sites[\n                        i + 1]\n                    eqs.append(eq_pi)\n                eq_last = S_rates[-1] * P_sites[-2] - (1 + D_rates[-1]) * P_sites[-1]\n                eqs.append(eq_last)\n                return [eq_R, eq_P] + eqs\n\n    elif TEST_MODEL == 'crosstalk':\n        # Differential Equations (Crosstalk):\n        #   Let \u03c6 = (P1 + ... + Pn)/n.\n        #   dR/dt = A - B\u00b7R\n        #   dP/dt = C\u00b7R - D\u00b7P - S1\u00b7P\u00b7(1 + \u03c6) + P1\n        #   For n = 1: dP1/dt = S1\u00b7P\u00b7(1 + \u03c6) - (1 + D1)\u00b7P1\n        #   For n &gt; 1:\n        #     dP1/dt = S1\u00b7P\u00b7(1 + \u03c6) - (1 + S2\u00b7(1 + \u03c6) + D1)\u00b7P1 + P2\n        #     dP\u1d62/dt = S\u1d62\u00b7P\u1d62\u208b\u2081\u00b7(1 + \u03c6) - (1 + S\u1d62\u208a\u2081\u00b7(1 + \u03c6) + D\u1d62)\u00b7P\u1d62 + P\u1d62\u208a\u2081\n        def steady_state_equations(y):\n            R, P, *P_sites = y\n            mod_factor = np.sum(P_sites) / num_psites if num_psites &gt; 0 else 0\n            eq_R = A - B * R\n            eq_P = C * R - D * P - S_rates[0] * P * (1 + mod_factor) + (P_sites[0] if num_psites &gt;= 1 else 0)\n            if num_psites == 1:\n                eq_P1 = S_rates[0] * P * (1 + mod_factor) - (1 + D_rates[0]) * P_sites[0]\n                return [eq_R, eq_P, eq_P1]\n            else:\n                eqs = []\n                eq_P1 = S_rates[0] * P * (1 + mod_factor) - (1 + S_rates[1] * (1 + mod_factor) + D_rates[0]) * P_sites[\n                    0] + P_sites[1]\n                eqs.append(eq_P1)\n                for i in range(1, num_psites - 1):\n                    eq_pi = S_rates[i] * P_sites[i - 1] * (1 + mod_factor) - (\n                                1 + S_rates[i + 1] * (1 + mod_factor) + D_rates[i]) * P_sites[i] + P_sites[i + 1]\n                    eqs.append(eq_pi)\n                eq_last = S_rates[-1] * P_sites[-2] * (1 + mod_factor) - (1 + D_rates[-1]) * P_sites[-1]\n                eqs.append(eq_last)\n                return [eq_R, eq_P] + eqs\n\n    elif TEST_MODEL == 'cooperative':\n        # Differential Equations (Cooperative, Hill-type):\n        #   Let activation \u03c6 = (\u03a3P_i)^hill_n / (K_half^hill_n + (\u03a3P_i)^hill_n + \u03b5), with hill_n = 2, K_half = 0.5.\n        #   dR/dt = A - B\u00b7R\n        #   dP/dt = C\u00b7R - D\u00b7P - S1\u00b7P\u00b7\u03c6 + P1\n        #   For n = 1: dP1/dt = S1\u00b7P\u00b7\u03c6 - (1 + D1)\u00b7P1\n        #   For n &gt; 1:\n        #     dP1/dt = S1\u00b7P\u00b7\u03c6 - (1 + S2\u00b7\u03c6 + D1)\u00b7P1 + P2\n        #     dP\u1d62/dt = S\u1d62\u00b7P\u1d62\u208b\u2081\u00b7\u03c6 - (1 + S\u1d62\u208a\u2081\u00b7\u03c6 + D\u1d62)\u00b7P\u1d62 + P\u1d62\u208a\u2081, for i = 2,...,n-1\n        #     dP\u2099/dt = S\u2099\u00b7P\u2099\u208b\u2081\u00b7\u03c6 - (1 + D\u2099)\u00b7P\u2099\n\n        # Works well for hill_n = 0.5 and K_half = 2\n        hill_n = HILL_N\n        K_half = K_HALF\n\n        def steady_state_equations(y):\n            R, P, *P_sites = y\n            sum_P = np.sum(P_sites)\n            activation = (sum_P ** hill_n) / (K_half ** hill_n + sum_P ** hill_n + 1e-8)\n            eq_R = A - B * R\n            eq_P = C * R - D * P - S_rates[0] * P * activation + (P_sites[0] if num_psites &gt;= 1 else 0)\n            if num_psites == 1:\n                eq_P1 = S_rates[0] * P * activation - (1 + D_rates[0]) * P_sites[0]\n                return [eq_R, eq_P, eq_P1]\n            else:\n                eqs = []\n                eq_P1 = S_rates[0] * P * activation - (1 + S_rates[1] * activation + D_rates[0]) * P_sites[0] + P_sites[\n                    1]\n                eqs.append(eq_P1)\n                for i in range(1, num_psites - 1):\n                    eq_pi = S_rates[i] * P_sites[i - 1] * activation - (1 + S_rates[i + 1] * activation + D_rates[i]) * \\\n                            P_sites[i] + P_sites[i + 1]\n                    eqs.append(eq_pi)\n                eq_last = S_rates[-1] * P_sites[-2] * activation - (1 + D_rates[-1]) * P_sites[-1]\n                eqs.append(eq_last)\n                return [eq_R, eq_P] + eqs\n    else:\n        raise ValueError(\"Unknown model type: \" + TEST_MODEL)\n\n    y0_guess = np.ones(num_psites + 2)\n    bounds_local = [(1e-8, None)] * (num_psites + 2)\n\n    result = minimize(lambda y: 0, y0_guess, method='SLSQP', bounds=bounds_local,\n                      constraints={'type': 'eq', 'fun': steady_state_equations},\n                      options={'maxiter': 10000})\n\n    logger.info(\"Steady-State conditions calculated for TEST model: \" + TEST_MODEL)\n    if result.success:\n        return result.x.tolist()\n    else:\n        logger.info(f\"result: {result}\")\n        raise ValueError(\"Failed to find steady-state conditions for model: \" + TEST_MODEL)\n</code></pre>"},{"location":"reference/#tfopt.evol.config.constants.parse_args","title":"<code>parse_args()</code>","text":"<p>Parse command line arguments for the PhosKinTime optimization problem. This function uses argparse to handle input parameters for the optimization process. The parameters include: - lower_bound: Lower bound for the optimization variables (default: -2). - upper_bound: Upper bound for the optimization variables (default: 2). - loss_type: Type of loss function to use (default: 0).     Options:     0: MSE     1: MAE     2: soft L1     3: Cauchy     4: Arctan     5: Elastic Net     6: Tikhonov - optimizer: Global Evolutionary Optimization method (default: 0).     Options:     0: NGSA2     1: SMSEMOA     2: AGEMOEA</p> <p>:returns - lower_bound: Lower bound for the optimization variables. - upper_bound: Upper bound for the optimization variables. - loss_type: Type of loss function to use. - optimizer: Global Evolutionary Optimization method. :rtype: tuple :raises argparse.ArgumentError: If an invalid argument is provided. :raises SystemExit: If the script is run with invalid arguments.</p> Source code in <code>tfopt/evol/config/constants.py</code> <pre><code>def parse_args():\n    \"\"\"\n    Parse command line arguments for the PhosKinTime optimization problem.\n    This function uses argparse to handle input parameters for the optimization process.\n    The parameters include:\n    - lower_bound: Lower bound for the optimization variables (default: -2).\n    - upper_bound: Upper bound for the optimization variables (default: 2).\n    - loss_type: Type of loss function to use (default: 0).\n        Options:\n        0: MSE\n        1: MAE\n        2: soft L1\n        3: Cauchy\n        4: Arctan\n        5: Elastic Net\n        6: Tikhonov\n    - optimizer: Global Evolutionary Optimization method (default: 0).\n        Options:\n        0: NGSA2\n        1: SMSEMOA\n        2: AGEMOEA\n\n    :returns\n    - lower_bound: Lower bound for the optimization variables.\n    - upper_bound: Upper bound for the optimization variables.\n    - loss_type: Type of loss function to use.\n    - optimizer: Global Evolutionary Optimization method.\n    :rtype: tuple\n    :raises argparse.ArgumentError: If an invalid argument is provided.\n    :raises SystemExit: If the script is run with invalid arguments.\n    \"\"\"\n\n    parser = argparse.ArgumentParser(\n        description=\"PhosKinTime - Global Optimization mRNA-TF Optimization Problem.\"\n    )\n    # Adding command line arguments for lower and upper bounds, loss type, and optimizer\n    parser.add_argument(\"--lower_bound\", type=float, default=-2, help=\"Lower Beta bound.\")\n    parser.add_argument(\"--upper_bound\", type=float, default=2, help=\"Upper Beta bound.\")\n    parser.add_argument(\"--loss_type\", type=int, choices=[0, 1, 2, 3, 4, 5, 6], default=0,\n                        help=\"Loss function to use:  \"\n                             \"0: MSE, 1: MAE, 2: soft L1, 3: Cauchy,\"\n                             \"4: Arctan, 5: Elastic Net, 6: Tikhonov.\")\n    parser.add_argument(\"--optimizer\", type=int, choices=[0, 1, 2], default=0,\n                        help=\"Global Evolutionary Optimization method:  \"\n                             \"0: NGSA2, 1: SMSEMOA , 2: AGEMOEA\")\n    args = parser.parse_args()\n    return args.lower_bound, args.upper_bound, args.loss_type, args.optimizer\n</code></pre>"},{"location":"reference/#tfopt.evol.exporter.plotout.compute_predictions","title":"<code>compute_predictions(x, regulators, protein_mat, psite_tensor, n_reg, T_use, n_mRNA, beta_start_indices, num_psites)</code>","text":"<p>Compute the predicted expression levels based on the optimization variables. This function calculates the predicted expression levels for each mRNA based on the optimization variables, the regulators, and the protein and phosphorylation site tensors.</p> <p>:param x: :param regulators: :param protein_mat: :param psite_tensor: :param n_reg: :param T_use: :param n_mRNA: :param beta_start_indices: :param num_psites: :return: predictions</p> Source code in <code>tfopt/evol/exporter/plotout.py</code> <pre><code>def compute_predictions(x, regulators, protein_mat, psite_tensor, n_reg, T_use, n_mRNA, beta_start_indices, num_psites):\n    \"\"\"\n    Compute the predicted expression levels based on the optimization variables.\n    This function calculates the predicted expression levels for each mRNA based on the optimization variables,\n    the regulators, and the protein and phosphorylation site tensors.\n\n    :param x:\n    :param regulators:\n    :param protein_mat:\n    :param psite_tensor:\n    :param n_reg:\n    :param T_use:\n    :param n_mRNA:\n    :param beta_start_indices:\n    :param num_psites:\n    :return: predictions\n    \"\"\"\n    n_alpha = n_mRNA * n_reg\n    predictions = np.zeros((n_mRNA, T_use))\n    for i in range(n_mRNA):\n        R_pred = np.zeros(T_use)\n        for r in range(n_reg):\n            tf_idx = regulators[i, r]\n            if tf_idx == -1: # No valid TF for this regulator\n                continue\n            a = x[i * n_reg + r]\n            protein = protein_mat[tf_idx, :T_use]\n            beta_start = beta_start_indices[tf_idx]\n            length = 1 + num_psites[tf_idx]\n            beta_vec = x[n_alpha + beta_start : n_alpha + beta_start + length]\n            tf_effect = beta_vec[0] * protein\n            for k in range(num_psites[tf_idx]):\n                tf_effect += beta_vec[k + 1] * psite_tensor[tf_idx, k, :T_use]\n            R_pred += a * tf_effect\n        predictions[i, :] = R_pred\n    return predictions\n</code></pre>"},{"location":"reference/#tfopt.evol.exporter.plotout.plot_estimated_vs_observed","title":"<code>plot_estimated_vs_observed(predictions, expression_matrix, gene_ids, time_points, regulators, tf_protein_matrix, tf_ids, num_targets, save_path=OUT_DIR)</code>","text":"<p>Plot the estimated vs observed expression levels for a set of genes. This function generates two plots for each gene: 1. A full time series plot showing the observed and estimated expression levels. 2. A plot showing the observed and estimated expression levels for the first 5 time points. Additionally, it plots the protein signals for the regulators of each gene. The plots are saved as PNG files in the specified save path.</p> <p>:param predictions: Predicted expression levels. :param expression_matrix: Observed expression levels. :param gene_ids: List of gene identifiers. :param time_points: Time points for the expression data. :param regulators: Matrix of regulators for each gene. :param tf_protein_matrix: Matrix of protein signals for each transcription factor. :param tf_ids: List of transcription factor identifiers. :param num_targets: Number of target genes to plot. :param save_path: Path to save the plots. :type predictions: np.ndarray :type expression_matrix: np.ndarray :type gene_ids: list :type time_points: np.ndarray :type regulators: np.ndarray :type tf_protein_matrix: np.ndarray :type tf_ids: list :type num_targets: int :type save_path: str</p> Source code in <code>tfopt/evol/exporter/plotout.py</code> <pre><code>def plot_estimated_vs_observed(predictions, expression_matrix, gene_ids, time_points, regulators, tf_protein_matrix,\n                               tf_ids, num_targets, save_path=OUT_DIR):\n    \"\"\"\n    Plot the estimated vs observed expression levels for a set of genes.\n    This function generates two plots for each gene:\n    1. A full time series plot showing the observed and estimated expression levels.\n    2. A plot showing the observed and estimated expression levels for the first 5 time points.\n    Additionally, it plots the protein signals for the regulators of each gene.\n    The plots are saved as PNG files in the specified save path.\n\n    :param predictions: Predicted expression levels.\n    :param expression_matrix: Observed expression levels.\n    :param gene_ids: List of gene identifiers.\n    :param time_points: Time points for the expression data.\n    :param regulators: Matrix of regulators for each gene.\n    :param tf_protein_matrix: Matrix of protein signals for each transcription factor.\n    :param tf_ids: List of transcription factor identifiers.\n    :param num_targets: Number of target genes to plot.\n    :param save_path: Path to save the plots.\n    :type predictions: np.ndarray\n    :type expression_matrix: np.ndarray\n    :type gene_ids: list\n    :type time_points: np.ndarray\n    :type regulators: np.ndarray\n    :type tf_protein_matrix: np.ndarray\n    :type tf_ids: list\n    :type num_targets: int\n    :type save_path: str\n    \"\"\"\n    T = len(time_points)\n    time_vals_expr = np.array([4, 8, 15, 30, 60, 120, 240, 480, 960])\n    time_vals_tf = np.array([4, 8, 16, 30, 60, 120, 240, 480, 960])\n    combined_ticks = np.unique(np.concatenate((time_vals_expr, time_vals_tf)))\n    num_targets = min(num_targets, predictions.shape[0])\n\n    for i in range(num_targets):\n        fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n\n        # --- Full time series plot ---\n        ax = axes[0]\n        ax.plot(time_vals_expr, expression_matrix[i, :], 's-', label='Observed', color='black')\n        ax.plot(time_vals_expr, predictions[i, :], '-', label='Estimated', color='red')\n        plotted_tfs = set()\n        for r in regulators[i, :]:\n            if r == -1:\n                continue\n            tf_name = tf_ids[r]\n            if tf_name not in plotted_tfs:\n                protein_signal = tf_protein_matrix[r, :T]\n                ax.plot(time_vals_tf, protein_signal, ':', label=f\"{tf_name}\")\n                plotted_tfs.add(tf_name)\n        ax.set_title(f\"mRNA: {gene_ids[i]}\")\n        ax.set_xlabel(\"Time (minutes)\")\n        ax.set_ylabel(\"Fold Changes\")\n        ax.set_xticks(combined_ticks)\n        ax.set_xticklabels(combined_ticks, rotation=45)\n        ax.grid(True, alpha=0.3)\n\n        # --- First 5 time points plot ---\n        ax = axes[1]\n        ax.plot(time_vals_expr[:5], expression_matrix[i, :5], 's-', label='Observed', color='black')\n        ax.plot(time_vals_expr[:5], predictions[i, :5], '-', label='Estimated', color='red')\n        plotted_tfs = set()\n        for r in regulators[i, :]:\n            if r == -1:\n                continue\n            tf_name = tf_ids[r]\n            if tf_name not in plotted_tfs:\n                protein_signal = tf_protein_matrix[r, :5]\n                ax.plot(time_vals_tf[:5], protein_signal, ':', label=f\"{tf_name}\")\n                plotted_tfs.add(tf_name)\n        ax.set_xlabel(\"Time (minutes)\")\n        ax.set_xticks(time_vals_expr[:5])\n        ax.set_xticklabels(time_vals_expr[:5], rotation=45)\n        ax.legend(title=\"TFs\")\n        ax.grid(True, alpha=0.3)\n        plt.tight_layout()\n        plt.savefig(f\"{save_path}/{gene_ids[i]}_model_fit_.png\", dpi=300)\n        plt.close()\n\n        # This block is for saving two plots for one TF\n        # One for full time series and one for first 5 time points\n        # To see clearly the dynamics early on\n\n        # plt.figure(figsize=(8, 8))\n        # plt.plot(time_vals_expr, expression_matrix[i, :], 's-', label='Observed')\n        # plt.plot(time_vals_expr, predictions[i, :], '-', label='Estimated')\n        # # Plot protein time series for each regulator of mRNA i (only unique TFs)\n        # plotted_tfs = set()\n        # for r in regulators[i, :]:\n        #     if r == -1:  # Skip invalid TF\n        #         continue\n        #     tf_name = tf_ids[r]\n        #     if tf_name not in plotted_tfs:\n        #         protein_signal = tf_protein_matrix[r, :T]\n        #         plt.plot(time_vals_tf, protein_signal, ':', label=f\"mRNA: {tf_name}\")\n        #         plotted_tfs.add(tf_name)\n        # plt.title(f\"mRNA: {gene_ids[i]}\")\n        # plt.xlabel(\"Time (minutes)\")\n        # plt.ylabel(\"Fold Changes\")\n        # plt.xticks(combined_ticks, combined_ticks, rotation=45)\n        # plt.legend()\n        # plt.tight_layout()\n        # plt.grid(True, alpha=0.3)\n        # plt.show()\n        #\n        # plt.figure(figsize=(8, 8))\n        # plt.plot(time_vals_expr[:5], expression_matrix[i, :5], 's-', label='Observed')\n        # plt.plot(time_vals_expr[:5], predictions[i, :5], '-', label='Estimated')\n        # # Plot protein time series for each regulator of mRNA i (only unique TFs)\n        # plotted_tfs = set()\n        # for r in regulators[i, :]:\n        #     if r == -1:  # Skip invalid TF\n        #         continue\n        #     tf_name = tf_ids[r]\n        #     if tf_name not in plotted_tfs:\n        #         protein_signal = tf_protein_matrix[r, :5]\n        #         plt.plot(time_vals_tf[:5], protein_signal, ':', label=f\"mRNA: {tf_name}\")\n        #         plotted_tfs.add(tf_name)\n        # plt.title(f\"mRNA: {gene_ids[i]}\")\n        # plt.xlabel(\"Time (minutes)\")\n        # plt.ylabel(\"Fold Changes\")\n        # plt.xticks(time_vals_expr[:5], time_vals_expr[:5], rotation=45)\n        # plt.legend()\n        # plt.tight_layout()\n        # plt.grid(True, alpha=0.3)\n        # plt.show()\n\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(\n            x=time_vals_expr,\n            y=expression_matrix[i, :],\n            mode='markers+lines',\n            name='Observed',\n            marker=dict(symbol='square')\n        ))\n        fig.add_trace(go.Scatter(\n            x=time_vals_expr,\n            y=predictions[i, :],\n            mode='lines+markers',\n            name='Estimated'\n        ))\n        plotted_tfs = set()\n        for r in regulators[i, :]:\n            if r == -1:\n                continue\n            tf_name = tf_ids[r]\n            if tf_name not in plotted_tfs:\n                protein_signal = tf_protein_matrix[r, :len(time_vals_tf)]\n                fig.add_trace(go.Scatter(\n                    x=time_vals_tf,\n                    y=protein_signal,\n                    mode='lines',\n                    name=f\"mRNA: {tf_name}\",\n                    line=dict(dash='dot')\n                ))\n                plotted_tfs.add(tf_name)\n        fig.update_layout(\n            title=f\"mRNA: {gene_ids[i]}\",\n            xaxis_title=\"Time (minutes)\",\n            yaxis_title=\"Fold Changes\",\n            xaxis=dict(\n                tickmode='array',\n                tickvals=combined_ticks,\n                ticktext=[str(t) for t in combined_ticks]\n            ),\n            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n        )\n        fig.write_html(f\"{save_path}/{gene_ids[i]}_model_fit_.html\")\n</code></pre>"},{"location":"reference/#tfopt.evol.exporter.sheetutils.save_results_to_excel","title":"<code>save_results_to_excel(gene_ids, tf_ids, final_alpha, final_beta, psite_labels_arr, expression_matrix, predictions, objective_value, reg_map, filename=OUT_FILE)</code>","text":"<p>Save the optimization results to an Excel file. This function creates multiple sheets in the Excel file to store different types of data, including alpha values, beta values, residuals, observed values, estimated values, and optimization results. Each sheet is formatted with appropriate column names and data types. The function also calculates various metrics (MSE, MAE, MAPE, R^2) to evaluate the performance of the optimization.</p> <p>:param gene_ids: :param tf_ids: :param final_alpha: :param final_beta: :param psite_labels_arr: :param expression_matrix: :param predictions: :param objective_value: :param reg_map: :param filename:</p> Source code in <code>tfopt/evol/exporter/sheetutils.py</code> <pre><code>def save_results_to_excel(\n        gene_ids, tf_ids,\n        final_alpha, final_beta, psite_labels_arr,\n        expression_matrix, predictions,\n        objective_value,\n        reg_map,\n        filename=OUT_FILE\n):\n    \"\"\"\n    Save the optimization results to an Excel file.\n    This function creates multiple sheets in the Excel file to store different types of data,\n    including alpha values, beta values, residuals, observed values, estimated values,\n    and optimization results.\n    Each sheet is formatted with appropriate column names and data types.\n    The function also calculates various metrics (MSE, MAE, MAPE, R^2)\n    to evaluate the performance of the optimization.\n\n    :param gene_ids:\n    :param tf_ids:\n    :param final_alpha:\n    :param final_beta:\n    :param psite_labels_arr:\n    :param expression_matrix:\n    :param predictions:\n    :param objective_value:\n    :param reg_map:\n    :param filename:\n    \"\"\"\n    # --- Alpha Values ---\n    alpha_rows = []\n    n_genes, n_reg = final_alpha.shape\n    for i in range(n_genes):\n        gene = gene_ids[i]\n        actual_tfs = [tf for tf in reg_map[gene] if tf in tf_ids]\n        for j, tf_name in enumerate(actual_tfs):\n            alpha_rows.append([gene, tf_name, final_alpha[i, j]])\n    df_alpha = pd.DataFrame(alpha_rows, columns=[\"mRNA\", \"TF\", \"Value\"])\n\n    # --- Beta Values ---\n    beta_rows = []\n    for i, tf in enumerate(tf_ids):\n        beta_vec = final_beta[i]\n        beta_rows.append([tf, \"\", beta_vec[0]])  # Protein beta\n        for j in range(1, len(beta_vec)):\n            beta_rows.append([tf, psite_labels_arr[i][j - 1], beta_vec[j]])\n    df_beta = pd.DataFrame(beta_rows, columns=[\"TF\", \"PSite\", \"Value\"])\n\n    # --- Residuals ---\n    residuals = expression_matrix - predictions\n    df_residuals = pd.DataFrame(residuals, columns=[f\"x{j + 1}\" for j in range(residuals.shape[1])])\n    df_residuals.insert(0, \"mRNA\", gene_ids)\n\n    # --- Observed ---\n    df_observed = pd.DataFrame(expression_matrix, columns=[f\"x{j + 1}\" for j in range(expression_matrix.shape[1])])\n    df_observed.insert(0, \"mRNA\", gene_ids)\n\n    # --- Estimated ---\n    df_estimated = pd.DataFrame(predictions, columns=[f\"x{j + 1}\" for j in range(predictions.shape[1])])\n    df_estimated.insert(0, \"mRNA\", gene_ids)\n\n    # --- Optimization Results ---\n    y_true = expression_matrix.flatten()\n    y_pred = predictions.flatten()\n    mse = mean_squared_error(y_true, y_pred)\n    mae = mean_absolute_error(y_true, y_pred)\n    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100\n    r2 = r2_score(y_true, y_pred)\n    df_metrics = pd.DataFrame([\n        [\"Objective Value\", objective_value],\n        [\"MSE\", mse],\n        [\"MAE\", mae],\n        [\"MAPE\", mape],\n        [\"R^2\", r2],\n    ], columns=[\"Metric\", \"Value\"])\n\n    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n        df_alpha.to_excel(writer, sheet_name=\"Alpha Values\", index=False)\n        df_beta.to_excel(writer, sheet_name=\"Beta Values\", index=False)\n        df_residuals.to_excel(writer, sheet_name=\"Residuals\", index=False)\n        df_observed.to_excel(writer, sheet_name=\"Observed\", index=False)\n        df_estimated.to_excel(writer, sheet_name=\"Estimated\", index=False)\n        df_metrics.to_excel(writer, sheet_name=\"Optimization Results\", index=False)\n</code></pre>"},{"location":"reference/#tfopt.evol.objfn.minfn.TFOptimizationMultiObjectiveProblem","title":"<code>TFOptimizationMultiObjectiveProblem</code>","text":"<p>               Bases: <code>Problem</code></p> <p>Originally implemented by Julius Normann.</p> <p>This version has been modified and optimized for consistency &amp; speed in submodules by Abhinav Mishra.</p> <p>Multi-objective optimization problem for TF optimization. This class defines a multi-objective optimization problem for the transcription factor (TF) optimization problem. It inherits from the <code>Problem</code> class in the pymoo library. The problem is defined with three objectives: f1 (error), f2 (alpha violation), and f3 (beta violation).</p> <p>The problem is initialized with the following parameters: - n_var: Number of decision variables. - n_mRNA: Number of mRNA genes. - n_TF: Number of transcription factors. - n_reg: Number of regulators. - n_psite_max: Maximum number of phosphorylation sites. - n_alpha: Number of alpha parameters. - mRNA_mat: Matrix of measured mRNA values. - regulators: Matrix of TF regulators for each mRNA. - protein_mat: Matrix of TF protein time series. - psite_tensor: Tensor of phosphorylation site signals. - T_use: Number of time points used. - beta_start_indices: Integer array giving the starting index (in the \u03b2\u2013segment)                       for each TF. - num_psites: Integer array with the actual number of phosphorylation sites for each TF. - no_psite_tf: Boolean array indicating if the TF has no phosphorylation sites. - xl: Lower bounds for the decision variables. - xu: Upper bounds for the decision variables. - kwargs: Additional keyword arguments.</p> Source code in <code>tfopt/evol/objfn/minfn.py</code> <pre><code>class TFOptimizationMultiObjectiveProblem(Problem):\n    \"\"\"\n    Originally implemented by Julius Normann.\n\n    This version has been modified and optimized\n    for consistency &amp; speed in submodules by Abhinav Mishra.\n\n    Multi-objective optimization problem for TF optimization.\n    This class defines a multi-objective optimization problem for the\n    transcription factor (TF) optimization problem. It inherits from the\n    `Problem` class in the pymoo library. The problem is defined with three\n    objectives: f1 (error), f2 (alpha violation), and f3 (beta violation).\n\n    The problem is initialized with the following parameters:\n    - n_var: Number of decision variables.\n    - n_mRNA: Number of mRNA genes.\n    - n_TF: Number of transcription factors.\n    - n_reg: Number of regulators.\n    - n_psite_max: Maximum number of phosphorylation sites.\n    - n_alpha: Number of alpha parameters.\n    - mRNA_mat: Matrix of measured mRNA values.\n    - regulators: Matrix of TF regulators for each mRNA.\n    - protein_mat: Matrix of TF protein time series.\n    - psite_tensor: Tensor of phosphorylation site signals.\n    - T_use: Number of time points used.\n    - beta_start_indices: Integer array giving the starting index (in the \u03b2\u2013segment)\n                          for each TF.\n    - num_psites: Integer array with the actual number of phosphorylation sites for each TF.\n    - no_psite_tf: Boolean array indicating if the TF has no phosphorylation sites.\n    - xl: Lower bounds for the decision variables.\n    - xu: Upper bounds for the decision variables.\n    - kwargs: Additional keyword arguments.\n    \"\"\"\n    def __init__(self, n_var, n_mRNA, n_TF, n_reg, n_psite_max, n_alpha,\n                 mRNA_mat, regulators, protein_mat, psite_tensor, T_use,\n                 beta_start_indices, num_psites, no_psite_tf, xl=None, xu=None,\n                 **kwargs):\n        \"\"\"\n        Initialize the multi-objective optimization problem.\n\n        :param n_var:\n        :param n_mRNA:\n        :param n_TF:\n        :param n_reg:\n        :param n_psite_max:\n        :param n_alpha:\n        :param mRNA_mat:\n        :param regulators:\n        :param protein_mat:\n        :param psite_tensor:\n        :param T_use:\n        :param beta_start_indices:\n        :param num_psites:\n        :param no_psite_tf:\n        :param xl:\n        :param xu:\n        :param kwargs:\n        \"\"\"\n        super().__init__(n_var=n_var, n_obj=3, n_constr=0, xl=xl, xu=xu)\n        self.n_mRNA = n_mRNA\n        self.n_TF = n_TF\n        self.n_reg = n_reg\n        self.n_psite_max = n_psite_max\n        self.n_alpha = n_alpha\n        self.mRNA_mat = mRNA_mat\n        self.regulators = regulators\n        self.protein_mat = protein_mat\n        self.psite_tensor = psite_tensor\n        self.T_use = T_use\n        self.beta_start_indices = beta_start_indices\n        self.num_psites = num_psites\n        self.no_psite_tf = no_psite_tf\n        self.loss_type = kwargs.get(\"loss_type\", 0)\n\n    def _evaluate(self, X, out, *args, **kwargs):\n        \"\"\"\n        Evaluate the objectives for the given decision variables.\n        This function computes the objectives for each individual in the population.\n        The objectives are defined as follows:\n        - f1: Error (objective function value).\n        - f2: Alpha violation (sum of squares of alpha values).\n        - f3: Beta violation (sum of squares of beta values).\n\n        The function computes the objectives for each individual in the population\n        and stores the results in the output dictionary.\n        :param X: Decision variables (population).\n        :param out: Output dictionary to store the results.\n        :param args: Additional arguments.\n        :param kwargs: Additional keyword arguments.\n        :return: Final Objective values.\n        \"\"\"\n        n_pop = X.shape[0]\n        F = np.empty((n_pop, 3))\n        n_alpha = self.n_alpha\n        for i in range(n_pop):\n            xi = X[i]\n            f1 = objective_(xi, self.mRNA_mat, self.regulators, self.protein_mat,\n                                       self.psite_tensor, self.n_reg, self.T_use, self.n_mRNA, self.beta_start_indices, self.num_psites, self.loss_type)\n            f2 = 0.0\n            for m in range(self.n_mRNA):\n                s = 0.0\n                for r in range(self.n_reg):\n                    s += xi[m * self.n_reg + r]\n                f2 += (s - 1.0) ** 2\n            f3 = 0.0\n            for tf in range(self.n_TF):\n                start = n_alpha + self.beta_start_indices[tf]\n                length = 1 + self.num_psites[tf]\n                beta_vec = xi[start : start + length]\n                f3 += (np.sum(beta_vec) - 1.0) ** 2\n                if self.no_psite_tf[tf]:\n                    for q in range(1, length):\n                        f3 += beta_vec[q] ** 2\n            # Three objectives:\n            # f1 (error)\n            F[i, 0] = f1\n            # f2 (alpha violation)\n            F[i, 1] = f2\n            # f3 (beta violation)\n            F[i, 2] = f3\n        out[\"F\"] = F\n</code></pre>"},{"location":"reference/#tfopt.evol.objfn.minfn.TFOptimizationMultiObjectiveProblem.__init__","title":"<code>__init__(n_var, n_mRNA, n_TF, n_reg, n_psite_max, n_alpha, mRNA_mat, regulators, protein_mat, psite_tensor, T_use, beta_start_indices, num_psites, no_psite_tf, xl=None, xu=None, **kwargs)</code>","text":"<p>Initialize the multi-objective optimization problem.</p> <p>:param n_var: :param n_mRNA: :param n_TF: :param n_reg: :param n_psite_max: :param n_alpha: :param mRNA_mat: :param regulators: :param protein_mat: :param psite_tensor: :param T_use: :param beta_start_indices: :param num_psites: :param no_psite_tf: :param xl: :param xu: :param kwargs:</p> Source code in <code>tfopt/evol/objfn/minfn.py</code> <pre><code>def __init__(self, n_var, n_mRNA, n_TF, n_reg, n_psite_max, n_alpha,\n             mRNA_mat, regulators, protein_mat, psite_tensor, T_use,\n             beta_start_indices, num_psites, no_psite_tf, xl=None, xu=None,\n             **kwargs):\n    \"\"\"\n    Initialize the multi-objective optimization problem.\n\n    :param n_var:\n    :param n_mRNA:\n    :param n_TF:\n    :param n_reg:\n    :param n_psite_max:\n    :param n_alpha:\n    :param mRNA_mat:\n    :param regulators:\n    :param protein_mat:\n    :param psite_tensor:\n    :param T_use:\n    :param beta_start_indices:\n    :param num_psites:\n    :param no_psite_tf:\n    :param xl:\n    :param xu:\n    :param kwargs:\n    \"\"\"\n    super().__init__(n_var=n_var, n_obj=3, n_constr=0, xl=xl, xu=xu)\n    self.n_mRNA = n_mRNA\n    self.n_TF = n_TF\n    self.n_reg = n_reg\n    self.n_psite_max = n_psite_max\n    self.n_alpha = n_alpha\n    self.mRNA_mat = mRNA_mat\n    self.regulators = regulators\n    self.protein_mat = protein_mat\n    self.psite_tensor = psite_tensor\n    self.T_use = T_use\n    self.beta_start_indices = beta_start_indices\n    self.num_psites = num_psites\n    self.no_psite_tf = no_psite_tf\n    self.loss_type = kwargs.get(\"loss_type\", 0)\n</code></pre>"},{"location":"reference/#tfopt.evol.objfn.minfn.objective_","title":"<code>objective_(x, mRNA_mat, regulators, protein_mat, psite_tensor, n_reg, T_use, n_mRNA, beta_start_indices, num_psites, loss_type, lam1=0.001, lam2=0.001)</code>","text":"<p>Computes a loss value using one of several loss functions.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code> </code> <p>Decision vector.</p> required <code>mRNA_mat</code> <code> </code> <p>(n_mRNA x T_use) measured mRNA values.</p> required <code>regulators</code> <code> </code> <p>(n_mRNA x n_reg) indices of TF regulators for each mRNA.</p> required <code>protein_mat</code> <code> </code> <p>(n_TF x T_use) TF protein time series.</p> required <code>psite_tensor</code> <code> </code> <p>(n_TF x n_psite_max x T_use) matrix of PSite signals (padded with zeros).</p> required <code>n_reg</code> <code> </code> <p>Maximum number of regulators per mRNA.</p> required <code>T_use</code> <code> </code> <p>Number of time points used.</p> required <code>n_mRNA,</code> <code>n_TF</code> <p>Number of mRNA and TF respectively.</p> required <code>beta_start_indices</code> <p>Integer array giving the starting index (in the \u03b2\u2013segment)                  for each TF.</p> required <code>num_psites</code> <code> </code> <p>Integer array with the actual number of PSites for each TF.</p> required <code>loss_type</code> <code> </code> <p>Integer indicating the loss type (0: MSE, 1: MAE, 2: soft L1,                  3: Cauchy, 4: Arctan, 5: Elastic Net, 6: Tikhonov).</p> required <code>lam1,</code> <code>lam2</code> <p>Regularization parameters (used for loss_type 5 and 6).</p> required <p>Returns:</p> Type Description <p>The computed loss (a scalar).</p> Source code in <code>tfopt/evol/objfn/minfn.py</code> <pre><code>@njit(cache=False, fastmath=False, parallel=True, nogil=False)\ndef objective_(x, mRNA_mat, regulators, protein_mat, psite_tensor, n_reg, T_use, n_mRNA,\n                   beta_start_indices, num_psites, loss_type, lam1=1e-3, lam2=1e-3):\n    \"\"\"\n    Computes a loss value using one of several loss functions.\n\n    Parameters:\n      x               : Decision vector.\n      mRNA_mat        : (n_mRNA x T_use) measured mRNA values.\n      regulators      : (n_mRNA x n_reg) indices of TF regulators for each mRNA.\n      protein_mat     : (n_TF x T_use) TF protein time series.\n      psite_tensor    : (n_TF x n_psite_max x T_use) matrix of PSite signals (padded with zeros).\n      n_reg           : Maximum number of regulators per mRNA.\n      T_use           : Number of time points used.\n      n_mRNA, n_TF    : Number of mRNA and TF respectively.\n      beta_start_indices: Integer array giving the starting index (in the \u03b2\u2013segment)\n                         for each TF.\n      num_psites      : Integer array with the actual number of PSites for each TF.\n      loss_type       : Integer indicating the loss type (0: MSE, 1: MAE, 2: soft L1,\n                         3: Cauchy, 4: Arctan, 5: Elastic Net, 6: Tikhonov).\n      lam1, lam2      : Regularization parameters (used for loss_type 5 and 6).\n\n    Returns:\n      The computed loss (a scalar).\n    \"\"\"\n    total_loss = 0.0\n    n_alpha = n_mRNA * n_reg\n    for i in prange(n_mRNA):\n        R_meas = mRNA_mat[i, :T_use]\n        R_pred = np.zeros(T_use)\n        for r in range(n_reg):\n            tf_idx = regulators[i, r]\n            if tf_idx == -1: # No valid TF for this regulator\n                continue\n            a = x[i * n_reg + r]\n            protein = protein_mat[tf_idx, :T_use]\n            beta_start = beta_start_indices[tf_idx]\n            length = 1 + num_psites[tf_idx]  # actual length of beta vector for TF\n            beta_vec = x[n_alpha + beta_start: n_alpha + beta_start + length]\n            tf_effect = beta_vec[0] * protein\n            for k in range(num_psites[tf_idx]):\n                tf_effect += beta_vec[k + 1] * psite_tensor[tf_idx, k, :T_use]\n            R_pred += a * tf_effect\n        # For each time point, add loss according to loss_type.\n        for t in range(T_use):\n            e = R_meas[t] - R_pred[t]\n            if loss_type == 0:  # MSE\n                total_loss += e * e\n            elif loss_type == 1:  # MAE\n                total_loss += abs(e)\n            elif loss_type == 2:  # Soft L1 (pseudo-Huber)\n                total_loss += 2.0 * (np.sqrt(1.0 + e * e) - 1.0)\n            elif loss_type == 3:  # Cauchy\n                total_loss += np.log(1.0 + e * e)\n            elif loss_type == 4:  # Arctan\n                total_loss += np.arctan(e * e)\n            else:\n                # Default to MSE if unknown.\n                total_loss += e * e\n    loss = total_loss / (n_mRNA * T_use)\n\n    # For elastic net (loss_type 5), add L1 and L2 penalties on the beta portion.\n    if loss_type == 5:\n        l1 = 0.0\n        l2 = 0.0\n        # Compute over beta parameters only.\n        for i in range(n_alpha, x.shape[0]):\n            v = x[i]\n            l1 += abs(v)\n            l2 += v * v\n        loss += lam1 * l1 + lam2 * l2\n\n    # For Tikhonov (loss_type 6), add L2 penalty on the beta portion.\n    if loss_type == 6:\n        l2 = 0.0\n        for i in range(n_alpha, x.shape[0]):\n            v = x[i]\n            l2 += v * v\n        loss += lam1 * l2\n\n    return loss\n</code></pre>"},{"location":"reference/#tfopt.evol.opt.optrun.run_optimization","title":"<code>run_optimization(problem, total_dim, optimizer)</code>","text":"<p>Run the optimization using the specified algorithm and problem. This function sets up the algorithm parameters, initializes the optimizer, and runs the optimization process.</p> <p>:param problem: :param total_dim: :param optimizer: :return: result</p> Source code in <code>tfopt/evol/opt/optrun.py</code> <pre><code>def run_optimization(problem, total_dim, optimizer):\n    \"\"\"\n    Run the optimization using the specified algorithm and problem.\n    This function sets up the algorithm parameters, initializes the optimizer,\n    and runs the optimization process.\n\n    :param problem:\n    :param total_dim:\n    :param optimizer:\n    :return: result\n    \"\"\"\n    # Define algorithm settings.\n    global algo\n    pop_size = 2000\n    crossover = TwoPointCrossover(prob=0.9)\n    mutation = PolynomialMutation(prob=1.0 / total_dim, eta=20)\n    eliminate_duplicates = True\n\n    # Choose the optimizer based on the input parameter.\n    if optimizer == 0:\n        # NSGA2 settings.\n        algo = NSGA2(\n            pop_size=pop_size,\n            crossover=crossover,\n            mutation=mutation,\n            eliminate_duplicates=eliminate_duplicates\n        )\n    elif optimizer == 1:\n        # SMSEMOA settings.\n        algo= SMSEMOA(\n            pop_size=pop_size,\n            crossover=crossover,\n            mutation=mutation,\n            eliminate_duplicates=eliminate_duplicates\n        )\n    elif optimizer == 2:\n        # AGEMOEA settings.\n        algo = AGEMOEA(\n            pop_size=pop_size,\n            crossover=crossover,\n            mutation=mutation,\n            eliminate_duplicates=eliminate_duplicates\n        )\n    else:\n        logger.error(\"Unknown optimizer type. Please choose 0 (NSGA2), 1 (SMSEMOA), or 2 (AGEMOEA).\")\n\n    termination = DefaultMultiObjectiveTermination()\n\n    # Run the optimization\n    # buf = io.StringIO()\n    # with contextlib.redirect_stdout(buf):\n    res = pymoo_minimize(problem=problem,\n                         algorithm=algo,\n                         termination=termination,\n                         seed=1,\n                         verbose=True)\n\n        # Log the captured pymoo progress\n    # pymoo_progress = buf.getvalue()\n    # if pymoo_progress.strip():  # only log if there's actual text\n    #     logger.info(\"--- Progress Output ---\\n\" + pymoo_progress)\n\n    return res\n</code></pre>"},{"location":"reference/#tfopt.evol.optcon.construct.build_fixed_arrays","title":"<code>build_fixed_arrays(mRNA_ids, mRNA_mat, TF_ids, protein_dict, psite_dict, psite_labels_dict, reg_map)</code>","text":"<p>Builds fixed-shape arrays from the input data. Returns:   - mRNA_mat: array of shape (n_mRNA, T)   - regulators: array of shape (n_mRNA, n_reg) with indices into TF_ids.   - protein_mat: array of shape (n_TF, T)   - psite_tensor: array of shape (n_TF, n_psite_max, T), padded with zeros.   - n_reg: maximum number of regulators per mRNA.   - n_psite_max: maximum number of PSites among TFs.   - psite_labels_arr: list (length n_TF) of lists of PSite names (padded with empty strings).   - num_psites: array of length n_TF with the actual number of PSites for each TF.</p> Source code in <code>tfopt/evol/optcon/construct.py</code> <pre><code>def build_fixed_arrays(mRNA_ids, mRNA_mat, TF_ids, protein_dict, psite_dict, psite_labels_dict, reg_map):\n    \"\"\"\n    Builds fixed-shape arrays from the input data.\n    Returns:\n      - mRNA_mat: array of shape (n_mRNA, T)\n      - regulators: array of shape (n_mRNA, n_reg) with indices into TF_ids.\n      - protein_mat: array of shape (n_TF, T)\n      - psite_tensor: array of shape (n_TF, n_psite_max, T), padded with zeros.\n      - n_reg: maximum number of regulators per mRNA.\n      - n_psite_max: maximum number of PSites among TFs.\n      - psite_labels_arr: list (length n_TF) of lists of PSite names (padded with empty strings).\n      - num_psites: array of length n_TF with the actual number of PSites for each TF.\n    \"\"\"\n    n_mRNA, T = mRNA_mat.shape\n\n    # Map TF_id to index.\n    TF_index = {tf: idx for idx, tf in enumerate(TF_ids)}\n    n_TF = len(TF_ids)\n\n    # # Determine maximum number of regulators per mRNA.\n    # max_reg = 0\n    # reg_list = []\n    # for gene in mRNA_ids:\n    #     regs = reg_map.get(gene, [])\n    #     max_reg = max(max_reg, len(regs))\n    #     reg_list.append(regs)\n    # n_reg = max_reg if max_reg &gt; 0 else 1\n    #\n    # # Build regulators array (n_mRNA x n_reg), padded with index 0.\n    # regulators = np.zeros((n_mRNA, n_reg), dtype=np.int32)\n    # for i, regs in enumerate(reg_list):\n    #     for j in range(n_reg):\n    #         if j &lt; len(regs):\n    #             regulators[i, j] = TF_index.get(regs[j], 0)\n    #         else:\n    #             regulators[i, j] = 0\n\n    # Determine max number of valid regulators across all mRNA, and keep valid indices only.\n    reg_list = []\n    for gene in mRNA_ids:\n        regs = [tf for tf in reg_map.get(gene, []) if tf in TF_ids]\n        reg_list.append(regs)\n    n_reg = max(len(regs) for regs in reg_list) if reg_list else 1\n\n    # Build regulators array (n_mRNA x n_reg), padded with -1 to mark invalid.\n    regulators = np.full((n_mRNA, n_reg), -1, dtype=np.int32)\n    for i, regs in enumerate(reg_list):\n        for j, tf in enumerate(regs):\n            regulators[i, j] = TF_index.get(tf, -1)\n\n    # Build protein_mat.\n    protein_mat = np.zeros((n_TF, T), dtype=np.float64)\n    for tf, idx in TF_index.items():\n        if protein_dict.get(tf) is not None:\n            protein_mat[idx, :] = protein_dict[tf][:T]\n        else:\n            protein_mat[idx, :] = np.zeros(T)\n\n    # For each TF, record the actual number of PSites.\n    num_psites = np.zeros(n_TF, dtype=np.int32)\n    for i, tf in enumerate(TF_ids):\n        num_psites[i] = len(psite_dict.get(tf, []))\n    # Maximum number of PSites across all TFs.\n    n_psite_max = int(np.max(num_psites)) if np.max(num_psites) &gt; 0 else 0\n\n    # Build psite_tensor and psite_labels_arr.\n    # psite_tensor will have shape (n_TF, n_psite_max, T) and we pad shorter vectors with zeros.\n    psite_tensor = np.zeros((n_TF, n_psite_max, T), dtype=np.float64)\n    psite_labels_arr = []\n    for tf, idx in TF_index.items():\n        psites = psite_dict.get(tf, [])\n        labels = psite_labels_dict.get(tf, [])\n        for j in range(n_psite_max):\n            if j &lt; len(psites):\n                psite_tensor[idx, j, :] = psites[j][:T]\n            else:\n                psite_tensor[idx, j, :] = np.zeros(T)\n        padded_labels = labels + [\"\"] * (n_psite_max - len(labels))\n        psite_labels_arr.append(padded_labels)\n\n    return mRNA_mat, regulators, protein_mat, psite_tensor, n_reg, n_psite_max, psite_labels_arr, num_psites\n</code></pre>"},{"location":"reference/#tfopt.evol.optcon.filter.determine_T_use","title":"<code>determine_T_use(mRNA_mat, TF_time_cols)</code>","text":"<p>Determine the number of time points to use for the analysis. This function takes the mRNA matrix and TF time columns as input and returns the minimum number of time points available across both datasets. This is important for ensuring that the analysis is consistent and comparable across different datasets. The function checks the shape of the mRNA matrix and the length of the TF time columns to determine the minimum number of time points. If the mRNA matrix has fewer time points than the TF time columns, it uses the number of time points in the mRNA matrix. If the TF time columns have fewer time points, it uses that value instead. This ensures that the analysis is based on the same number of time points for both mRNA and TF data.</p> <p>:param mRNA_mat: Matrix of mRNA expression data. :param TF_time_cols: Time points for TF data. :return: T_use: Number of time points to use for the analysis.</p> Source code in <code>tfopt/evol/optcon/filter.py</code> <pre><code>def determine_T_use(mRNA_mat, TF_time_cols):\n    \"\"\"\n    Determine the number of time points to use for the analysis.\n    This function takes the mRNA matrix and TF time columns as input\n    and returns the minimum number of time points available across both datasets.\n    This is important for ensuring that the analysis is consistent and\n    comparable across different datasets.\n    The function checks the shape of the mRNA matrix and the length of the TF time columns\n    to determine the minimum number of time points.\n    If the mRNA matrix has fewer time points than the TF time columns,\n    it uses the number of time points in the mRNA matrix.\n    If the TF time columns have fewer time points, it uses that value instead.\n    This ensures that the analysis is based on the same number of time points\n    for both mRNA and TF data.\n\n    :param mRNA_mat: Matrix of mRNA expression data.\n    :param TF_time_cols: Time points for TF data.\n    :return: T_use: Number of time points to use for the analysis.\n    \"\"\"\n    T_use = min(mRNA_mat.shape[1], len(TF_time_cols))\n    return T_use\n</code></pre>"},{"location":"reference/#tfopt.evol.optcon.filter.filter_TF","title":"<code>filter_TF(TF_ids, protein_dict, psite_dict, psite_labels_dict, relevant_TFs)</code>","text":"<p>Filter transcription factors to only those present in the relevant_TFs set. This function returns the filtered TF_ids and their corresponding protein and phosphorylation site data. This is important for ensuring that only relevant transcription factors are included in the analysis. :param TF_ids: List of transcription factor identifiers. :param protein_dict: Dictionary mapping TF_ids to their protein data. :param psite_dict: Dictionary mapping TF_ids to their phosphorylation site data. :param psite_labels_dict: Dictionary mapping TF_ids to their phosphorylation site labels. :param relevant_TFs: Set of relevant transcription factors. :return: filtered TF_ids, protein_dict, psite_dict, psite_labels_dict</p> Source code in <code>tfopt/evol/optcon/filter.py</code> <pre><code>def filter_TF(TF_ids, protein_dict, psite_dict, psite_labels_dict, relevant_TFs):\n    \"\"\"\n    Filter transcription factors to only those present in the relevant_TFs set.\n    This function returns the filtered TF_ids and their corresponding protein and phosphorylation site data.\n    This is important for ensuring that only relevant transcription factors are included in the analysis.\n    :param TF_ids: List of transcription factor identifiers.\n    :param protein_dict: Dictionary mapping TF_ids to their protein data.\n    :param psite_dict: Dictionary mapping TF_ids to their phosphorylation site data.\n    :param psite_labels_dict: Dictionary mapping TF_ids to their phosphorylation site labels.\n    :param relevant_TFs: Set of relevant transcription factors.\n    :return: filtered TF_ids, protein_dict, psite_dict, psite_labels_dict\n    \"\"\"\n    TF_ids_filtered = [tf for tf in TF_ids if tf in relevant_TFs]\n    protein_dict = {tf: protein_dict[tf] for tf in TF_ids_filtered}\n    psite_dict = {tf: psite_dict[tf] for tf in TF_ids_filtered}\n    psite_labels_dict = {tf: psite_labels_dict[tf] for tf in TF_ids_filtered}\n    return TF_ids_filtered, protein_dict, psite_dict, psite_labels_dict\n</code></pre>"},{"location":"reference/#tfopt.evol.optcon.filter.filter_mrna","title":"<code>filter_mrna(mRNA_ids, mRNA_mat, reg_map)</code>","text":"<p>Filter mRNA genes to only those with regulators present in the regulation map. This function returns the filtered mRNA_ids and their corresponding expression matrix.</p> <p>:param mRNA_ids: List of mRNA gene identifiers. :param mRNA_mat: Matrix of mRNA expression data. :param reg_map: Regulation map, mapping mRNA genes to their regulators. :return: filtered_mRNA_ids, filtered_mRNA_mat</p> Source code in <code>tfopt/evol/optcon/filter.py</code> <pre><code>def filter_mrna(mRNA_ids, mRNA_mat, reg_map):\n    \"\"\"\n    Filter mRNA genes to only those with regulators present in the regulation map.\n    This function returns the filtered mRNA_ids and their corresponding expression matrix.\n\n    :param mRNA_ids: List of mRNA gene identifiers.\n    :param mRNA_mat: Matrix of mRNA expression data.\n    :param reg_map: Regulation map, mapping mRNA genes to their regulators.\n    :return: filtered_mRNA_ids, filtered_mRNA_mat\n    \"\"\"\n    filtered_indices = [i for i, gene in enumerate(mRNA_ids) if gene in reg_map and len(reg_map[gene]) &gt; 0]\n    if not filtered_indices:\n        raise ValueError(\"No mRNA with regulators found.\")\n    return [mRNA_ids[i] for i in filtered_indices], mRNA_mat[filtered_indices, :]\n</code></pre>"},{"location":"reference/#tfopt.evol.optcon.filter.load_raw_data","title":"<code>load_raw_data()</code>","text":"<p>Load raw data from files. This includes mRNA data, TF data, and regulation maps. The function returns the following: - mRNA_ids: List of mRNA gene identifiers. - mRNA_mat: Matrix of mRNA expression data. - mRNA_time_cols: Time points for mRNA data. - TF_ids: List of transcription factor identifiers. - protein_dict: Dictionary mapping TF_ids to their protein data. - psite_dict: Dictionary mapping TF_ids to their phosphorylation site data. - psite_labels_dict: Dictionary mapping TF_ids to their phosphorylation site labels. - TF_time_cols: Time points for TF data. - reg_map: Regulation map, mapping mRNA genes to their regulators.</p> <p>:return: mRNA_ids, mRNA_mat, mRNA_time_cols, TF_ids, protein_dict, psite_dict, psite_labels_dict, TF_time_cols, reg_map</p> Source code in <code>tfopt/evol/optcon/filter.py</code> <pre><code>def load_raw_data():\n    \"\"\"\n    Load raw data from files.\n    This includes mRNA data, TF data, and regulation maps.\n    The function returns the following:\n    - mRNA_ids: List of mRNA gene identifiers.\n    - mRNA_mat: Matrix of mRNA expression data.\n    - mRNA_time_cols: Time points for mRNA data.\n    - TF_ids: List of transcription factor identifiers.\n    - protein_dict: Dictionary mapping TF_ids to their protein data.\n    - psite_dict: Dictionary mapping TF_ids to their phosphorylation site data.\n    - psite_labels_dict: Dictionary mapping TF_ids to their phosphorylation site labels.\n    - TF_time_cols: Time points for TF data.\n    - reg_map: Regulation map, mapping mRNA genes to their regulators.\n\n    :return: mRNA_ids, mRNA_mat, mRNA_time_cols, TF_ids, protein_dict, psite_dict, psite_labels_dict, TF_time_cols, reg_map\n    \"\"\"\n    mRNA_ids, mRNA_mat, mRNA_time_cols = load_mRNA_data()\n    TF_ids, protein_dict, psite_dict, psite_labels_dict, TF_time_cols = load_TF_data()\n    reg_map = load_regulation()\n    return mRNA_ids, mRNA_mat, mRNA_time_cols, TF_ids, protein_dict, psite_dict, psite_labels_dict, TF_time_cols, reg_map\n</code></pre>"},{"location":"reference/#tfopt.evol.optcon.filter.update_regulations","title":"<code>update_regulations(mRNA_ids, reg_map, TF_ids)</code>","text":"<p>Update the regulation map to only include relevant transcription factors. This function modifies the reg_map in place and returns a set of relevant transcription factors.</p> <p>:param mRNA_ids: List of mRNA gene identifiers. :param reg_map: Regulation map, mapping mRNA genes to their regulators. :param TF_ids: List of transcription factor identifiers. :return: relevant_TFs: Set of relevant transcription factors.</p> Source code in <code>tfopt/evol/optcon/filter.py</code> <pre><code>def update_regulations(mRNA_ids, reg_map, TF_ids):\n    \"\"\"\n    Update the regulation map to only include relevant transcription factors.\n    This function modifies the reg_map in place and returns a set of relevant transcription factors.\n\n    :param mRNA_ids: List of mRNA gene identifiers.\n    :param reg_map: Regulation map, mapping mRNA genes to their regulators.\n    :param TF_ids: List of transcription factor identifiers.\n    :return: relevant_TFs: Set of relevant transcription factors.\n    \"\"\"\n    relevant_TFs = set()\n    for gene in mRNA_ids:\n        regs = reg_map.get(gene, [])\n        regs_filtered = [tf for tf in regs if tf in TF_ids]\n        reg_map[gene] = regs_filtered\n        relevant_TFs.update(regs_filtered)\n    return relevant_TFs\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.iodata.create_report","title":"<code>create_report(results_dir, output_file='report.html')</code>","text":"<p>Creates a single global report HTML file from all gene folders inside the results directory.</p> <p>For each gene folder (e.g. \"ABL2\"), the report will include:   - All PNG plots and interactive HTML plots displayed in a grid with three plots per row.   - Each plot is confined to a fixed size of 900px by 900px.   - Data tables from XLSX or CSV files in the gene folder are displayed below the plots, one per row.</p> <p>Parameters:</p> Name Type Description Default <code>results_dir</code> <code>str</code> <p>Path to the root results directory.</p> required <code>output_file</code> <code>str</code> <p>Name of the generated global report file (placed inside results_dir).</p> <code>'report.html'</code> Source code in <code>tfopt/evol/utils/iodata.py</code> <pre><code>def create_report(results_dir: str, output_file: str = \"report.html\"):\n    \"\"\"\n    Creates a single global report HTML file from all gene folders inside the results directory.\n\n    For each gene folder (e.g. \"ABL2\"), the report will include:\n      - All PNG plots and interactive HTML plots displayed in a grid with three plots per row.\n      - Each plot is confined to a fixed size of 900px by 900px.\n      - Data tables from XLSX or CSV files in the gene folder are displayed below the plots, one per row.\n\n    Args:\n        results_dir (str): Path to the root results directory.\n        output_file (str): Name of the generated global report file (placed inside results_dir).\n    \"\"\"\n    # Gather gene folders (skip \"General\" and \"logs\")\n    gene_folders = [\n        d for d in os.listdir(results_dir)\n        if os.path.isdir(os.path.join(results_dir, d)) and d not in (\"General\", \"logs\")\n    ]\n\n    # Build HTML content with updated CSS for spacing.\n    html_parts = [\n        \"&lt;html&gt;\",\n        \"&lt;head&gt;\",\n        \"&lt;meta charset='UTF-8'&gt;\",\n        \"&lt;title&gt;Estimation Report&lt;/title&gt;\",\n        \"&lt;style&gt;\",\n        \"body { font-family: Arial, sans-serif; margin: 20px; }\",\n        \"h1 { color: #333; }\",\n        \"h2 { color: #555; font-size: 1.8em; border-bottom: 1px solid #ccc; padding-bottom: 5px; }\",\n        \"h3 { color: #666; font-size: 1.4em; margin-top: 10px; margin-bottom: 10px; }\",\n        # /* CSS grid for plots: two per row, fixed size 500px x 500px, extra space between rows */\n        \".plot-container {\",\n        \"  display: grid;\",\n        \"  grid-template-columns: repeat(2, 500px);\",\n        \"  column-gap: 20px;\",\n        \"  row-gap: 40px;\", # /* extra vertical gap */\n        \"  justify-content: left;\",\n        \"  margin-bottom: 20px;\",\n        \"}\",\n        \".plot-item {\",\n        \"  width: 500px;\",\n        \"  height: 500px;\",\n        \"}\",\n        \"img, iframe {\",\n        \"  width: 100%;\",\n        \"  height: 100%;\",\n        \"  object-fit: contain;\",\n        \"  border: none;\",\n        \"}\",\n        # /* Data tables: full width, one per row */\n        \".data-table {\",\n        \"  width: 50%;\",\n        \"  margin-bottom: 20px;\",\n        \"}\",\n        \"table {\",\n        \"  border-collapse: collapse;\",\n        \"  width: 100%;\",\n        \"  margin-top: 10px;\",\n        \"}\",\n        \"th, td {\",\n        \"  border: 1px solid #ccc;\",\n        \"  padding: 8px;\",\n        \"  text-align: left;\",\n        \"}\",\n        \"&lt;/style&gt;\",\n        \"&lt;/head&gt;\",\n        \"&lt;body&gt;\",\n        \"&lt;h1&gt;mRNA-TF Optimization Report&lt;/h1&gt;\"\n    ]\n\n    # For each gene folder, create a section in the report.\n    for gene in sorted(gene_folders):\n        gene_folder = os.path.join(results_dir, gene)\n        html_parts.append(f\"&lt;h2&gt;mRNA: {gene}&lt;/h2&gt;\")\n\n        # Create grid container for fixed-size plots.\n        html_parts.append('&lt;div class=\"plot-container\"&gt;')\n        files = sorted(os.listdir(gene_folder))\n        for filename in files:\n            file_path = os.path.join(gene_folder, filename)\n            if os.path.isfile(file_path):\n                if filename.endswith(\".png\"):\n                    rel_path = os.path.join(gene, filename)\n                    html_parts.append(\n                        f'&lt;div class=\"plot-item\"&gt;&lt;h3&gt;{filename}&lt;/h3&gt;&lt;img src=\"{rel_path}\" alt=\"{filename}\"&gt;&lt;/div&gt;'\n                    )\n        html_parts.append('&lt;/div&gt;')  # End of plot container\n\n        # Data tables: display XLSX or CSV files from the gene folder, one per row.\n        for filename in files:\n            file_path = os.path.join(gene_folder, filename)\n            if os.path.isfile(file_path) and filename.endswith(\".xlsx\"):\n                try:\n                    df = pd.read_excel(file_path)\n                    table_html = df.to_html(index=False, border=0)\n                    html_parts.append(f'&lt;div class=\"data-table\"&gt;&lt;h3&gt;Data Table: {filename}&lt;/h3&gt;{table_html}&lt;/div&gt;')\n                except Exception as e:\n                    html_parts.append(\n                        f'&lt;div class=\"data-table\"&gt;&lt;h3&gt;Data Table: {filename}&lt;/h3&gt;&lt;p&gt;Error reading {filename}: {e}&lt;/p&gt;&lt;/div&gt;'\n                    )\n\n    html_parts.append(\"&lt;/body&gt;\")\n    html_parts.append(\"&lt;/html&gt;\")\n\n    # Write the report into the results directory.\n    output_path = os.path.join(results_dir, output_file)\n    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(html_parts))\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.iodata.format_duration","title":"<code>format_duration(seconds)</code>","text":"<p>Format a duration in seconds into a human-readable string. The function converts the duration into hours, minutes, or seconds, depending on the length of the duration. Args:     seconds (float): Duration in seconds. Returns:     str: Formatted duration string.</p> Source code in <code>tfopt/evol/utils/iodata.py</code> <pre><code>def format_duration(seconds):\n    \"\"\"\n    Format a duration in seconds into a human-readable string.\n    The function converts the duration into hours, minutes, or seconds,\n    depending on the length of the duration.\n    Args:\n        seconds (float): Duration in seconds.\n    Returns:\n        str: Formatted duration string.\n    \"\"\"\n    if seconds &lt; 60:\n        return f\"{seconds:.2f} sec\"\n    elif seconds &lt; 3600:\n        return f\"{seconds / 60:.2f} min\"\n    else:\n        return f\"{seconds / 3600:.2f} hr\"\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.iodata.load_TF_data","title":"<code>load_TF_data(filename=INPUT1)</code>","text":"<p>Load TF data from a CSV file. The file is expected to have a \"GeneID\" column, a \"Psite\" column, and time columns for protein data. The function returns a list of TF gene identifiers, a dictionary mapping TF_ids to their protein data, a dictionary mapping TF_ids to their phosphorylation site data, a dictionary mapping TF_ids to their phosphorylation site labels, and the time columns. The TF_ids are converted to strings, and the protein data is stored in a dictionary with TF_ids as keys. The phosphorylation site data is stored in a list for each TF_id, and the phosphorylation site labels are also stored in a list. The time columns are extracted from the DataFrame, excluding the \"GeneID\" and \"Psite\" columns. The function returns:     - TF_ids: List of TF gene identifiers (strings).     - protein_dict: Dictionary mapping TF_ids to their protein data (numpy arrays).     - psite_dict: Dictionary mapping TF_ids to their phosphorylation site data (lists of numpy arrays).     - psite_labels_dict: Dictionary mapping TF_ids to their phosphorylation site labels (lists of strings).     - time_cols: List of time columns (excluding \"GeneID\" and \"Psite\").</p> <p>:param filename: str :return: TF_ids, protein_dict, psite_dict, psite_labels_dict, time_cols</p> Source code in <code>tfopt/evol/utils/iodata.py</code> <pre><code>def load_TF_data(filename=INPUT1):\n    \"\"\"\n    Load TF data from a CSV file.\n    The file is expected to have a \"GeneID\" column, a \"Psite\" column, and time columns for protein data.\n    The function returns a list of TF gene identifiers, a dictionary mapping TF_ids to their protein data,\n    a dictionary mapping TF_ids to their phosphorylation site data, a dictionary mapping TF_ids to their phosphorylation site labels,\n    and the time columns.\n    The TF_ids are converted to strings, and the protein data is stored in a dictionary with TF_ids as keys.\n    The phosphorylation site data is stored in a list for each TF_id, and the phosphorylation site labels are also stored in a list.\n    The time columns are extracted from the DataFrame, excluding the \"GeneID\" and \"Psite\" columns.\n    The function returns:\n        - TF_ids: List of TF gene identifiers (strings).\n        - protein_dict: Dictionary mapping TF_ids to their protein data (numpy arrays).\n        - psite_dict: Dictionary mapping TF_ids to their phosphorylation site data (lists of numpy arrays).\n        - psite_labels_dict: Dictionary mapping TF_ids to their phosphorylation site labels (lists of strings).\n        - time_cols: List of time columns (excluding \"GeneID\" and \"Psite\").\n\n    :param filename: str\n    :return: TF_ids, protein_dict, psite_dict, psite_labels_dict, time_cols\n    \"\"\"\n    df = pd.read_csv(filename)\n    protein_dict = {}\n    psite_dict = {}\n    psite_labels_dict = {}\n    for _, row in df.iterrows():\n        tf = str(row[\"GeneID\"]).strip()\n        psite = str(row[\"Psite\"]).strip()\n        time_cols = [col for col in df.columns if col not in [\"GeneID\", \"Psite\"]]\n        vals = row[time_cols].to_numpy(dtype=float)\n        if tf not in protein_dict:\n            protein_dict[tf] = vals\n            psite_dict[tf] = []\n            psite_labels_dict[tf] = []\n        else:\n            psite_dict[tf].append(vals)\n            psite_labels_dict[tf].append(psite)\n    TF_ids = list(protein_dict.keys())\n    return TF_ids, protein_dict, psite_dict, psite_labels_dict, time_cols\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.iodata.load_mRNA_data","title":"<code>load_mRNA_data(filename=INPUT3)</code>","text":"<p>Load mRNA data from a CSV file. The file is expected to have a \"GeneID\" column and time columns for expression data. The function returns a list of mRNA gene identifiers, a matrix of expression data, and the time columns. The mRNA_ids are converted to strings, and the expression data is converted to a numpy array of floats. The time columns are extracted from the DataFrame, excluding the \"GeneID\" column. The function returns:     - mRNA_ids: List of mRNA gene identifiers (strings).     - mRNA_mat: Numpy array of expression data (floats).     - time_cols: List of time columns (excluding \"GeneID\").</p> <p>:param filename: str :return: mRNA_ids, mRNA_mat, time_cols</p> Source code in <code>tfopt/evol/utils/iodata.py</code> <pre><code>def load_mRNA_data(filename=INPUT3):\n    \"\"\"\n    Load mRNA data from a CSV file.\n    The file is expected to have a \"GeneID\" column and time columns for expression data.\n    The function returns a list of mRNA gene identifiers, a matrix of expression data,\n    and the time columns.\n    The mRNA_ids are converted to strings, and the expression data is converted to a numpy array of floats.\n    The time columns are extracted from the DataFrame, excluding the \"GeneID\" column.\n    The function returns:\n        - mRNA_ids: List of mRNA gene identifiers (strings).\n        - mRNA_mat: Numpy array of expression data (floats).\n        - time_cols: List of time columns (excluding \"GeneID\").\n\n    :param filename: str\n    :return: mRNA_ids, mRNA_mat, time_cols\n    \"\"\"\n    df = pd.read_csv(filename)\n    mRNA_ids = df[\"GeneID\"].astype(str).tolist()\n    time_cols = [col for col in df.columns if col != \"GeneID\"]\n    mRNA_mat = df[time_cols].to_numpy(dtype=float)\n    return mRNA_ids, mRNA_mat, time_cols\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.iodata.load_regulation","title":"<code>load_regulation(filename=INPUT4)</code>","text":"<p>Load regulation data from a CSV file. The file is expected to have \"Source\" and \"Target\" columns. The function returns a dictionary mapping mRNA gene identifiers to their regulators (TFs). The mRNA gene identifiers and TF identifiers are converted to strings and stripped of whitespace. The function returns:     - reg_map: Dictionary mapping mRNA gene identifiers to their regulators (TFs).</p> <p>:param filename: str :return: reg_map</p> Source code in <code>tfopt/evol/utils/iodata.py</code> <pre><code>def load_regulation(filename=INPUT4):\n    \"\"\"\n    Load regulation data from a CSV file.\n    The file is expected to have \"Source\" and \"Target\" columns.\n    The function returns a dictionary mapping mRNA gene identifiers to their regulators (TFs).\n    The mRNA gene identifiers and TF identifiers are converted to strings and stripped of whitespace.\n    The function returns:\n        - reg_map: Dictionary mapping mRNA gene identifiers to their regulators (TFs).\n\n    :param filename: str\n    :return: reg_map\n    \"\"\"\n    df = pd.read_csv(filename)\n    reg_map = {}\n    for _, row in df.iterrows():\n        mrna = str(row[\"Source\"]).strip()\n        tf = str(row[\"Target\"]).strip()\n        if mrna not in reg_map:\n            reg_map[mrna] = []\n        if tf not in reg_map[mrna]:\n            reg_map[mrna].append(tf)\n    return reg_map\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.iodata.organize_output_files","title":"<code>organize_output_files(*directories)</code>","text":"<p>Organizes output files from multiple directories into separate folders for each protein. Files are moved into folders named after the protein identifier extracted from the filename. Remaining files are moved to a \"General\" folder. Args:     directories (str): List of directories to organize.</p> Source code in <code>tfopt/evol/utils/iodata.py</code> <pre><code>def organize_output_files(*directories):\n    \"\"\"\n    Organizes output files from multiple directories into separate folders for each protein.\n    Files are moved into folders named after the protein identifier extracted from the filename.\n    Remaining files are moved to a \"General\" folder.\n    Args:\n        directories (str): List of directories to organize.\n    \"\"\"\n    protein_regex = re.compile(r'([A-Za-z0-9]+)_.*\\.(json|svg|png|html|csv|xlsx)$')\n\n    for directory in directories:\n        if not os.path.isdir(directory):\n            print(f\"Warning: '{directory}' is not a valid directory. Skipping.\")\n            continue\n\n        # Move files matching the protein pattern.\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            if os.path.isfile(file_path):\n                match = protein_regex.search(filename)\n                if match:\n                    protein = match.group(1)\n                    protein_folder = os.path.join(directory, protein)\n                    os.makedirs(protein_folder, exist_ok=True)\n                    destination_path = os.path.join(protein_folder, filename)\n                    shutil.move(file_path, destination_path)\n\n        # After protein files have been moved, move remaining files to a \"General\" folder.\n        general_folder = os.path.join(directory, \"General\")\n        os.makedirs(general_folder, exist_ok=True)\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            if os.path.isfile(file_path):\n                destination_path = os.path.join(general_folder, filename)\n                shutil.move(file_path, destination_path)\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.params.compute_beta_indices","title":"<code>compute_beta_indices(num_psites, n_TF)</code>","text":"<p>Compute the starting indices for the beta parameters for each TF. The beta parameters are stored in a flat array, and this function computes the starting index for each TF based on the number of phosphorylation sites. The starting index for the beta parameters of TF i is given by: beta_start_indices[i] = sum(1 + num_psites[j] for j in range(i)) This function is used to extract the beta parameters from the flat array during the optimization process.</p> <p>:param num_psites: array of integers indicating the number of phosphorylation sites for each TF :param n_TF: number of TFs :return: beta_start_indices: array of integers indicating the starting index for each TF          cum: total number of beta parameters</p> Source code in <code>tfopt/evol/utils/params.py</code> <pre><code>def compute_beta_indices(num_psites, n_TF):\n    \"\"\"\n    Compute the starting indices for the beta parameters for each TF.\n    The beta parameters are stored in a flat array, and this function computes\n    the starting index for each TF based on the number of phosphorylation sites.\n    The starting index for the beta parameters of TF i is given by:\n    beta_start_indices[i] = sum(1 + num_psites[j] for j in range(i))\n    This function is used to extract the beta parameters from the flat array\n    during the optimization process.\n\n    :param num_psites: array of integers indicating the number of phosphorylation sites for each TF\n    :param n_TF: number of TFs\n    :return: beta_start_indices: array of integers indicating the starting index for each TF\n             cum: total number of beta parameters\n    \"\"\"\n    beta_start_indices = np.zeros(n_TF, dtype=np.int32)\n    cum = 0\n    for i in range(n_TF):\n        beta_start_indices[i] = cum\n        cum += 1 + num_psites[i]\n    return beta_start_indices, cum\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.params.create_bounds","title":"<code>create_bounds(n_alpha, n_beta_total, lb, ub)</code>","text":"<p>Create the lower and upper bounds for the optimization variables. The lower bounds are set to 0 for the alpha parameters and lb for the beta parameters. The upper bounds are set to 1 for the alpha parameters and ub for the beta parameters. The bounds are used to constrain the optimization process and ensure that the parameters are within a reasonable range. The bounds are stored in two separate arrays: xl and xu. The xl array contains the lower bounds for each parameter, and the xu array contains the upper bounds.</p> <p>:param n_alpha: number of alpha parameters :param n_beta_total: total number of beta parameters :param lb: lower bound for beta parameters :param ub: upper bound for beta parameters :return: xl: lower bounds array          xu: upper bounds array</p> Source code in <code>tfopt/evol/utils/params.py</code> <pre><code>def create_bounds(n_alpha, n_beta_total, lb, ub):\n    \"\"\"\n    Create the lower and upper bounds for the optimization variables.\n    The lower bounds are set to 0 for the alpha parameters and lb for the beta parameters.\n    The upper bounds are set to 1 for the alpha parameters and ub for the beta parameters.\n    The bounds are used to constrain the optimization process and ensure that the parameters\n    are within a reasonable range.\n    The bounds are stored in two separate arrays: xl and xu.\n    The xl array contains the lower bounds for each parameter,\n    and the xu array contains the upper bounds.\n\n    :param n_alpha: number of alpha parameters\n    :param n_beta_total: total number of beta parameters\n    :param lb: lower bound for beta parameters\n    :param ub: upper bound for beta parameters\n    :return: xl: lower bounds array\n             xu: upper bounds array\n    \"\"\"\n    xl = np.concatenate([np.zeros(n_alpha), lb * np.ones(n_beta_total)])\n    xu = np.concatenate([np.ones(n_alpha), ub * np.ones(n_beta_total)])\n    return xl, xu\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.params.create_initial_guess","title":"<code>create_initial_guess(n_mRNA, n_reg, n_TF, num_psites, no_psite_tf)</code>","text":"<p>Create the initial guess for the optimization variables. The initial guess is a flat array containing the alpha and beta parameters. The alpha parameters are initialized to 1.0 / n_reg for each mRNA-regulator pair. The beta parameters are initialized to 1.0 for the protein and 1.0 / (1 + num_psites[i]) for each phosphorylation site of TF i. The beta parameters for TFs with no phosphorylation sites are initialized to 1.0. The initial guess is used as the starting point for the optimization process. The initial guess is a flat array of length n_alpha + n_beta_total, where n_alpha is the number of alpha parameters and n_beta_total is the total number of beta parameters. The alpha parameters are stored in the first n_alpha elements of the array, and the beta parameters are stored in the remaining elements. The beta parameters are stored in the order of the TFs, with the protein parameter first followed by the phosphorylation site parameters. The beta parameters for TFs with no phosphorylation sites are stored as a single value. The beta parameters for TFs with phosphorylation sites are stored as a vector of length 1 + num_psites[i].</p> <p>:param n_mRNA: :param n_reg: :param n_TF: :param num_psites: :param no_psite_tf: :return: initial guess array, n_alpha</p> Source code in <code>tfopt/evol/utils/params.py</code> <pre><code>def create_initial_guess(n_mRNA, n_reg, n_TF, num_psites, no_psite_tf):\n    \"\"\"\n    Create the initial guess for the optimization variables.\n    The initial guess is a flat array containing the alpha and beta parameters.\n    The alpha parameters are initialized to 1.0 / n_reg for each mRNA-regulator pair.\n    The beta parameters are initialized to 1.0 for the protein and 1.0 / (1 + num_psites[i])\n    for each phosphorylation site of TF i.\n    The beta parameters for TFs with no phosphorylation sites are initialized to 1.0.\n    The initial guess is used as the starting point for the optimization process.\n    The initial guess is a flat array of length n_alpha + n_beta_total,\n    where n_alpha is the number of alpha parameters and n_beta_total is the total number of beta parameters.\n    The alpha parameters are stored in the first n_alpha elements of the array,\n    and the beta parameters are stored in the remaining elements.\n    The beta parameters are stored in the order of the TFs, with the protein parameter first\n    followed by the phosphorylation site parameters.\n    The beta parameters for TFs with no phosphorylation sites are stored as a single value.\n    The beta parameters for TFs with phosphorylation sites are stored as a vector of length 1 + num_psites[i].\n\n    :param n_mRNA:\n    :param n_reg:\n    :param n_TF:\n    :param num_psites:\n    :param no_psite_tf:\n    :return: initial guess array, n_alpha\n    \"\"\"\n    n_alpha = n_mRNA * n_reg\n    x0_alpha = np.full(n_alpha, 1.0 / n_reg)\n    x0_beta_list = []\n    for i in range(n_TF):\n        if no_psite_tf[i]:\n            x0_beta_list.extend([1.0])\n        else:\n            length = 1 + num_psites[i]\n            x0_beta_list.extend([1.0 / length] * length)\n    x0_beta = np.array(x0_beta_list)\n    x0 = np.concatenate([x0_alpha, x0_beta])\n    return x0, n_alpha\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.params.create_no_psite_array","title":"<code>create_no_psite_array(n_TF, num_psites, psite_labels_arr)</code>","text":"<p>Create an array indicating whether each TF has no phosphorylation sites. A TF is considered to have no phosphorylation sites if: 1. The number of phosphorylation sites is zero. 2. All labels for the phosphorylation sites are empty strings. This function is used to determine the initial guess for the beta parameters in the optimization process.</p> <p>:param n_TF: :param num_psites: :param psite_labels_arr: :return: array of booleans indicating no phosphorylation sites for each TF</p> Source code in <code>tfopt/evol/utils/params.py</code> <pre><code>def create_no_psite_array(n_TF, num_psites, psite_labels_arr):\n    \"\"\"\n    Create an array indicating whether each TF has no phosphorylation sites.\n    A TF is considered to have no phosphorylation sites if:\n    1. The number of phosphorylation sites is zero.\n    2. All labels for the phosphorylation sites are empty strings.\n    This function is used to determine the initial guess for the beta parameters\n    in the optimization process.\n\n    :param n_TF:\n    :param num_psites:\n    :param psite_labels_arr:\n    :return: array of booleans indicating no phosphorylation sites for each TF\n    \"\"\"\n    return np.array([(num_psites[i] == 0) or all(label == \"\" for label in psite_labels_arr[i])\n                     for i in range(n_TF)])\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.params.extract_best_solution","title":"<code>extract_best_solution(res, n_alpha, n_mRNA, n_reg, n_TF, num_psites, beta_start_indices)</code>","text":"<p>Extract the best solution from the optimization results. This function finds the best solution based on the Pareto front, which is a set of non-dominated solutions in the objective space. The best solution is determined by minimizing the weighted sum of the objectives. The alpha parameters are reshaped into a matrix of shape (n_mRNA, n_reg), and the beta parameters are extracted based on the starting indices and the number of phosphorylation sites for each TF. The beta parameters are stored in a list of arrays, where each array corresponds to a TF and contains the protein parameter and the phosphorylation site parameters. The function returns the final alpha and beta parameters, the best objectives, and the final decision variables.</p> <p>:param res: optimization results :param n_alpha: number of alpha parameters :param n_mRNA: number of mRNAs :param n_reg: number of regulators :param n_TF: number of transcription factors :param num_psites: number of phosphorylation sites for each TF :param beta_start_indices: starting indices for the beta parameters</p> <p>:return: final_alpha: final alpha parameters (n_mRNA x n_reg)             final_beta: final beta parameters (n_TF x (1 + num_psites))             best_objectives: best objectives (3 objectives)             final_x: final decision variables (flat array)</p> Source code in <code>tfopt/evol/utils/params.py</code> <pre><code>def extract_best_solution(res, n_alpha, n_mRNA, n_reg, n_TF, num_psites, beta_start_indices):\n    \"\"\"\n    Extract the best solution from the optimization results.\n    This function finds the best solution based on the Pareto front,\n    which is a set of non-dominated solutions in the objective space.\n    The best solution is determined by minimizing the weighted sum of the objectives.\n    The alpha parameters are reshaped into a matrix of shape (n_mRNA, n_reg),\n    and the beta parameters are extracted based on the starting indices and\n    the number of phosphorylation sites for each TF.\n    The beta parameters are stored in a list of arrays, where each array corresponds to a TF\n    and contains the protein parameter and the phosphorylation site parameters.\n    The function returns the final alpha and beta parameters, the best objectives,\n    and the final decision variables.\n\n    :param res: optimization results\n    :param n_alpha: number of alpha parameters\n    :param n_mRNA: number of mRNAs\n    :param n_reg: number of regulators\n    :param n_TF: number of transcription factors\n    :param num_psites: number of phosphorylation sites for each TF\n    :param beta_start_indices: starting indices for the beta parameters\n\n    :return: final_alpha: final alpha parameters (n_mRNA x n_reg)\n                final_beta: final beta parameters (n_TF x (1 + num_psites))\n                best_objectives: best objectives (3 objectives)\n                final_x: final decision variables (flat array)\n    \"\"\"\n    pareto_front = np.array([ind.F for ind in res.pop])\n    # Scoring the Pareto front\n    weights = np.array([1.0, 1.0, 1.0])\n    scores = pareto_front[:, 0] + weights[1] * np.abs(pareto_front[:, 1]) + weights[2] * np.abs(pareto_front[:, 2])\n    best_index = np.argmin(scores)\n    best_solution = res.pop[best_index]\n    best_objectives = pareto_front[best_index]\n    final_x = best_solution.X\n    final_alpha = final_x[:n_alpha].reshape((n_mRNA, n_reg))\n    final_beta = []\n    for i in range(n_TF):\n        start = beta_start_indices[i]\n        length = 1 + num_psites[i]\n        final_beta.append(final_x[n_alpha + start : n_alpha + start + length])\n    final_beta = np.array(final_beta, dtype=object)\n    return final_alpha, final_beta, best_objectives, final_x\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.params.get_parallel_runner","title":"<code>get_parallel_runner()</code>","text":"<p>Get a parallel runner for multi-threading. This function uses the lscpu command to determine the number of threads available on the system and creates a ThreadPool with that number of threads. The ThreadPool is used to parallelize the optimization process and speed up the computation.</p> <p>:return: runner: StarmapParallelization object for parallel execution             pool: ThreadPool object for managing threads</p> Source code in <code>tfopt/evol/utils/params.py</code> <pre><code>def get_parallel_runner():\n    \"\"\"\n    Get a parallel runner for multi-threading.\n    This function uses the lscpu command to determine the number of threads available\n    on the system and creates a ThreadPool with that number of threads.\n    The ThreadPool is used to parallelize the optimization process and speed up the computation.\n\n    :return: runner: StarmapParallelization object for parallel execution\n                pool: ThreadPool object for managing threads\n    \"\"\"\n    n_threads_cmd = \"lscpu -p | grep -v '^#' | wc -l\"\n    n_threads = int(subprocess.check_output(n_threads_cmd, shell=True).decode().strip())\n    pool = ThreadPool(n_threads)\n    runner = StarmapParallelization(pool.starmap)\n    return runner, pool\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.params.print_alpha_mapping","title":"<code>print_alpha_mapping(mRNA_ids, reg_map, TF_ids, final_alpha)</code>","text":"<p>Print the mapping of transcription factors (TFs) to mRNAs with their corresponding alpha values. This function iterates through the mRNA IDs and their corresponding regulators, and logs the TFs that are present in the final alpha matrix. The alpha values are printed for each TF that regulates the mRNA.</p> <p>:param mRNA_ids: List of mRNA gene identifiers. :param reg_map: Regulation map, mapping mRNA genes to their regulators. :param TF_ids: List of transcription factor identifiers. :param final_alpha: Final alpha parameters (n_mRNA x n_reg).</p> Source code in <code>tfopt/evol/utils/params.py</code> <pre><code>def print_alpha_mapping(mRNA_ids, reg_map, TF_ids, final_alpha):\n    \"\"\"\n    Print the mapping of transcription factors (TFs) to mRNAs with their corresponding alpha values.\n    This function iterates through the mRNA IDs and their corresponding regulators,\n    and logs the TFs that are present in the final alpha matrix.\n    The alpha values are printed for each TF that regulates the mRNA.\n\n    :param mRNA_ids: List of mRNA gene identifiers.\n    :param reg_map: Regulation map, mapping mRNA genes to their regulators.\n    :param TF_ids: List of transcription factor identifiers.\n    :param final_alpha: Final alpha parameters (n_mRNA x n_reg).\n    \"\"\"\n    logger.info(\"Mapping of TFs to mRNAs (\u03b1 values):\")\n    for i, mrna in enumerate(mRNA_ids):\n        actual_tfs = [tf for tf in reg_map[mrna] if tf in TF_ids]\n        logger.info(f\"mRNA {mrna}:\")\n        for j, tf in enumerate(actual_tfs):\n            logger.info(f\"TF   {tf}: {final_alpha[i, j]:.4f}\")\n</code></pre>"},{"location":"reference/#tfopt.evol.utils.params.print_beta_mapping","title":"<code>print_beta_mapping(TF_ids, final_beta, psite_labels_arr)</code>","text":"<p>Print the mapping of transcription factors (TFs) to their beta parameters. This function iterates through the TF IDs and their corresponding beta values, and logs the beta values for each TF. The beta values are printed for the protein and each phosphorylation site, with appropriate labels.</p> <p>:param TF_ids: List of transcription factor identifiers. :param final_beta: Final beta parameters (n_TF x (1 + num_psites)). :param psite_labels_arr: Array of phosphorylation site labels for each TF.</p> Source code in <code>tfopt/evol/utils/params.py</code> <pre><code>def print_beta_mapping(TF_ids, final_beta, psite_labels_arr):\n    \"\"\"\n    Print the mapping of transcription factors (TFs) to their beta parameters.\n    This function iterates through the TF IDs and their corresponding beta values,\n    and logs the beta values for each TF.\n    The beta values are printed for the protein and each phosphorylation site,\n    with appropriate labels.\n\n    :param TF_ids: List of transcription factor identifiers.\n    :param final_beta: Final beta parameters (n_TF x (1 + num_psites)).\n    :param psite_labels_arr: Array of phosphorylation site labels for each TF.\n    \"\"\"\n    logger.info(\"Mapping of TFs to \u03b2 parameters:\")\n    for idx, tf in enumerate(TF_ids):\n        beta_vec = final_beta[idx]\n        logger.info(f\"{tf}:\")\n        logger.info(f\"   TF {tf}: {beta_vec[0]:.4f}\")\n        for q in range(1, len(beta_vec)):\n            label = psite_labels_arr[idx][q-1]\n            if label == \"\":\n                label = f\"PSite{q}\"\n            logger.info(f\"   {label}: {beta_vec[q]:.4f}\")\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter","title":"<code>Plotter</code>","text":"<p>A class to plot various analysis results from an Excel file. The class provides methods to visualize the alpha and beta values, residuals, observed and estimated values, and other metrics.</p> <p>The plots include: - Alpha distribution - Beta bar plots - Heatmap of absolute residuals - Goodness of fit - Kullback-Leibler divergence - PCA - Box plots for alpha and beta values - CDF for alpha and beta values - Time-wise residuals</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>class Plotter:\n    \"\"\"\n    A class to plot various analysis results from an Excel file.\n    The class provides methods to visualize the alpha and beta values,\n    residuals, observed and estimated values, and other metrics.\n\n    The plots include:\n    - Alpha distribution\n    - Beta bar plots\n    - Heatmap of absolute residuals\n    - Goodness of fit\n    - Kullback-Leibler divergence\n    - PCA\n    - Box plots for alpha and beta values\n    - CDF for alpha and beta values\n    - Time-wise residuals\n    \"\"\"\n    def __init__(self, filepath, savepath):\n        \"\"\"\n        Initializes the Plotter instance by loading data from the Excel file.\n        \"\"\"\n        self.filepath = filepath\n        self.savepath = savepath\n        self.load_data()\n\n    def load_data(self):\n        \"\"\"\n        Loads data from the specified Excel file.\n        The data includes residuals, observed values, estimated values,\n        alpha values, and beta values.\n        \"\"\"\n        self.df = pd.read_excel(self.filepath, sheet_name='Residuals', index_col=0)\n        self.df_obs = pd.read_excel(self.filepath, sheet_name='Observed', index_col=0)\n        self.df_est = pd.read_excel(self.filepath, sheet_name='Estimated', index_col=0)\n        self.df_alpha = pd.read_excel(self.filepath, sheet_name='Alpha Values', index_col=(0,1))\n        self.df_beta = pd.read_excel(self.filepath, sheet_name='Beta Values')\n\n    def plot_alpha_distribution(self):\n        \"\"\"\n        Plots the distribution of alpha parameter values grouped by transcription factors (TFs)\n        using a strip plot.\n        \"\"\"\n        plt.figure(figsize=(10, 10))\n        all_markers = ['^', 'v', '&lt;', '&gt;', 's', 'p', '*', 'h', 'H', 'D', 'd', 'X', '+', 'x']\n        unique_tfs = self.df_alpha.index.get_level_values(1).unique()\n        marker_map = {tf: all_markers[i % len(all_markers)] for i, tf in enumerate(unique_tfs)}\n\n        for tf, marker in marker_map.items():\n            mask = self.df_alpha.index.get_level_values(1) == tf\n            sns.stripplot(\n                y=self.df_alpha.index.get_level_values(0)[mask],     # mRNA names\n                x=self.df_alpha.iloc[:, 0][mask],                     # Alpha values\n                hue=self.df_alpha.index.get_level_values(0)[mask],    # mRNA used for hue\n                label=tf,\n                palette='Dark2',\n                dodge=True,\n                size=12,\n                jitter=True,\n                marker=marker,\n                edgecolor='black'\n            )\n\n        # Create a custom legend for each TF\n        legend_handles = [\n            mlines.Line2D([], [], color='black', marker=marker_map[tf],\n                          linestyle='None', markersize=7, label=tf)\n            for tf in unique_tfs\n        ]\n        plt.legend(\n            handles=legend_handles,\n            title='TFs',\n            frameon=True,\n            loc='upper left',\n            bbox_to_anchor=(1, 1),\n            title_fontsize='10',\n            fontsize='7'\n        )\n        plt.title('Effect of Transcription Factors (TFs) on mRNA Expression')\n        plt.ylabel('mRNA')\n        plt.yticks(fontsize=6, rotation=0)\n        plt.xlabel('Alpha Value')\n        plt.tight_layout()\n        plt.savefig(f\"{self.savepath}/mRNA_alpha_group.png\", dpi=300, bbox_inches='tight')\n        plt.close()\n\n    def plot_beta_barplots(self):\n        \"\"\"\n        Processes the beta values DataFrame and creates a separate bar plot\n        for each unique transcription factor (TF).\n        \"\"\"\n        # Data cleaning for df_beta\n        self.df_beta['PSite'] = self.df_beta['PSite'].fillna(self.df_beta['TF'])\n        self.df_beta['Value'] = self.df_beta.apply(\n            lambda row: 0 if row['PSite'] == row['TF'] and pd.isna(row['Value']) else row['Value'], axis=1\n        )\n        self.df_beta['PSite'] = self.df_beta.apply(\n            lambda row: '\u03b2\u2080' if row['PSite'] == row['TF'] else row['PSite'], axis=1\n        )\n\n        unique_tfs = self.df_beta['TF'].unique()\n        # Plot bar plot for each TF\n        for tf in unique_tfs:\n            tf_data = self.df_beta[self.df_beta['TF'] == tf]\n            plt.figure(figsize=(6, 6))\n            sns.barplot(\n                data=tf_data,\n                x='PSite',\n                y='Value',\n                palette='Dark2',\n                edgecolor='black',\n                linewidth=0.5\n            )\n            plt.xlabel(\"Phosphorylation - Residue Position\")\n            plt.ylabel(\"Transcription Factor\")\n            plt.title(f\"Effect of Phosphorylation on Transcription Factor {tf} Activity\")\n            plt.grid(True, alpha=0.2)\n            plt.tight_layout()\n            plt.savefig(f'{self.savepath}/TF_{tf}_beta_group.png', dpi=300)\n            plt.close()\n\n    def plot_heatmap_abs_residuals(self):\n        \"\"\"\n        Plots a heatmap of the absolute values of the residuals.\n        \"\"\"\n        plt.figure(figsize=(12, 12))\n        abs_df = self.df.abs()\n        # Use fixed x tick labels as given in the original code\n        sns.heatmap(\n            abs_df,\n            xticklabels=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9'],\n            yticklabels=abs_df.index,\n            cmap='viridis'\n        )\n        plt.title('Absolute Residuals')\n        plt.xlabel('Time Points')\n        plt.ylabel('mRNA')\n        plt.yticks(fontsize=6, rotation=0)\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.savefig(f'{self.savepath}/Residual_Heatmap.png', dpi=300)\n        plt.close()\n\n    def plot_goodness_of_fit(self):\n        \"\"\"\n        Creates a scatter plot comparing observed vs. estimated values,\n        fits a linear regression model, plots the 95% confidence interval,\n        and labels points outside the confidence interval.\n        \"\"\"\n        plt.figure(figsize=(12, 12))\n        plt.scatter(self.df_obs, self.df_est, alpha=0.5)\n\n        mRNAs = self.df.index\n        for i, mRNA in enumerate(mRNAs):\n            plt.scatter(\n                self.df_obs.iloc[i],\n                self.df_est.iloc[i],\n                label=mRNA,\n                alpha=0.5,\n                s=100,\n                edgecolor='black'\n            )\n\n        # Linear Regression and Confidence Interval Calculation\n        X = self.df_obs.values.reshape(-1, 1)\n        y = self.df_est.values.reshape(-1, 1)\n        model = LinearRegression()\n        model.fit(X, y)\n        y_pred = model.predict(X)\n        mse = mean_squared_error(y, y_pred)\n        std_error = np.sqrt(mse)\n\n        # Flatten arrays for plotting\n        obs_flat = self.df_obs.values.flatten()\n        est_flat = self.df_est.values.flatten()\n\n        plt.fill_between(\n            obs_flat,\n            y_pred.flatten() - 1.96 * std_error,\n            y_pred.flatten() + 1.96 * std_error,\n            color='gray', alpha=0.3, label='95% CI'\n        )\n\n        # Label any points that lie outside the 95% confidence interval\n        for i, (x_val, y_val) in enumerate(zip(obs_flat, est_flat)):\n            if i &lt; len(mRNAs):\n                if y_val &lt; y_pred.flatten()[i] - 1.96 * std_error or y_val &gt; y_pred.flatten()[i] + 1.96 * std_error:\n                    plt.text(\n                        x_val, y_val, mRNAs[i],\n                        fontsize=8, ha='right', va='bottom',\n                        fontweight='light', fontstyle='normal'\n                    )\n\n        plt.plot(obs_flat, y_pred, color='red', linestyle='--', label='Estimated Values', linewidth=0.5)\n        plt.xlabel('Observed Values')\n        plt.ylabel('Estimated Values')\n        plt.title('Goodness of Fit')\n        plt.grid(True, alpha=0.1)\n        plt.tight_layout()\n        plt.savefig(f'{self.savepath}/Goodness_of_Fit.png', dpi=300)\n        plt.close()\n\n    def plot_kld(self):\n        \"\"\"\n        Plots the Kullback-Leibler Divergence (KLD) for each mRNA.\n        The KLD is calculated between the observed and estimated distributions\n        of the mRNA expression levels.\n        \"\"\"\n\n        # Normalize observed and estimated values\n        normalized_obs = self.df_obs.loc[:, 'x1':'x9'].div(self.df_obs.loc[:, 'x1':'x9'].sum(axis=1), axis=0)\n        normalized_est = self.df_est.loc[:, 'x1':'x9'].div(self.df_est.loc[:, 'x1':'x9'].sum(axis=1), axis=0)\n        # Calculate KLD for each mRNA\n        kld = normalized_obs.apply(lambda row: entropy(row, normalized_est.loc[row.name]), axis=1)\n        # Create a DataFrame for KLD values\n        kld_df = pd.DataFrame({'mRNA': self.df_obs.index, 'KL': kld.values}).set_index('mRNA')\n        # Sort KLD values by mRNA\n        kld_by_gene = kld_df.sort_values(by='KL', ascending=False)\n        # Plot the KLD values\n        plt.figure(figsize=(12, 12))\n        # Add horizontal bar plot for KLD values with different color for bars above 0.03\n        plt.barh(kld_by_gene.index[kld_by_gene['KL'] &gt; 0.03], kld_by_gene['KL'][kld_by_gene['KL'] &gt; 0.03],\n                 color='coral', alpha=0.6)\n        plt.barh(kld_by_gene.index[kld_by_gene['KL'] &lt;= 0.03], kld_by_gene['KL'][kld_by_gene['KL'] &lt;= 0.03],\n                 color='cornflowerblue', alpha=0.6)\n        plt.ylabel(\"mRNA\", fontsize=7)\n        plt.yticks(fontsize=6)\n        plt.xticks(fontsize=9)\n        plt.xlabel(\"Kullback-Leibler Divergence\", fontsize=7)\n        plt.tight_layout()\n        plt.savefig(f'{self.savepath}/KLD.png', dpi=300)\n        plt.close()\n\n    def plot_pca(self):\n        \"\"\"\n        Plots a PCA (Principal Component Analysis) of the observed and estimated values.\n        \"\"\"\n        # Standardize the data\n        scaler = StandardScaler()\n        scaled_data = scaler.fit_transform(self.df_est)\n        # Perform PCA\n        pca = PCA(n_components=2)\n        pca_result = pca.fit_transform(scaled_data)\n        # Create a DataFrame for PCA results\n        pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'], index=self.df_est.index)\n        # Perform KMeans clustering\n        kmeans = KMeans(n_clusters=3)\n        kmeans.fit(pca_df)\n        pca_df['Cluster'] = kmeans.labels_\n        # Add clusters to the PCA plot\n        plt.figure(figsize=(12, 12))\n        plt.scatter(pca_df['PC1'], pca_df['PC2'], alpha=0.5)\n        # Plot clusters\n        sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='Cluster', palette='Set1', alpha=0.5)\n        for i, mRNA in enumerate(pca_df.index):\n            plt.annotate(mRNA, (pca_df['PC1'].iloc[i], pca_df['PC2'].iloc[i]), fontsize=6,\n                         ha='right', va='bottom', annotation_clip=True)\n        plt.title('Principal Component Analysis')\n        plt.xlabel('PC1')\n        plt.ylabel('PC2')\n        plt.tight_layout()\n        plt.savefig(f'{self.savepath}/PCA.png', dpi=300)\n        plt.close()\n\n    def plot_boxplot_alpha(self):\n        \"\"\"\n        Plots a boxplot of the alpha values.\n        \"\"\"\n        plt.figure(figsize=(6, 6))\n        sns.boxplot(data=self.df_alpha.iloc[:, 0], palette='Dark2')\n        plt.title('Distribution of Alpha Values')\n        plt.ylabel('Alpha Value')\n        plt.xlabel('mRNA')\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.savefig(f'{self.savepath}/Box_Plot_Alpha.png', dpi=300)\n        plt.close()\n\n    def plot_boxplot_beta(self):\n        \"\"\"\n        Plots a boxplot of the beta values.\n        \"\"\"\n        plt.figure(figsize=(6, 6))\n        sns.boxplot(data=self.df_beta['Value'], palette='Dark2')\n        plt.title('Distribution of Beta Values')\n        plt.ylabel('Beta Value')\n        plt.xlabel('Phosphorylation - Residue Position')\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.savefig(f'{self.savepath}/Box_Plot_Beta.png', dpi=300)\n        plt.close()\n\n    def plot_cdf_alpha(self):\n        \"\"\"\n        Plots the cumulative distribution function (CDF) of the alpha values.\n        \"\"\"\n        plt.figure(figsize=(6, 6))\n        sns.ecdfplot(self.df_alpha.iloc[:, 0], stat='proportion')\n        plt.xlabel('Alpha Value')\n        plt.ylabel('Cumulative Probability')\n        plt.tight_layout()\n        plt.savefig(f'{self.savepath}/CDF_Alpha.png', dpi=300)\n        plt.close()\n\n    def plot_cdf_beta(self):\n        \"\"\"\n        Plots the cumulative distribution function (CDF) of the beta values.\n        \"\"\"\n        plt.figure(figsize=(6, 6))\n        sns.ecdfplot(self.df_beta['Value'], stat='proportion')\n        plt.xlabel('Beta Value')\n        plt.ylabel('Cumulative Probability')\n        plt.tight_layout()\n        plt.savefig(f'{self.savepath}/CDF_Beta.png', dpi=300)\n        plt.close()\n\n    def plot_time_wise_residuals(self):\n        \"\"\"\n        Plots the residuals over time for each mRNA.\n        \"\"\"\n        plt.figure(figsize=(6, 6))\n        # Generate a colormap for unique mRNAs with residuals &gt; 0.5\n        unique_colors = plt.cm.tab10(np.linspace(0, 1, len(self.df.index)))\n        default_color = 'lightgray'\n        # Calculate a single mean absolute value across all time points for all mRNAs\n        mean_residuals = self.df.abs().mean(axis=1)\n        for i, mRNA in enumerate(self.df.index):\n            if any(self.df.iloc[i] &gt; mean_residuals.iloc[i]):\n                # Assign a unique color for mRNAs with residuals &gt; 0.5\n                color = unique_colors[i % len(unique_colors)]\n                linestyle = '-'\n            else:\n                # Use the default color for other mRNAs\n                color = default_color\n                linestyle = ':'\n                mRNA = ''  # Hide label for mRNAs with no residuals &gt; 0.5\n\n            plt.plot(self.df.columns, self.df.iloc[i], label=mRNA, color=color, linestyle=linestyle)\n\n        plt.xlabel('Time Points', fontsize=7)\n        plt.ylabel('Residuals', fontsize=7)\n        plt.yticks(fontsize=8)\n        plt.xticks(fontsize=8)\n        plt.legend(loc='best', fontsize=8, frameon=True)\n        plt.tight_layout()\n        plt.savefig(f'{self.savepath}/Time_Wise_Residuals.png', dpi=300)\n        plt.close()\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter.__init__","title":"<code>__init__(filepath, savepath)</code>","text":"<p>Initializes the Plotter instance by loading data from the Excel file.</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>def __init__(self, filepath, savepath):\n    \"\"\"\n    Initializes the Plotter instance by loading data from the Excel file.\n    \"\"\"\n    self.filepath = filepath\n    self.savepath = savepath\n    self.load_data()\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter.load_data","title":"<code>load_data()</code>","text":"<p>Loads data from the specified Excel file. The data includes residuals, observed values, estimated values, alpha values, and beta values.</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>def load_data(self):\n    \"\"\"\n    Loads data from the specified Excel file.\n    The data includes residuals, observed values, estimated values,\n    alpha values, and beta values.\n    \"\"\"\n    self.df = pd.read_excel(self.filepath, sheet_name='Residuals', index_col=0)\n    self.df_obs = pd.read_excel(self.filepath, sheet_name='Observed', index_col=0)\n    self.df_est = pd.read_excel(self.filepath, sheet_name='Estimated', index_col=0)\n    self.df_alpha = pd.read_excel(self.filepath, sheet_name='Alpha Values', index_col=(0,1))\n    self.df_beta = pd.read_excel(self.filepath, sheet_name='Beta Values')\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter.plot_alpha_distribution","title":"<code>plot_alpha_distribution()</code>","text":"<p>Plots the distribution of alpha parameter values grouped by transcription factors (TFs) using a strip plot.</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>def plot_alpha_distribution(self):\n    \"\"\"\n    Plots the distribution of alpha parameter values grouped by transcription factors (TFs)\n    using a strip plot.\n    \"\"\"\n    plt.figure(figsize=(10, 10))\n    all_markers = ['^', 'v', '&lt;', '&gt;', 's', 'p', '*', 'h', 'H', 'D', 'd', 'X', '+', 'x']\n    unique_tfs = self.df_alpha.index.get_level_values(1).unique()\n    marker_map = {tf: all_markers[i % len(all_markers)] for i, tf in enumerate(unique_tfs)}\n\n    for tf, marker in marker_map.items():\n        mask = self.df_alpha.index.get_level_values(1) == tf\n        sns.stripplot(\n            y=self.df_alpha.index.get_level_values(0)[mask],     # mRNA names\n            x=self.df_alpha.iloc[:, 0][mask],                     # Alpha values\n            hue=self.df_alpha.index.get_level_values(0)[mask],    # mRNA used for hue\n            label=tf,\n            palette='Dark2',\n            dodge=True,\n            size=12,\n            jitter=True,\n            marker=marker,\n            edgecolor='black'\n        )\n\n    # Create a custom legend for each TF\n    legend_handles = [\n        mlines.Line2D([], [], color='black', marker=marker_map[tf],\n                      linestyle='None', markersize=7, label=tf)\n        for tf in unique_tfs\n    ]\n    plt.legend(\n        handles=legend_handles,\n        title='TFs',\n        frameon=True,\n        loc='upper left',\n        bbox_to_anchor=(1, 1),\n        title_fontsize='10',\n        fontsize='7'\n    )\n    plt.title('Effect of Transcription Factors (TFs) on mRNA Expression')\n    plt.ylabel('mRNA')\n    plt.yticks(fontsize=6, rotation=0)\n    plt.xlabel('Alpha Value')\n    plt.tight_layout()\n    plt.savefig(f\"{self.savepath}/mRNA_alpha_group.png\", dpi=300, bbox_inches='tight')\n    plt.close()\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter.plot_beta_barplots","title":"<code>plot_beta_barplots()</code>","text":"<p>Processes the beta values DataFrame and creates a separate bar plot for each unique transcription factor (TF).</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>def plot_beta_barplots(self):\n    \"\"\"\n    Processes the beta values DataFrame and creates a separate bar plot\n    for each unique transcription factor (TF).\n    \"\"\"\n    # Data cleaning for df_beta\n    self.df_beta['PSite'] = self.df_beta['PSite'].fillna(self.df_beta['TF'])\n    self.df_beta['Value'] = self.df_beta.apply(\n        lambda row: 0 if row['PSite'] == row['TF'] and pd.isna(row['Value']) else row['Value'], axis=1\n    )\n    self.df_beta['PSite'] = self.df_beta.apply(\n        lambda row: '\u03b2\u2080' if row['PSite'] == row['TF'] else row['PSite'], axis=1\n    )\n\n    unique_tfs = self.df_beta['TF'].unique()\n    # Plot bar plot for each TF\n    for tf in unique_tfs:\n        tf_data = self.df_beta[self.df_beta['TF'] == tf]\n        plt.figure(figsize=(6, 6))\n        sns.barplot(\n            data=tf_data,\n            x='PSite',\n            y='Value',\n            palette='Dark2',\n            edgecolor='black',\n            linewidth=0.5\n        )\n        plt.xlabel(\"Phosphorylation - Residue Position\")\n        plt.ylabel(\"Transcription Factor\")\n        plt.title(f\"Effect of Phosphorylation on Transcription Factor {tf} Activity\")\n        plt.grid(True, alpha=0.2)\n        plt.tight_layout()\n        plt.savefig(f'{self.savepath}/TF_{tf}_beta_group.png', dpi=300)\n        plt.close()\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter.plot_boxplot_alpha","title":"<code>plot_boxplot_alpha()</code>","text":"<p>Plots a boxplot of the alpha values.</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>def plot_boxplot_alpha(self):\n    \"\"\"\n    Plots a boxplot of the alpha values.\n    \"\"\"\n    plt.figure(figsize=(6, 6))\n    sns.boxplot(data=self.df_alpha.iloc[:, 0], palette='Dark2')\n    plt.title('Distribution of Alpha Values')\n    plt.ylabel('Alpha Value')\n    plt.xlabel('mRNA')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig(f'{self.savepath}/Box_Plot_Alpha.png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter.plot_boxplot_beta","title":"<code>plot_boxplot_beta()</code>","text":"<p>Plots a boxplot of the beta values.</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>def plot_boxplot_beta(self):\n    \"\"\"\n    Plots a boxplot of the beta values.\n    \"\"\"\n    plt.figure(figsize=(6, 6))\n    sns.boxplot(data=self.df_beta['Value'], palette='Dark2')\n    plt.title('Distribution of Beta Values')\n    plt.ylabel('Beta Value')\n    plt.xlabel('Phosphorylation - Residue Position')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig(f'{self.savepath}/Box_Plot_Beta.png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter.plot_cdf_alpha","title":"<code>plot_cdf_alpha()</code>","text":"<p>Plots the cumulative distribution function (CDF) of the alpha values.</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>def plot_cdf_alpha(self):\n    \"\"\"\n    Plots the cumulative distribution function (CDF) of the alpha values.\n    \"\"\"\n    plt.figure(figsize=(6, 6))\n    sns.ecdfplot(self.df_alpha.iloc[:, 0], stat='proportion')\n    plt.xlabel('Alpha Value')\n    plt.ylabel('Cumulative Probability')\n    plt.tight_layout()\n    plt.savefig(f'{self.savepath}/CDF_Alpha.png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter.plot_cdf_beta","title":"<code>plot_cdf_beta()</code>","text":"<p>Plots the cumulative distribution function (CDF) of the beta values.</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>def plot_cdf_beta(self):\n    \"\"\"\n    Plots the cumulative distribution function (CDF) of the beta values.\n    \"\"\"\n    plt.figure(figsize=(6, 6))\n    sns.ecdfplot(self.df_beta['Value'], stat='proportion')\n    plt.xlabel('Beta Value')\n    plt.ylabel('Cumulative Probability')\n    plt.tight_layout()\n    plt.savefig(f'{self.savepath}/CDF_Beta.png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter.plot_goodness_of_fit","title":"<code>plot_goodness_of_fit()</code>","text":"<p>Creates a scatter plot comparing observed vs. estimated values, fits a linear regression model, plots the 95% confidence interval, and labels points outside the confidence interval.</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>def plot_goodness_of_fit(self):\n    \"\"\"\n    Creates a scatter plot comparing observed vs. estimated values,\n    fits a linear regression model, plots the 95% confidence interval,\n    and labels points outside the confidence interval.\n    \"\"\"\n    plt.figure(figsize=(12, 12))\n    plt.scatter(self.df_obs, self.df_est, alpha=0.5)\n\n    mRNAs = self.df.index\n    for i, mRNA in enumerate(mRNAs):\n        plt.scatter(\n            self.df_obs.iloc[i],\n            self.df_est.iloc[i],\n            label=mRNA,\n            alpha=0.5,\n            s=100,\n            edgecolor='black'\n        )\n\n    # Linear Regression and Confidence Interval Calculation\n    X = self.df_obs.values.reshape(-1, 1)\n    y = self.df_est.values.reshape(-1, 1)\n    model = LinearRegression()\n    model.fit(X, y)\n    y_pred = model.predict(X)\n    mse = mean_squared_error(y, y_pred)\n    std_error = np.sqrt(mse)\n\n    # Flatten arrays for plotting\n    obs_flat = self.df_obs.values.flatten()\n    est_flat = self.df_est.values.flatten()\n\n    plt.fill_between(\n        obs_flat,\n        y_pred.flatten() - 1.96 * std_error,\n        y_pred.flatten() + 1.96 * std_error,\n        color='gray', alpha=0.3, label='95% CI'\n    )\n\n    # Label any points that lie outside the 95% confidence interval\n    for i, (x_val, y_val) in enumerate(zip(obs_flat, est_flat)):\n        if i &lt; len(mRNAs):\n            if y_val &lt; y_pred.flatten()[i] - 1.96 * std_error or y_val &gt; y_pred.flatten()[i] + 1.96 * std_error:\n                plt.text(\n                    x_val, y_val, mRNAs[i],\n                    fontsize=8, ha='right', va='bottom',\n                    fontweight='light', fontstyle='normal'\n                )\n\n    plt.plot(obs_flat, y_pred, color='red', linestyle='--', label='Estimated Values', linewidth=0.5)\n    plt.xlabel('Observed Values')\n    plt.ylabel('Estimated Values')\n    plt.title('Goodness of Fit')\n    plt.grid(True, alpha=0.1)\n    plt.tight_layout()\n    plt.savefig(f'{self.savepath}/Goodness_of_Fit.png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter.plot_heatmap_abs_residuals","title":"<code>plot_heatmap_abs_residuals()</code>","text":"<p>Plots a heatmap of the absolute values of the residuals.</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>def plot_heatmap_abs_residuals(self):\n    \"\"\"\n    Plots a heatmap of the absolute values of the residuals.\n    \"\"\"\n    plt.figure(figsize=(12, 12))\n    abs_df = self.df.abs()\n    # Use fixed x tick labels as given in the original code\n    sns.heatmap(\n        abs_df,\n        xticklabels=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9'],\n        yticklabels=abs_df.index,\n        cmap='viridis'\n    )\n    plt.title('Absolute Residuals')\n    plt.xlabel('Time Points')\n    plt.ylabel('mRNA')\n    plt.yticks(fontsize=6, rotation=0)\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig(f'{self.savepath}/Residual_Heatmap.png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter.plot_kld","title":"<code>plot_kld()</code>","text":"<p>Plots the Kullback-Leibler Divergence (KLD) for each mRNA. The KLD is calculated between the observed and estimated distributions of the mRNA expression levels.</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>def plot_kld(self):\n    \"\"\"\n    Plots the Kullback-Leibler Divergence (KLD) for each mRNA.\n    The KLD is calculated between the observed and estimated distributions\n    of the mRNA expression levels.\n    \"\"\"\n\n    # Normalize observed and estimated values\n    normalized_obs = self.df_obs.loc[:, 'x1':'x9'].div(self.df_obs.loc[:, 'x1':'x9'].sum(axis=1), axis=0)\n    normalized_est = self.df_est.loc[:, 'x1':'x9'].div(self.df_est.loc[:, 'x1':'x9'].sum(axis=1), axis=0)\n    # Calculate KLD for each mRNA\n    kld = normalized_obs.apply(lambda row: entropy(row, normalized_est.loc[row.name]), axis=1)\n    # Create a DataFrame for KLD values\n    kld_df = pd.DataFrame({'mRNA': self.df_obs.index, 'KL': kld.values}).set_index('mRNA')\n    # Sort KLD values by mRNA\n    kld_by_gene = kld_df.sort_values(by='KL', ascending=False)\n    # Plot the KLD values\n    plt.figure(figsize=(12, 12))\n    # Add horizontal bar plot for KLD values with different color for bars above 0.03\n    plt.barh(kld_by_gene.index[kld_by_gene['KL'] &gt; 0.03], kld_by_gene['KL'][kld_by_gene['KL'] &gt; 0.03],\n             color='coral', alpha=0.6)\n    plt.barh(kld_by_gene.index[kld_by_gene['KL'] &lt;= 0.03], kld_by_gene['KL'][kld_by_gene['KL'] &lt;= 0.03],\n             color='cornflowerblue', alpha=0.6)\n    plt.ylabel(\"mRNA\", fontsize=7)\n    plt.yticks(fontsize=6)\n    plt.xticks(fontsize=9)\n    plt.xlabel(\"Kullback-Leibler Divergence\", fontsize=7)\n    plt.tight_layout()\n    plt.savefig(f'{self.savepath}/KLD.png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter.plot_pca","title":"<code>plot_pca()</code>","text":"<p>Plots a PCA (Principal Component Analysis) of the observed and estimated values.</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>def plot_pca(self):\n    \"\"\"\n    Plots a PCA (Principal Component Analysis) of the observed and estimated values.\n    \"\"\"\n    # Standardize the data\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(self.df_est)\n    # Perform PCA\n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(scaled_data)\n    # Create a DataFrame for PCA results\n    pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'], index=self.df_est.index)\n    # Perform KMeans clustering\n    kmeans = KMeans(n_clusters=3)\n    kmeans.fit(pca_df)\n    pca_df['Cluster'] = kmeans.labels_\n    # Add clusters to the PCA plot\n    plt.figure(figsize=(12, 12))\n    plt.scatter(pca_df['PC1'], pca_df['PC2'], alpha=0.5)\n    # Plot clusters\n    sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='Cluster', palette='Set1', alpha=0.5)\n    for i, mRNA in enumerate(pca_df.index):\n        plt.annotate(mRNA, (pca_df['PC1'].iloc[i], pca_df['PC2'].iloc[i]), fontsize=6,\n                     ha='right', va='bottom', annotation_clip=True)\n    plt.title('Principal Component Analysis')\n    plt.xlabel('PC1')\n    plt.ylabel('PC2')\n    plt.tight_layout()\n    plt.savefig(f'{self.savepath}/PCA.png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#tfopt.fitanalysis.helper.Plotter.plot_time_wise_residuals","title":"<code>plot_time_wise_residuals()</code>","text":"<p>Plots the residuals over time for each mRNA.</p> Source code in <code>tfopt/fitanalysis/helper.py</code> <pre><code>def plot_time_wise_residuals(self):\n    \"\"\"\n    Plots the residuals over time for each mRNA.\n    \"\"\"\n    plt.figure(figsize=(6, 6))\n    # Generate a colormap for unique mRNAs with residuals &gt; 0.5\n    unique_colors = plt.cm.tab10(np.linspace(0, 1, len(self.df.index)))\n    default_color = 'lightgray'\n    # Calculate a single mean absolute value across all time points for all mRNAs\n    mean_residuals = self.df.abs().mean(axis=1)\n    for i, mRNA in enumerate(self.df.index):\n        if any(self.df.iloc[i] &gt; mean_residuals.iloc[i]):\n            # Assign a unique color for mRNAs with residuals &gt; 0.5\n            color = unique_colors[i % len(unique_colors)]\n            linestyle = '-'\n        else:\n            # Use the default color for other mRNAs\n            color = default_color\n            linestyle = ':'\n            mRNA = ''  # Hide label for mRNAs with no residuals &gt; 0.5\n\n        plt.plot(self.df.columns, self.df.iloc[i], label=mRNA, color=color, linestyle=linestyle)\n\n    plt.xlabel('Time Points', fontsize=7)\n    plt.ylabel('Residuals', fontsize=7)\n    plt.yticks(fontsize=8)\n    plt.xticks(fontsize=8)\n    plt.legend(loc='best', fontsize=8, frameon=True)\n    plt.tight_layout()\n    plt.savefig(f'{self.savepath}/Time_Wise_Residuals.png', dpi=300)\n    plt.close()\n</code></pre>"},{"location":"reference/#tfopt.local.config.constants.parse_args","title":"<code>parse_args()</code>","text":"<p>Parse command line arguments for the PhosKinTime optimization problem. This function uses argparse to handle input parameters for the optimization process. The parameters include: - lower_bound: Lower bound for the optimization variables (default: -2). - upper_bound: Upper bound for the optimization variables (default: 2). - loss_type: Type of loss function to use (default: 0).     Options:     0: MSE     1: MAE     2: soft L1     3: Cauchy     4: Arctan     5: Elastic Net     6: Tikhonov</p> <p>:return: lower_bound, upper_bound, loss_type</p> Source code in <code>tfopt/local/config/constants.py</code> <pre><code>def parse_args():\n    \"\"\"\n    Parse command line arguments for the PhosKinTime optimization problem.\n    This function uses argparse to handle input parameters for the optimization process.\n    The parameters include:\n    - lower_bound: Lower bound for the optimization variables (default: -2).\n    - upper_bound: Upper bound for the optimization variables (default: 2).\n    - loss_type: Type of loss function to use (default: 0).\n        Options:\n        0: MSE\n        1: MAE\n        2: soft L1\n        3: Cauchy\n        4: Arctan\n        5: Elastic Net\n        6: Tikhonov\n\n    :return: lower_bound, upper_bound, loss_type\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"PhosKinTime - SLSQP mRNA-TF Optimization Problem.\"\n    )\n    parser.add_argument(\"--lower_bound\", type=float, default=-2, help=\"Lower Beta bound.\")\n    parser.add_argument(\"--upper_bound\", type=float, default=2, help=\"Upper Beta bound.\")\n    parser.add_argument(\"--loss_type\", type=int, choices=[0, 1, 2, 3, 4, 5, 6], default=0,\n                        help=\"Loss function to use:  \"\n                             \"0: MSE, 1: MAE, 2: soft L1, 3: Cauchy,\"\n                             \"4: Arctan, 5: Elastic Net, 6: Tikhonov.\")\n    args = parser.parse_args()\n    return args.lower_bound, args.upper_bound, args.loss_type\n</code></pre>"},{"location":"reference/#tfopt.local.exporter.plotout.plot_estimated_vs_observed","title":"<code>plot_estimated_vs_observed(predictions, expression_matrix, gene_ids, time_points, regulators, tf_protein_matrix, tf_ids, num_targets, save_path=OUT_DIR)</code>","text":"<p>Plots the estimated vs observed values for a given set of genes and their corresponding TFs. The function generates two types of plots: 1. A full time series plot showing the observed and estimated values for each gene. 2. A plot showing the first 5 time points for each gene. Additionally, it generates an interactive plot using Plotly for each gene.</p> <p>:param predictions: 2D numpy array of predicted values. :param expression_matrix: 2D numpy array of observed values. :param gene_ids: List of gene identifiers. :param time_points: 1D numpy array of time points. :param regulators: 2D numpy array of regulators for each gene. :param tf_protein_matrix: 2D numpy array of TF protein signals. :param tf_ids: List of TF identifiers. :param num_targets: Number of target genes to plot. :param save_path: Directory path to save the plots.</p> Source code in <code>tfopt/local/exporter/plotout.py</code> <pre><code>def plot_estimated_vs_observed(predictions, expression_matrix, gene_ids, time_points, regulators, tf_protein_matrix,\n                               tf_ids, num_targets, save_path=OUT_DIR):\n    \"\"\"\n    Plots the estimated vs observed values for a given set of genes and their corresponding TFs.\n    The function generates two types of plots:\n    1. A full time series plot showing the observed and estimated values for each gene.\n    2. A plot showing the first 5 time points for each gene.\n    Additionally, it generates an interactive plot using Plotly for each gene.\n\n    :param predictions: 2D numpy array of predicted values.\n    :param expression_matrix: 2D numpy array of observed values.\n    :param gene_ids: List of gene identifiers.\n    :param time_points: 1D numpy array of time points.\n    :param regulators: 2D numpy array of regulators for each gene.\n    :param tf_protein_matrix: 2D numpy array of TF protein signals.\n    :param tf_ids: List of TF identifiers.\n    :param num_targets: Number of target genes to plot.\n    :param save_path: Directory path to save the plots.\n    \"\"\"\n    T = len(time_points)\n    time_vals_expr = np.array([4, 8, 15, 30, 60, 120, 240, 480, 960])\n    time_vals_tf = np.array([4, 8, 16, 30, 60, 120, 240, 480, 960])\n    combined_ticks = np.unique(np.concatenate((time_vals_expr, time_vals_tf)))\n    num_targets = min(num_targets, predictions.shape[0])\n\n    for i in range(num_targets):\n        fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n\n        # --- Full time series plot ---\n        ax = axes[0]\n        ax.plot(time_vals_expr, expression_matrix[i, :], 's-', label='Observed', color='black')\n        ax.plot(time_vals_expr, predictions[i, :], '-', label='Estimated', color='red')\n        plotted_tfs = set()\n        for r in regulators[i, :]:\n            if r == -1:\n                continue\n            tf_name = tf_ids[r]\n            if tf_name not in plotted_tfs:\n                protein_signal = tf_protein_matrix[r, :T]\n                ax.plot(time_vals_tf, protein_signal, ':', label=f\"{tf_name}\")\n                plotted_tfs.add(tf_name)\n        ax.set_title(f\"mRNA: {gene_ids[i]}\")\n        ax.set_xlabel(\"Time (minutes)\")\n        ax.set_ylabel(\"Fold Changes\")\n        ax.set_xticks(combined_ticks[4:])\n        ax.set_xticklabels(combined_ticks[4:])\n        ax.grid(True, alpha=0.3)\n\n        # --- First 5 time points plot ---\n        ax = axes[1]\n        ax.plot(time_vals_expr[:5], expression_matrix[i, :5], 's-', label='Observed', color='black')\n        ax.plot(time_vals_expr[:5], predictions[i, :5], '-', label='Estimated', color='red')\n        plotted_tfs = set()\n        for r in regulators[i, :]:\n            if r == -1:\n                continue\n            tf_name = tf_ids[r]\n            if tf_name not in plotted_tfs:\n                protein_signal = tf_protein_matrix[r, :5]\n                ax.plot(time_vals_tf[:5], protein_signal, ':', label=f\"{tf_name}\")\n                plotted_tfs.add(tf_name)\n        ax.set_xlabel(\"Time (minutes)\")\n        ax.set_xticks(time_vals_expr[:5])\n        ax.set_xticklabels(time_vals_expr[:5])\n        ax.legend(title=\"TFs\")\n        ax.grid(True, alpha=0.3)\n        plt.tight_layout()\n        plt.savefig(f\"{save_path}/{gene_ids[i]}_model_fit_.png\", dpi=300)\n        plt.close()\n\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(\n            x=time_vals_expr,\n            y=expression_matrix[i, :],\n            mode='markers+lines',\n            name='Observed',\n            marker=dict(symbol='square')\n        ))\n        fig.add_trace(go.Scatter(\n            x=time_vals_expr,\n            y=predictions[i, :],\n            mode='lines+markers',\n            name='Estimated'\n        ))\n        plotted_tfs = set()\n        for r in regulators[i, :]:\n            if r == -1:\n                continue\n            tf_name = tf_ids[r]\n            if tf_name not in plotted_tfs:\n                protein_signal = tf_protein_matrix[r, :len(time_vals_tf)]\n                fig.add_trace(go.Scatter(\n                    x=time_vals_tf,\n                    y=protein_signal,\n                    mode='lines',\n                    name=f\"TF: {tf_name}\",\n                    line=dict(dash='dot')\n                ))\n                plotted_tfs.add(tf_name)\n        fig.update_layout(\n            title=f\"mRNA: {gene_ids[i]}\",\n            xaxis_title=\"Time (minutes)\",\n            yaxis_title=\"Fold Changes\",\n            xaxis=dict(\n                tickmode='array',\n                tickvals=combined_ticks,\n                ticktext=[str(t) for t in combined_ticks]\n            ),\n            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n            template=\"plotly_white\",\n            width=900, height=900\n        )\n        fig.write_html(f\"{save_path}/{gene_ids[i]}_model_fit_.html\")\n</code></pre>"},{"location":"reference/#tfopt.local.exporter.sheetutils.save_results_to_excel","title":"<code>save_results_to_excel(gene_ids, tf_ids, final_alpha, final_beta, psite_labels_arr, expression_matrix, predictions, objective_value, reg_map, filename=OUT_FILE)</code>","text":"<p>Save the optimization results to an Excel file. This function creates multiple sheets in the Excel file, each containing different aspects of the optimization results, including alpha values, beta values, residuals, observed values, estimated values, and optimization metrics. Each sheet is formatted with appropriate column names and data types. The function also computes various metrics such as Mean Squared Error (MSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and R-squared score to evaluate the performance of the optimization.</p> <p>:param gene_ids: List of gene identifiers. :param tf_ids: List of TF identifiers. :param final_alpha: 2D numpy array of alpha values. :param final_beta: 2D numpy array of beta values. :param psite_labels_arr: List of post-translational modification labels. :param expression_matrix: 2D numpy array of observed values. :param predictions: 2D numpy array of predicted values. :param objective_value: Objective value of the optimization. :param reg_map: Dictionary mapping genes to their regulators. :param filename: Path to the output Excel file. :type filename: str</p> Source code in <code>tfopt/local/exporter/sheetutils.py</code> <pre><code>def save_results_to_excel(\n        gene_ids, tf_ids,\n        final_alpha, final_beta, psite_labels_arr,\n        expression_matrix, predictions,\n        objective_value,\n        reg_map,\n        filename=OUT_FILE\n):\n    \"\"\"\n    Save the optimization results to an Excel file.\n    This function creates multiple sheets in the Excel file, each containing different\n    aspects of the optimization results, including alpha values, beta values,\n    residuals, observed values, estimated values, and optimization metrics.\n    Each sheet is formatted with appropriate column names and data types.\n    The function also computes various metrics such as Mean Squared Error (MSE),\n    Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and R-squared\n    score to evaluate the performance of the optimization.\n\n    :param gene_ids: List of gene identifiers.\n    :param tf_ids: List of TF identifiers.\n    :param final_alpha: 2D numpy array of alpha values.\n    :param final_beta: 2D numpy array of beta values.\n    :param psite_labels_arr: List of post-translational modification labels.\n    :param expression_matrix: 2D numpy array of observed values.\n    :param predictions: 2D numpy array of predicted values.\n    :param objective_value: Objective value of the optimization.\n    :param reg_map: Dictionary mapping genes to their regulators.\n    :param filename: Path to the output Excel file.\n    :type filename: str\n    \"\"\"\n    # --- Alpha Values ---\n    alpha_rows = []\n    n_genes, n_reg = final_alpha.shape\n    for i in range(n_genes):\n        gene = gene_ids[i]\n        actual_tfs = [tf for tf in reg_map[gene] if tf in tf_ids]\n        for j, tf_name in enumerate(actual_tfs):\n            alpha_rows.append([gene, tf_name, final_alpha[i, j]])\n    df_alpha = pd.DataFrame(alpha_rows, columns=[\"mRNA\", \"TF\", \"Value\"])\n\n    # --- Beta Values ---\n    beta_rows = []\n    for i, tf in enumerate(tf_ids):\n        beta_vec = final_beta[i]\n        beta_rows.append([tf, \"\", beta_vec[0]])  # Protein beta\n        for j in range(1, len(beta_vec)):\n            beta_rows.append([tf, psite_labels_arr[i][j - 1], beta_vec[j]])\n    df_beta = pd.DataFrame(beta_rows, columns=[\"TF\", \"PSite\", \"Value\"])\n\n    # --- Residuals ---\n    residuals = expression_matrix - predictions\n    df_residuals = pd.DataFrame(residuals, columns=[f\"x{j + 1}\" for j in range(residuals.shape[1])])\n    df_residuals.insert(0, \"mRNA\", gene_ids)\n\n    # --- Observed ---\n    df_observed = pd.DataFrame(expression_matrix, columns=[f\"x{j + 1}\" for j in range(expression_matrix.shape[1])])\n    df_observed.insert(0, \"mRNA\", gene_ids)\n\n    # --- Estimated ---\n    df_estimated = pd.DataFrame(predictions, columns=[f\"x{j + 1}\" for j in range(predictions.shape[1])])\n    df_estimated.insert(0, \"mRNA\", gene_ids)\n\n    # --- Optimization Results ---\n    y_true = expression_matrix.flatten()\n    y_pred = predictions.flatten()\n    mse = mean_squared_error(y_true, y_pred)\n    mae = mean_absolute_error(y_true, y_pred)\n    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100\n    r2 = r2_score(y_true, y_pred)\n    df_metrics = pd.DataFrame([\n        [\"Objective Value\", objective_value],\n        [\"MSE\", mse],\n        [\"MAE\", mae],\n        [\"MAPE\", mape],\n        [\"R^2\", r2],\n    ], columns=[\"Metric\", \"Value\"])\n\n    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n        df_alpha.to_excel(writer, sheet_name=\"Alpha Values\", index=False)\n        df_beta.to_excel(writer, sheet_name=\"Beta Values\", index=False)\n        df_residuals.to_excel(writer, sheet_name=\"Residuals\", index=False)\n        df_observed.to_excel(writer, sheet_name=\"Observed\", index=False)\n        df_estimated.to_excel(writer, sheet_name=\"Estimated\", index=False)\n        df_metrics.to_excel(writer, sheet_name=\"Optimization Results\", index=False)\n</code></pre>"},{"location":"reference/#tfopt.local.objfn.minfn.compute_predictions","title":"<code>compute_predictions(x, regulators, tf_protein_matrix, psite_tensor, n_reg, T_use, n_genes, beta_start_indices, num_psites)</code>","text":"<p>Computes the predicted expression matrix based on the decision vector x. This function uses the regulators, TF protein matrix, and post-translational modification tensor to generate predictions for each gene at each time point. Parameters:   x                  : Decision vector.   regulators         : (n_genes x n_reg) indices of TF regulators for each gene.   tf_protein_matrix  : (n_TF x T_use) TF protein time series.   psite_tensor       : (n_TF x n_psite_max x T_use) matrix of PSite signals (padded with zeros).   n_reg              : Maximum number of regulators per gene.   T_use              : Number of time points used.   n_genes, n_TF     : Number of genes and TF respectively.   beta_start_indices : Integer array giving the starting index (in the \u03b2\u2013segment) for each TF.   num_psites         : Integer array with the actual number of PSites for each TF. Returns:     predictions        : (n_genes x T_use) matrix of predicted gene expression values.</p> Source code in <code>tfopt/local/objfn/minfn.py</code> <pre><code>def compute_predictions(x, regulators, tf_protein_matrix, psite_tensor, n_reg, T_use, n_genes, beta_start_indices,\n                        num_psites):\n    \"\"\"\n    Computes the predicted expression matrix based on the decision vector x.\n    This function uses the regulators, TF protein matrix, and post-translational modification tensor to generate\n    predictions for each gene at each time point.\n    Parameters:\n      x                  : Decision vector.\n      regulators         : (n_genes x n_reg) indices of TF regulators for each gene.\n      tf_protein_matrix  : (n_TF x T_use) TF protein time series.\n      psite_tensor       : (n_TF x n_psite_max x T_use) matrix of PSite signals (padded with zeros).\n      n_reg              : Maximum number of regulators per gene.\n      T_use              : Number of time points used.\n      n_genes, n_TF     : Number of genes and TF respectively.\n      beta_start_indices : Integer array giving the starting index (in the \u03b2\u2013segment) for each TF.\n      num_psites         : Integer array with the actual number of PSites for each TF.\n    Returns:\n        predictions        : (n_genes x T_use) matrix of predicted gene expression values.\n    \"\"\"\n    n_alpha = n_genes * n_reg\n    predictions = np.zeros((n_genes, T_use))\n    for i in range(n_genes):\n        R_pred = np.zeros(T_use)\n        for r in range(n_reg):\n            tf_idx = regulators[i, r]\n            if tf_idx == -1:\n                continue\n            a = x[i * n_reg + r]\n            protein = tf_protein_matrix[tf_idx, :T_use]\n            beta_start = beta_start_indices[tf_idx]\n            length = 1 + num_psites[tf_idx]\n            beta_vec = x[n_alpha + beta_start: n_alpha + beta_start + length]\n            tf_effect = beta_vec[0] * protein\n            for k in range(num_psites[tf_idx]):\n                tf_effect += beta_vec[k + 1] * psite_tensor[tf_idx, k, :T_use]\n            R_pred += a * tf_effect\n        predictions[i, :] = R_pred\n    return predictions\n</code></pre>"},{"location":"reference/#tfopt.local.objfn.minfn.objective_","title":"<code>objective_(x, expression_matrix, regulators, tf_protein_matrix, psite_tensor, n_reg, T_use, n_genes, beta_start_indices, num_psites, loss_type, lam1=1e-06, lam2=1e-06)</code>","text":"<p>Originally implemented by Julius Normann.</p> <p>This version has been modified and optimized for consistency &amp; speed in submodules by Abhinav Mishra.</p> <p>Computes a loss value using one of several loss functions.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code> </code> <p>Decision vector.</p> required <code>expression_matrix</code> <code> </code> <p>(n_genes x T_use) measured gene expression values.</p> required <code>regulators</code> <code> </code> <p>(n_genes x n_reg) indices of TF regulators for each gene.</p> required <code>tf_protein_matrix</code> <code> </code> <p>(n_TF x T_use) TF protein time series.</p> required <code>psite_tensor</code> <code> </code> <p>(n_TF x n_psite_max x T_use) matrix of PSite signals (padded with zeros).</p> required <code>n_reg</code> <code> </code> <p>Maximum number of regulators per gene.</p> required <code>T_use</code> <code> </code> <p>Number of time points used.</p> required <code>n_genes,</code> <code>n_TF</code> <p>Number of genes and TF respectively.</p> required <code>beta_start_indices</code> <p>Integer array giving the starting index (in the \u03b2\u2013segment) for each TF.</p> required <code>num_psites</code> <code> </code> <p>Integer array with the actual number of PSites for each TF.</p> required <code>loss_type</code> <code> </code> <p>Integer indicating the loss type (0: MSE, 1: MAE, 2: soft L1, 3: Cauchy, 4: Arctan, 5: Elastic Net, 6: Tikhonov).</p> required <code>lam1,</code> <code>lam2</code> <p>Regularization parameters (used for loss_type 5 and 6).</p> required <p>Returns:</p> Type Description <p>The computed loss (a scalar).</p> Source code in <code>tfopt/local/objfn/minfn.py</code> <pre><code>@njit(cache=False, fastmath=False, parallel=True, nogil=False)\ndef objective_(x, expression_matrix, regulators, tf_protein_matrix, psite_tensor, n_reg, T_use, n_genes,\n               beta_start_indices, num_psites, loss_type, lam1=1e-6, lam2=1e-6):\n    \"\"\"\n    Originally implemented by Julius Normann.\n\n    This version has been modified and optimized\n    for consistency &amp; speed in submodules by Abhinav Mishra.\n\n    Computes a loss value using one of several loss functions.\n\n    Parameters:\n      x                  : Decision vector.\n      expression_matrix  : (n_genes x T_use) measured gene expression values.\n      regulators         : (n_genes x n_reg) indices of TF regulators for each gene.\n      tf_protein_matrix  : (n_TF x T_use) TF protein time series.\n      psite_tensor       : (n_TF x n_psite_max x T_use) matrix of PSite signals (padded with zeros).\n      n_reg              : Maximum number of regulators per gene.\n      T_use              : Number of time points used.\n      n_genes, n_TF     : Number of genes and TF respectively.\n      beta_start_indices : Integer array giving the starting index (in the \u03b2\u2013segment) for each TF.\n      num_psites         : Integer array with the actual number of PSites for each TF.\n      loss_type          : Integer indicating the loss type (0: MSE, 1: MAE, 2: soft L1, 3: Cauchy, 4: Arctan, 5: Elastic Net, 6: Tikhonov).\n      lam1, lam2         : Regularization parameters (used for loss_type 5 and 6).\n\n    Returns:\n      The computed loss (a scalar).\n    \"\"\"\n    total_loss = 0.0\n    n_alpha = n_genes * n_reg\n    nT = n_genes * T_use\n    for i in prange(n_genes):\n        R_meas = expression_matrix[i, :T_use]\n        R_pred = np.zeros(T_use)\n        for r in range(n_reg):\n            tf_idx = regulators[i, r]\n            if tf_idx == -1:  # No valid TF for this regulator\n                continue\n            a = x[i * n_reg + r]\n            protein = tf_protein_matrix[tf_idx, :T_use]\n            beta_start = beta_start_indices[tf_idx]\n            length = 1 + num_psites[tf_idx]  # actual length of beta vector for TF\n            beta_vec = x[n_alpha + beta_start: n_alpha + beta_start + length]\n\n            tf_effect = beta_vec[0] * protein\n            for k in range(num_psites[tf_idx]):\n                tf_effect += beta_vec[k + 1] * psite_tensor[tf_idx, k, :T_use]\n\n            R_pred += a * tf_effect\n\n            # VECTORIZED RESIDUAL - use when mRNAs are &gt; 500\n        #     diff = R_meas - R_pred\n        #     if loss_type == 0:  # MSE\n        #         total_loss += np.dot(diff, diff)\n        #     elif loss_type == 1:  # MAE\n        #         total_loss += np.sum(np.abs(diff))\n        #     elif loss_type == 2:  # Soft L1 (pseudo-Huber)\n        #         total_loss += 2.0 * np.sum(np.sqrt(1.0 + diff * diff) - 1.0)\n        #     elif loss_type == 3:  # Cauchy\n        #         total_loss += np.sum(np.log(1.0 + diff * diff))\n        #     elif loss_type == 4:  # Arctan\n        #         total_loss += np.sum(np.arctan(diff * diff))\n        #     else:\n        #         total_loss += np.dot(diff, diff)\n        #\n        # loss = total_loss / nT\n        #\n        # # For elastic net penalty (loss_type 5) using vectorized operations.\n        # if loss_type == 5:\n        #     beta = x[n_alpha:]\n        #     loss += lam1 * np.sum(np.abs(beta)) + lam2 * np.dot(beta, beta)\n        #\n        # # For Tikhonov regularization (loss_type 6).\n        # if loss_type == 6:\n        #     beta = x[n_alpha:]\n        #     loss += lam1 * np.dot(beta, beta)\n\n            # Residuals computed timepoint-by-timepoint\n            for t in range(T_use):\n                diff = R_meas[t] - R_pred[t]\n                if loss_type == 0:  # MSE\n                    total_loss += diff * diff\n                elif loss_type == 1:  # MAE\n                    total_loss += np.abs(diff)\n                elif loss_type == 2:  # Soft L1\n                    total_loss += 2.0 * (np.sqrt(1.0 + diff * diff) - 1.0)\n                elif loss_type == 3:  # Cauchy\n                    total_loss += np.log(1.0 + diff * diff)\n                elif loss_type == 4:  # Arctan\n                    total_loss += np.arctan(diff * diff)\n                else:  # default to MSE\n                    total_loss += diff * diff\n\n        loss = total_loss / nT\n\n        # Regularization penalties\n        if loss_type == 5:\n            beta = x[n_alpha:]\n            loss += lam1 * np.sum(np.abs(beta)) + lam2 * np.dot(beta, beta)\n        elif loss_type == 6:\n            beta = x[n_alpha:]\n            loss += lam1 * np.dot(beta, beta)\n\n        return loss\n</code></pre>"},{"location":"reference/#tfopt.local.objfn.minfn.objective_wrapper","title":"<code>objective_wrapper(x, expression_matrix, regulators, tf_protein_matrix, psite_tensor, n_reg, T_use, n_genes, beta_start_indices, num_psites, loss_type)</code>","text":"<p>Wrapper function for the objective function. This function is used to call the objective function with the appropriate parameters. Parameters:   x                  : Decision vector.   expression_matrix  : (n_genes x T_use) measured gene expression values.   regulators         : (n_genes x n_reg) indices of TF regulators for each gene.   tf_protein_matrix  : (n_TF x T_use) TF protein time series.   psite_tensor       : (n_TF x n_psite_max x T_use) matrix of PSite signals (padded with zeros).   n_reg              : Maximum number of regulators per gene.   T_use              : Number of time points used.   n_genes, n_TF     : Number of genes and TF respectively.   beta_start_indices : Integer array giving the starting index (in the \u03b2\u2013segment) for each TF.   num_psites         : Integer array with the actual number of PSites for each TF.   loss_type          : Integer indicating the loss type (0: MSE, 1: MAE, 2: soft L1, 3: Cauchy, 4: Arctan, 5: Elastic Net, 6: Tikhonov). Returns:     loss               : The computed loss (a scalar).</p> Source code in <code>tfopt/local/objfn/minfn.py</code> <pre><code>def objective_wrapper(x, expression_matrix, regulators, tf_protein_matrix, psite_tensor, n_reg, T_use, n_genes,\n                      beta_start_indices, num_psites, loss_type):\n    \"\"\"\n    Wrapper function for the objective function.\n    This function is used to call the objective function with the appropriate parameters.\n    Parameters:\n      x                  : Decision vector.\n      expression_matrix  : (n_genes x T_use) measured gene expression values.\n      regulators         : (n_genes x n_reg) indices of TF regulators for each gene.\n      tf_protein_matrix  : (n_TF x T_use) TF protein time series.\n      psite_tensor       : (n_TF x n_psite_max x T_use) matrix of PSite signals (padded with zeros).\n      n_reg              : Maximum number of regulators per gene.\n      T_use              : Number of time points used.\n      n_genes, n_TF     : Number of genes and TF respectively.\n      beta_start_indices : Integer array giving the starting index (in the \u03b2\u2013segment) for each TF.\n      num_psites         : Integer array with the actual number of PSites for each TF.\n      loss_type          : Integer indicating the loss type (0: MSE, 1: MAE, 2: soft L1, 3: Cauchy, 4: Arctan, 5: Elastic Net, 6: Tikhonov).\n    Returns:\n        loss               : The computed loss (a scalar).\n    \"\"\"\n    return objective_(x, expression_matrix, regulators, tf_protein_matrix, psite_tensor, n_reg, T_use, n_genes,\n                      beta_start_indices, num_psites, loss_type)\n</code></pre>"},{"location":"reference/#tfopt.local.opt.optrun.run_optimizer","title":"<code>run_optimizer(x0, bounds, lin_cons, expression_matrix, regulators, tf_protein_matrix, psite_tensor, n_reg, T_use, n_genes, beta_start_indices, num_psites, loss_type)</code>","text":"<p>Runs the optimization algorithm to minimize the objective function.</p> <p>Parameters:</p> Name Type Description Default <code>x0</code> <code> </code> <p>Initial guess for the optimization variables.</p> required <code>bounds</code> <code> </code> <p>Bounds for the optimization variables.</p> required <code>lin_cons</code> <code> </code> <p>Linear constraints for the optimization problem.</p> required <code>expression_matrix</code> <code> </code> <p>(n_genes x T_use) measured gene expression values.</p> required <code>regulators</code> <code> </code> <p>(n_genes x n_reg) indices of TF regulators for each gene.</p> required <code>tf_protein_matrix</code> <code> </code> <p>(n_TF x T_use) TF protein time series.</p> required <code>psite_tensor</code> <code> </code> <p>(n_TF x n_psite_max x T_use) matrix of PSite signals (padded with zeros).</p> required <code>n_reg</code> <code> </code> <p>Maximum number of regulators per gene.</p> required <code>T_use</code> <code> </code> <p>Number of time points used.</p> required <code>n_genes,</code> <code>n_TF</code> <p>Number of genes and TF respectively.</p> required <code>beta_start_indices</code> <code> </code> <p>Integer array giving the starting index (in the \u03b2\u2013segment) for each TF.</p> required <code>num_psites</code> <code> </code> <p>Integer array with the actual number of PSites for each TF.</p> required <code>loss_type</code> <code> </code> <p>Type of loss function to use.</p> required <p>Returns:     result             : Result of the optimization process, including the optimized parameters and objective value.</p> Source code in <code>tfopt/local/opt/optrun.py</code> <pre><code>def run_optimizer(x0, bounds, lin_cons, expression_matrix, regulators, tf_protein_matrix, psite_tensor, n_reg, T_use, n_genes, beta_start_indices, num_psites, loss_type):\n    \"\"\"\n    Runs the optimization algorithm to minimize the objective function.\n\n    Parameters:\n      x0                  : Initial guess for the optimization variables.\n      bounds              : Bounds for the optimization variables.\n      lin_cons            : Linear constraints for the optimization problem.\n      expression_matrix   : (n_genes x T_use) measured gene expression values.\n      regulators          : (n_genes x n_reg) indices of TF regulators for each gene.\n      tf_protein_matrix   : (n_TF x T_use) TF protein time series.\n      psite_tensor        : (n_TF x n_psite_max x T_use) matrix of PSite signals (padded with zeros).\n      n_reg               : Maximum number of regulators per gene.\n      T_use               : Number of time points used.\n      n_genes, n_TF     : Number of genes and TF respectively.\n      beta_start_indices  : Integer array giving the starting index (in the \u03b2\u2013segment) for each TF.\n      num_psites          : Integer array with the actual number of PSites for each TF.\n      loss_type           : Type of loss function to use.\n    Returns:\n        result             : Result of the optimization process, including the optimized parameters and objective value.\n    \"\"\"\n    m = \"SLSQP\" # or trust-constr or SLSQP\n    result = minimize(\n        fun=objective_wrapper,\n        x0=x0,\n        args=(expression_matrix, regulators, tf_protein_matrix, psite_tensor, n_reg, T_use, n_genes, beta_start_indices, num_psites, loss_type),\n        method=m,\n        bounds=bounds,\n        constraints=lin_cons,\n        options={\"disp\": True, \"maxiter\": 10000} if m == \"SLSQP\" else {\"disp\": True, \"maxiter\": 10000, \"verbose\": 3}\n    )\n    return result\n</code></pre>"},{"location":"reference/#tfopt.local.optcon.construct.build_fixed_arrays","title":"<code>build_fixed_arrays(gene_ids, expression_matrix, tf_ids, tf_protein, tf_psite_data, tf_psite_labels, reg_map)</code>","text":"<p>Builds fixed-shape arrays from the input data. Returns:   - expression_matrix: array of shape (n_genes, T)   - regulators: array of shape (n_genes, n_reg) with indices into tf_ids.   - tf_protein_matrix: array of shape (n_TF, T)   - psite_tensor: array of shape (n_TF, n_psite_max, T), padded with zeros.   - n_reg: maximum number of regulators per gene.   - n_psite_max: maximum number of PSites among TFs.   - psite_labels_arr: list (length n_TF) of lists of PSite names (padded with empty strings).   - num_psites: array of length n_TF with the actual number of PSites for each TF.</p> Source code in <code>tfopt/local/optcon/construct.py</code> <pre><code>def build_fixed_arrays(gene_ids, expression_matrix, tf_ids, tf_protein, tf_psite_data, tf_psite_labels, reg_map):\n    \"\"\"\n    Builds fixed-shape arrays from the input data.\n    Returns:\n      - expression_matrix: array of shape (n_genes, T)\n      - regulators: array of shape (n_genes, n_reg) with indices into tf_ids.\n      - tf_protein_matrix: array of shape (n_TF, T)\n      - psite_tensor: array of shape (n_TF, n_psite_max, T), padded with zeros.\n      - n_reg: maximum number of regulators per gene.\n      - n_psite_max: maximum number of PSites among TFs.\n      - psite_labels_arr: list (length n_TF) of lists of PSite names (padded with empty strings).\n      - num_psites: array of length n_TF with the actual number of PSites for each TF.\n    \"\"\"\n    n_genes, T = expression_matrix.shape\n\n    # Map TF id to index.\n    tf_index = {tf: idx for idx, tf in enumerate(tf_ids)}\n    n_TF = len(tf_ids)\n\n    # Determine max number of valid regulators per gene, filtering out TFs not present in tf_ids.\n    reg_list = []\n    for gene in gene_ids:\n        regs = [tf for tf in reg_map.get(gene, []) if tf in tf_ids]\n        reg_list.append(regs)\n    n_reg = max(len(regs) for regs in reg_list) if reg_list else 1\n\n    # Build regulators array (n_genes x n_reg), padded with -1 to mark invalid.\n    regulators = np.full((n_genes, n_reg), -1, dtype=np.int32)\n    for i, regs in enumerate(reg_list):\n        for j, tf in enumerate(regs):\n            regulators[i, j] = tf_index.get(tf, -1)\n\n    tf_protein_matrix = np.zeros((n_TF, T), dtype=np.float64)\n    for tf, idx in tf_index.items():\n        if tf_protein.get(tf) is not None:\n            tf_protein_matrix[idx, :] = tf_protein[tf][:T]\n        else:\n            tf_protein_matrix[idx, :] = np.zeros(T)\n\n    # For each TF, record the actual number of PSites.\n    num_psites = np.zeros(n_TF, dtype=np.int32)\n    for i, tf in enumerate(tf_ids):\n        num_psites[i] = len(tf_psite_data.get(tf, []))\n    # Maximum number of PSites across all TFs.\n    n_psite_max = int(np.max(num_psites)) if np.max(num_psites) &gt; 0 else 0\n\n    # Build psite_tensor and psite_labels_arr.\n    psite_tensor = np.zeros((n_TF, n_psite_max, T), dtype=np.float64)\n    psite_labels_arr = []\n    for tf, idx in tf_index.items():\n        psites = tf_psite_data.get(tf, [])\n        labels = tf_psite_labels.get(tf, [])\n        for j in range(n_psite_max):\n            if j &lt; len(psites):\n                psite_tensor[idx, j, :] = psites[j][:T]\n            else:\n                psite_tensor[idx, j, :] = np.zeros(T)\n        padded_labels = labels + [\"\"] * (n_psite_max - len(labels))\n        psite_labels_arr.append(padded_labels)\n\n    return expression_matrix, regulators, tf_protein_matrix, psite_tensor, n_reg, n_psite_max, psite_labels_arr, num_psites\n</code></pre>"},{"location":"reference/#tfopt.local.optcon.construct.build_linear_constraints","title":"<code>build_linear_constraints(n_genes, n_TF, n_reg, n_alpha, beta_start_indices, num_psites, no_psite_tf)</code>","text":"<p>Build linear constraints for the optimization problem.</p> <p>The constraints are: 1. For each mRNA, the sum of its alpha parameters must equal 1. 2. For each TF, the sum of its beta parameters must equal 1.</p> Source code in <code>tfopt/local/optcon/construct.py</code> <pre><code>def build_linear_constraints(n_genes, n_TF, n_reg, n_alpha, beta_start_indices, num_psites, no_psite_tf):\n    \"\"\"\n    Build linear constraints for the optimization problem.\n\n    The constraints are:\n    1. For each mRNA, the sum of its alpha parameters must equal 1.\n    2. For each TF, the sum of its beta parameters must equal 1.\n    \"\"\"\n    total_vars = n_alpha + sum(1 + num_psites[i] for i in range(n_TF))\n\n    # --- Alpha constraints ---\n    alpha_constraints_matrix = []\n    for i in range(n_genes):\n        row = np.zeros(total_vars)\n        for j in range(n_reg):\n            row[i * n_reg + j] = 1.0\n        alpha_constraints_matrix.append(row)\n    alpha_constraints_matrix = np.array(alpha_constraints_matrix)\n    alpha_constraint = LinearConstraint(alpha_constraints_matrix, lb=1.0, ub=1.0)\n\n    # --- Beta constraints ---\n    beta_constraint_rows = []\n    lb_list = []\n    ub_list = []\n\n    for tf in range(n_TF):\n        start = n_alpha + beta_start_indices[tf]\n        length = 1 + num_psites[tf]\n        row = np.zeros(total_vars)\n        row[start: start + length] = 1.0\n        beta_constraint_rows.append(row)\n        lb_list.append(1.0)\n        ub_list.append(1.0)\n\n        if no_psite_tf[tf]:\n            for q in range(1, length):\n                row = np.zeros(total_vars)\n                row[start + q] = 1.0\n                beta_constraint_rows.append(row)\n                lb_list.append(0.0)\n                ub_list.append(0.0)\n\n    beta_constraints_matrix = np.array(beta_constraint_rows)\n    beta_constraint = LinearConstraint(beta_constraints_matrix, lb=lb_list, ub=ub_list)\n\n    return [alpha_constraint, beta_constraint]\n</code></pre>"},{"location":"reference/#tfopt.local.optcon.construct.constraint_alpha_func","title":"<code>constraint_alpha_func(x, n_genes, n_reg)</code>","text":"<p>For each gene, the sum of its alpha parameters must equal 1.</p> Source code in <code>tfopt/local/optcon/construct.py</code> <pre><code>def constraint_alpha_func(x, n_genes, n_reg):\n    \"\"\"\n    For each gene, the sum of its alpha parameters must equal 1.\n    \"\"\"\n    cons = []\n    for i in range(n_genes):\n        s = 0.0\n        for r in range(n_reg):\n            s += x[i * n_reg + r]\n        cons.append(s - 1.0)\n    return np.array(cons)\n</code></pre>"},{"location":"reference/#tfopt.local.optcon.construct.constraint_beta_func","title":"<code>constraint_beta_func(x, n_alpha, n_TF, beta_start_indices, num_psites, no_psite_tf)</code>","text":"<p>For each TF, the sum of its beta parameters must equal 1.</p> Source code in <code>tfopt/local/optcon/construct.py</code> <pre><code>def constraint_beta_func(x, n_alpha, n_TF, beta_start_indices, num_psites, no_psite_tf):\n    \"\"\"\n    For each TF, the sum of its beta parameters must equal 1.\n    \"\"\"\n    cons = []\n    for tf in range(n_TF):\n        length = 1 + num_psites[tf]  # Total beta parameters for TF tf.\n        start = n_alpha + beta_start_indices[tf]\n        beta_vec = x[start: start + length]\n        cons.append(np.sum(beta_vec) - 1.0)\n        if no_psite_tf[tf]:\n            for q in range(1, length):\n                cons.append(beta_vec[q])\n    return np.array(cons)\n</code></pre>"},{"location":"reference/#tfopt.local.optcon.filter.load_and_filter_data","title":"<code>load_and_filter_data()</code>","text":"<p>Load and filter data for the optimization problem. This function loads gene expression data, transcription factor (TF) data, and regulation data. It filters genes to only include those with at least one regulator and filters regulators to only include those present in the TF data. The function returns the filtered gene IDs, expression matrix, TF IDs, TF protein data, TF phosphorylation site data, TF phosphorylation site labels, and the regulation map. It raises a ValueError if no genes with regulators are found. The function also filters the TF data to only include those present in the regulation map.</p> <p>The function returns: - gene_ids: List of filtered gene IDs. - expr_matrix: Filtered expression matrix. - expr_time_cols: Time columns for gene expression data. - tf_ids: Filtered TF IDs. - tf_protein: Dictionary mapping TF IDs to their protein data. - tf_psite_data: Dictionary mapping TF IDs to their phosphorylation site data. - tf_psite_labels: Dictionary mapping TF IDs to their phosphorylation site labels. - tf_time_cols: Time columns for TF data. - reg_map: Regulation map, mapping gene IDs to their regulators.</p> Source code in <code>tfopt/local/optcon/filter.py</code> <pre><code>def load_and_filter_data():\n    \"\"\"\n    Load and filter data for the optimization problem.\n    This function loads gene expression data, transcription factor (TF) data,\n    and regulation data. It filters genes to only include those with at least\n    one regulator and filters regulators to only include those present in the\n    TF data. The function returns the filtered gene IDs, expression matrix,\n    TF IDs, TF protein data, TF phosphorylation site data, TF phosphorylation\n    site labels, and the regulation map.\n    It raises a ValueError if no genes with regulators are found.\n    The function also filters the TF data to only include those present in the\n    regulation map.\n\n    The function returns:\n    - gene_ids: List of filtered gene IDs.\n    - expr_matrix: Filtered expression matrix.\n    - expr_time_cols: Time columns for gene expression data.\n    - tf_ids: Filtered TF IDs.\n    - tf_protein: Dictionary mapping TF IDs to their protein data.\n    - tf_psite_data: Dictionary mapping TF IDs to their phosphorylation site data.\n    - tf_psite_labels: Dictionary mapping TF IDs to their phosphorylation site labels.\n    - tf_time_cols: Time columns for TF data.\n    - reg_map: Regulation map, mapping gene IDs to their regulators.\n    \"\"\"\n    gene_ids, expr_matrix, expr_time_cols = load_expression_data()\n    tf_ids, tf_protein, tf_psite_data, tf_psite_labels, tf_time_cols = load_tf_protein_data()\n    reg_map = load_regulation()\n\n    # Filter genes: only keep those with at least one regulator.\n    filtered_indices = [i for i, gene in enumerate(gene_ids) if gene in reg_map and len(reg_map[gene]) &gt; 0]\n    if len(filtered_indices) == 0:\n        raise ValueError(\"No genes with regulators found. Exiting.\")\n    gene_ids = [gene_ids[i] for i in filtered_indices]\n    expr_matrix = expr_matrix[filtered_indices, :]\n\n    # For each gene, filter regulators to those present in tf_ids.\n    relevant_tfs = set()\n    for gene in gene_ids:\n        regs = reg_map.get(gene, [])\n        regs_filtered = [tf for tf in regs if tf in tf_ids]\n        reg_map[gene] = regs_filtered\n        relevant_tfs.update(regs_filtered)\n\n    # Filter TFs.\n    tf_ids_filtered = [tf for tf in tf_ids if tf in relevant_tfs]\n    tf_ids = tf_ids_filtered\n    tf_protein = {tf: tf_protein[tf] for tf in tf_ids}\n    tf_psite_data = {tf: tf_psite_data[tf] for tf in tf_ids}\n    tf_psite_labels = {tf: tf_psite_labels[tf] for tf in tf_ids}\n\n    return gene_ids, expr_matrix, expr_time_cols, tf_ids, tf_protein, tf_psite_data, tf_psite_labels, tf_time_cols, reg_map\n</code></pre>"},{"location":"reference/#tfopt.local.optcon.filter.prepare_data","title":"<code>prepare_data(gene_ids, expr_matrix, tf_ids, tf_protein, tf_psite_data, tf_psite_labels, tf_time_cols, reg_map)</code>","text":"<p>Prepares the data for optimization by filtering the expression matrix to match the number of time points and building fixed arrays.</p> <p>Parameters:</p> Name Type Description Default <code>gene_ids</code> <code>list</code> <p>List of gene IDs.</p> required <code>expr_matrix</code> <code>ndarray</code> <p>Gene expression matrix.</p> required <code>tf_ids</code> <code>list</code> <p>List of transcription factor IDs.</p> required <code>tf_protein</code> <code>dict</code> <p>Dictionary mapping TF IDs to their protein data.</p> required <code>tf_psite_data</code> <code>dict</code> <p>Dictionary mapping TF IDs to their phosphorylation site data.</p> required <code>tf_psite_labels</code> <code>dict</code> <p>Dictionary mapping TF IDs to their phosphorylation site labels.</p> required <code>tf_time_cols</code> <code>list</code> <p>Time columns for TF data.</p> required <code>reg_map</code> <code>dict</code> <p>Regulation map, mapping gene IDs to their regulators.</p> required <p>Returns:     fixed_arrays (tuple): Tuple containing the fixed arrays:         - expression_matrix: array of shape (n_genes, T)         - regulators: array of shape (n_genes, n_reg) with indices into tf_ids.         - tf_protein_matrix: array of shape (n_TF, T)         - psite_tensor: array of shape (n_TF, n_psite_max, T), padded with zeros.         - n_reg: maximum number of regulators per gene.         - n_psite_max: maximum number of PSites among TFs.         - psite_labels_arr: list (length n_TF) of lists of PSite names (padded with empty strings).         - num_psites: array of length n_TF with the actual number of PSites for each TF.     T_use (int): Number of time points used in the expression matrix.</p> Source code in <code>tfopt/local/optcon/filter.py</code> <pre><code>def prepare_data(gene_ids, expr_matrix, tf_ids, tf_protein, tf_psite_data, tf_psite_labels, tf_time_cols, reg_map):\n    \"\"\"\n    Prepares the data for optimization by filtering the expression matrix\n    to match the number of time points and building fixed arrays.\n\n    Args:\n        gene_ids (list): List of gene IDs.\n        expr_matrix (np.ndarray): Gene expression matrix.\n        tf_ids (list): List of transcription factor IDs.\n        tf_protein (dict): Dictionary mapping TF IDs to their protein data.\n        tf_psite_data (dict): Dictionary mapping TF IDs to their phosphorylation site data.\n        tf_psite_labels (dict): Dictionary mapping TF IDs to their phosphorylation site labels.\n        tf_time_cols (list): Time columns for TF data.\n        reg_map (dict): Regulation map, mapping gene IDs to their regulators.\n    Returns:\n        fixed_arrays (tuple): Tuple containing the fixed arrays:\n            - expression_matrix: array of shape (n_genes, T)\n            - regulators: array of shape (n_genes, n_reg) with indices into tf_ids.\n            - tf_protein_matrix: array of shape (n_TF, T)\n            - psite_tensor: array of shape (n_TF, n_psite_max, T), padded with zeros.\n            - n_reg: maximum number of regulators per gene.\n            - n_psite_max: maximum number of PSites among TFs.\n            - psite_labels_arr: list (length n_TF) of lists of PSite names (padded with empty strings).\n            - num_psites: array of length n_TF with the actual number of PSites for each TF.\n        T_use (int): Number of time points used in the expression matrix.\n    \"\"\"\n    T_use = min(expr_matrix.shape[1], len(tf_time_cols))\n    expr_matrix = expr_matrix[:, :T_use]\n    fixed_arrays = build_fixed_arrays(gene_ids, expr_matrix, tf_ids, tf_protein, tf_psite_data, tf_psite_labels, reg_map)\n    return fixed_arrays, T_use\n</code></pre>"},{"location":"reference/#tfopt.local.utils.iodata.create_report","title":"<code>create_report(results_dir, output_file='report.html')</code>","text":"<p>Creates a single global report HTML file from all gene folders inside the results directory.</p> <p>For each gene folder (e.g. \"ABL2\"), the report will include:   - All PNG plots and interactive HTML plots displayed in a grid with three plots per row.   - Each plot is confined to a fixed size of 900px by 900px.   - Data tables from XLSX or CSV files in the gene folder are displayed below the plots, one per row.</p> <p>Parameters:</p> Name Type Description Default <code>results_dir</code> <code>str</code> <p>Path to the root results directory.</p> required <code>output_file</code> <code>str</code> <p>Name of the generated global report file (placed inside results_dir).</p> <code>'report.html'</code> Source code in <code>tfopt/local/utils/iodata.py</code> <pre><code>def create_report(results_dir: str, output_file: str = \"report.html\"):\n    \"\"\"\n    Creates a single global report HTML file from all gene folders inside the results directory.\n\n    For each gene folder (e.g. \"ABL2\"), the report will include:\n      - All PNG plots and interactive HTML plots displayed in a grid with three plots per row.\n      - Each plot is confined to a fixed size of 900px by 900px.\n      - Data tables from XLSX or CSV files in the gene folder are displayed below the plots, one per row.\n\n    Args:\n        results_dir (str): Path to the root results directory.\n        output_file (str): Name of the generated global report file (placed inside results_dir).\n    \"\"\"\n    # Gather gene folders (skip \"General\" and \"logs\")\n    gene_folders = [\n        d for d in os.listdir(results_dir)\n        if os.path.isdir(os.path.join(results_dir, d)) and d not in (\"General\", \"logs\")\n    ]\n\n    # Build HTML content with updated CSS for spacing.\n    html_parts = [\n        \"&lt;html&gt;\",\n        \"&lt;head&gt;\",\n        \"&lt;meta charset='UTF-8'&gt;\",\n        \"&lt;title&gt;Estimation Report&lt;/title&gt;\",\n        \"&lt;style&gt;\",\n        \"body { font-family: Arial, sans-serif; margin: 20px; }\",\n        \"h1 { color: #333; }\",\n        \"h2 { color: #555; font-size: 1.8em; border-bottom: 1px solid #ccc; padding-bottom: 5px; }\",\n        \"h3 { color: #666; font-size: 1.4em; margin-top: 10px; margin-bottom: 10px; }\",\n        # /* CSS grid for plots: two per row, fixed size 500px x 500px, extra space between rows */\n        \".plot-container {\",\n        \"  display: grid;\",\n        \"  grid-template-columns: repeat(2, 500px);\",\n        \"  column-gap: 20px;\",\n        \"  row-gap: 40px;\", # /* extra vertical gap */\n        \"  justify-content: left;\",\n        \"  margin-bottom: 20px;\",\n        \"}\",\n        \".plot-item {\",\n        \"  width: 500px;\",\n        \"  height: 500px;\",\n        \"}\",\n        \"img, iframe {\",\n        \"  width: 100%;\",\n        \"  height: 100%;\",\n        \"  object-fit: contain;\",\n        \"  border: none;\",\n        \"}\",\n        # /* Data tables: full width, one per row */\n        \".data-table {\",\n        \"  width: 50%;\",\n        \"  margin-bottom: 20px;\",\n        \"}\",\n        \"table {\",\n        \"  border-collapse: collapse;\",\n        \"  width: 100%;\",\n        \"  margin-top: 10px;\",\n        \"}\",\n        \"th, td {\",\n        \"  border: 1px solid #ccc;\",\n        \"  padding: 8px;\",\n        \"  text-align: left;\",\n        \"}\",\n        \"&lt;/style&gt;\",\n        \"&lt;/head&gt;\",\n        \"&lt;body&gt;\",\n        \"&lt;h1&gt;Global Report&lt;/h1&gt;\"\n    ]\n\n    # For each gene folder, create a section in the report.\n    for gene in sorted(gene_folders):\n        gene_folder = os.path.join(results_dir, gene)\n        html_parts.append(f\"&lt;h2&gt;mRNA: {gene}&lt;/h2&gt;\")\n\n        # Create grid container for fixed-size plots.\n        html_parts.append('&lt;div class=\"plot-container\"&gt;')\n        files = sorted(os.listdir(gene_folder))\n        for filename in files:\n            file_path = os.path.join(gene_folder, filename)\n            if os.path.isfile(file_path):\n                if filename.endswith(\".png\"):\n                    rel_path = os.path.join(gene, filename)\n                    html_parts.append(\n                        f'&lt;div class=\"plot-item\"&gt;&lt;h3&gt;{filename}&lt;/h3&gt;&lt;img src=\"{rel_path}\" alt=\"{filename}\"&gt;&lt;/div&gt;'\n                    )\n        html_parts.append('&lt;/div&gt;')  # End of plot container\n\n        # Data tables: display XLSX or CSV files from the gene folder, one per row.\n        for filename in files:\n            file_path = os.path.join(gene_folder, filename)\n            if os.path.isfile(file_path) and filename.endswith(\".xlsx\"):\n                try:\n                    df = pd.read_excel(file_path)\n                    table_html = df.to_html(index=False, border=0)\n                    html_parts.append(f'&lt;div class=\"data-table\"&gt;&lt;h3&gt;Data Table: {filename}&lt;/h3&gt;{table_html}&lt;/div&gt;')\n                except Exception as e:\n                    html_parts.append(\n                        f'&lt;div class=\"data-table\"&gt;&lt;h3&gt;Data Table: {filename}&lt;/h3&gt;&lt;p&gt;Error reading {filename}: {e}&lt;/p&gt;&lt;/div&gt;'\n                    )\n\n    html_parts.append(\"&lt;/body&gt;\")\n    html_parts.append(\"&lt;/html&gt;\")\n\n    # Write the report into the results directory.\n    output_path = os.path.join(results_dir, output_file)\n    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(html_parts))\n</code></pre>"},{"location":"reference/#tfopt.local.utils.iodata.load_expression_data","title":"<code>load_expression_data(filename=INPUT3)</code>","text":"<p>Loads gene expression (mRNA) data. Expects a CSV with a 'GeneID' column and time-point columns.</p> Source code in <code>tfopt/local/utils/iodata.py</code> <pre><code>def load_expression_data(filename=INPUT3):\n    \"\"\"\n    Loads gene expression (mRNA) data.\n    Expects a CSV with a 'GeneID' column and time-point columns.\n    \"\"\"\n    df = pd.read_csv(filename)\n    # Normlaize for high unscaled variability\n    # Exists often\n    # df = min_max_normalize(df, 4)\n    gene_ids = df[\"GeneID\"].astype(str).tolist()\n    time_cols = [col for col in df.columns if col != \"GeneID\"]\n    expression_matrix = df[time_cols].to_numpy(dtype=float)\n    return gene_ids, expression_matrix, time_cols\n</code></pre>"},{"location":"reference/#tfopt.local.utils.iodata.load_regulation","title":"<code>load_regulation(filename=INPUT4)</code>","text":"Assumes the regulation file is reversed <ul> <li>The 'Source' column holds gene (mRNA) identifiers.</li> <li>The 'Target' column holds TF identifiers.</li> </ul> <p>Returns a mapping from gene (source) to a list of TFs (targets).</p> Source code in <code>tfopt/local/utils/iodata.py</code> <pre><code>def load_regulation(filename=INPUT4):\n    \"\"\"\n    Assumes the regulation file is reversed:\n      - The 'Source' column holds gene (mRNA) identifiers.\n      - The 'Target' column holds TF identifiers.\n    Returns a mapping from gene (source) to a list of TFs (targets).\n    \"\"\"\n    df = pd.read_csv(filename)\n    reg_map = {}\n    for _, row in df.iterrows():\n        gene = str(row[\"Source\"]).strip()\n        tf = str(row[\"Target\"]).strip()\n        if gene not in reg_map:\n            reg_map[gene] = []\n        if tf not in reg_map[gene]:\n            reg_map[gene].append(tf)\n    return reg_map\n</code></pre>"},{"location":"reference/#tfopt.local.utils.iodata.load_tf_protein_data","title":"<code>load_tf_protein_data(filename=INPUT1)</code>","text":"<p>Loads TF protein data along with PSite information. Expects a CSV with 'GeneID' and 'Psite' columns. For rows without a valid PSite, the entire row is considered as the protein signal.</p> Source code in <code>tfopt/local/utils/iodata.py</code> <pre><code>def load_tf_protein_data(filename=INPUT1):\n    \"\"\"\n    Loads TF protein data along with PSite information.\n    Expects a CSV with 'GeneID' and 'Psite' columns.\n    For rows without a valid PSite, the entire row is considered as the protein signal.\n    \"\"\"\n    df = pd.read_csv(filename)\n    # Normlaize for high unscaled variability\n    # Exists often\n    # df = min_max_normalize(df, 4)\n    tf_protein = {}\n    tf_psite_data = {}\n    tf_psite_labels = {}\n    # Original time columns from TF data (should be 14 columns)\n    orig_time_cols = [col for col in df.columns if col not in [\"GeneID\", \"Psite\"]]\n    # Use only time points from index 5 onward (i.e. last 9 time points) if available.\n    # To match the expression data, we need to ensure the same number of time points.\n    if len(orig_time_cols) &gt;= 14:\n        time_cols = orig_time_cols[5:]\n    else:\n        time_cols = orig_time_cols\n    for _, row in df.iterrows():\n        tf = str(row[\"GeneID\"]).strip()\n        psite = str(row[\"Psite\"]).strip()\n        vals = row[orig_time_cols].to_numpy(dtype=float)\n        vals = vals[5:] if len(orig_time_cols) &gt;= 14 else vals\n        if tf not in tf_protein:\n            tf_protein[tf] = vals\n            tf_psite_data[tf] = []\n            tf_psite_labels[tf] = []\n        else:\n            tf_psite_data[tf].append(vals)\n            tf_psite_labels[tf].append(psite)\n    tf_ids = list(tf_protein.keys())\n    return tf_ids, tf_protein, tf_psite_data, tf_psite_labels, time_cols\n</code></pre>"},{"location":"reference/#tfopt.local.utils.iodata.min_max_normalize","title":"<code>min_max_normalize(df, custom_max=None)</code>","text":"<p>Row-wise (per-sample) min-max normalize time-series columns starting with 'x'.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame with time-series columns (x1-xN).</p> required <code>custom_max</code> <code>float</code> <p>If given, used as max for all rows.</p> <code>None</code> <p>Returns:</p> Type Description <p>pd.DataFrame: Normalized DataFrame with same shape.</p> Source code in <code>tfopt/local/utils/iodata.py</code> <pre><code>def min_max_normalize(df, custom_max=None):\n    \"\"\"\n    Row-wise (per-sample) min-max normalize time-series columns starting with 'x'.\n\n    Parameters:\n        df (pd.DataFrame): Input DataFrame with time-series columns (x1-xN).\n        custom_max (float, optional): If given, used as max for all rows.\n\n    Returns:\n        pd.DataFrame: Normalized DataFrame with same shape.\n    \"\"\"\n    df = df.copy()\n    time_cols = [col for col in df.columns if col.startswith(\"x\")]\n    other_cols = [col for col in df.columns if not col.startswith(\"x\")]\n\n    data = df[time_cols].to_numpy(dtype=float)\n\n    row_min = np.min(data, axis=1, keepdims=True)\n    if custom_max is not None:\n        row_max = custom_max\n        denom = (custom_max - row_min)\n    else:\n        row_max = np.max(data, axis=1, keepdims=True)\n        denom = (row_max - row_min)\n\n    normalized = (data - row_min) / denom\n    df[time_cols] = normalized\n\n    return df\n</code></pre>"},{"location":"reference/#tfopt.local.utils.iodata.summarize_stats","title":"<code>summarize_stats(input3=INPUT3, input1=INPUT1, input4=INPUT4)</code>","text":"<p>Summarizes statistics for the expression data (input3) and TF protein data (input1). It also summarizes the data after filtering based on the mapping file (input4).</p> The function prints the following statistics <ul> <li>Global min, max, std, var for the full dataset.</li> <li>Time-wise min, max, std, var for each time point.</li> <li>Global min, max, std, var for the subset data (filtered by input4).</li> <li>Time-wise min, max, std, var for the subset data.</li> </ul> <p>Args:     input3 (str): Path to the expression data CSV file.     input1 (str): Path to the TF protein data CSV file.     input4 (str): Path to the mapping file CSV.</p> Source code in <code>tfopt/local/utils/iodata.py</code> <pre><code>def summarize_stats(input3=INPUT3, input1=INPUT1, input4=INPUT4):\n    \"\"\"\n    Summarizes statistics for the expression data (input3) and TF protein data (input1).\n    It also summarizes the data after filtering based on the mapping file (input4).\n\n    The function prints the following statistics:\n        - Global min, max, std, var for the full dataset.\n        - Time-wise min, max, std, var for each time point.\n        - Global min, max, std, var for the subset data (filtered by input4).\n        - Time-wise min, max, std, var for the subset data.\n    Args:\n        input3 (str): Path to the expression data CSV file.\n        input1 (str): Path to the TF protein data CSV file.\n        input4 (str): Path to the mapping file CSV.\n    \"\"\"\n    # Load input3: expression data\n    expr_df = pd.read_csv(input3)\n    expr_data = expr_df.drop(columns=[\"GeneID\"])\n\n    print(\"=== Expression Data (input3) \u2014 Full Dataset ===\")\n    print(f\"Global min: {expr_data.values.min():.4f}\")\n    print(f\"Global max: {expr_data.values.max():.4f}\")\n    print(f\"Global std: {expr_data.values.std():.4f}\")\n    print(f\"Global var: {expr_data.values.var():.4f}\")\n    print(\"\\nTime-wise stats:\")\n    print(expr_data.agg(['min', 'max', 'std', 'var']).T)\n\n    # Load input1: TF protein data\n    prot_df = pd.read_csv(input1)\n    time_cols = [col for col in prot_df.columns if col not in [\"GeneID\", \"Psite\"]]\n    prot_data = prot_df[time_cols]\n\n    print(\"\\n=== TF Protein Data (input1) \u2014 Full Dataset ===\")\n    print(f\"Global min: {prot_data.values.min():.4f}\")\n    print(f\"Global max: {prot_data.values.max():.4f}\")\n    print(f\"Global std: {prot_data.values.std():.4f}\")\n    print(f\"Global var: {prot_data.values.var():.4f}\")\n    print(\"\\nTime-wise stats:\")\n    print(prot_data.agg(['min', 'max', 'std', 'var']).T)\n\n    # Load mapping from input4\n    map_df = pd.read_csv(input4)\n    expr_subset = expr_df[expr_df[\"GeneID\"].isin(map_df[\"Source\"])]\n    prot_subset = prot_df[prot_df[\"GeneID\"].isin(map_df[\"Target\"])]\n\n    print(\"\\n=== Expression Data \u2014 Subset from input4 ===\")\n    expr_data_sub = expr_subset.drop(columns=[\"GeneID\"])\n    print(f\"Global min: {expr_data_sub.values.min():.4f}\")\n    print(f\"Global max: {expr_data_sub.values.max():.4f}\")\n    print(f\"Global std: {expr_data_sub.values.std():.4f}\")\n    print(f\"Global var: {expr_data_sub.values.var():.4f}\")\n    print(\"\\nTime-wise stats:\")\n    print(expr_data_sub.agg(['min', 'max', 'std', 'var']).T)\n\n    print(\"\\n=== TF Protein Data \u2014 Subset from input4 ===\")\n    prot_data_sub = prot_subset[time_cols]\n    print(f\"Global min: {prot_data_sub.values.min():.4f}\")\n    print(f\"Global max: {prot_data_sub.values.max():.4f}\")\n    print(f\"Global std: {prot_data_sub.values.std():.4f}\")\n    print(f\"Global var: {prot_data_sub.values.var():.4f}\")\n    print(\"\\nTime-wise stats:\")\n    print(prot_data_sub.agg(['min', 'max', 'std', 'var']).T)\n</code></pre>"},{"location":"reference/#tfopt.local.utils.params.get_optimization_parameters","title":"<code>get_optimization_parameters(expression_matrix, tf_protein_matrix, n_reg, T_use, psite_labels_arr, num_psites, lb, ub)</code>","text":"<p>Prepare the optimization parameters for the optimization problem. This function initializes the alpha and beta parameters, sets up the bounds, and constructs the linear constraints for the optimization problem. It returns the initial guess for the optimization variables, the number of alpha parameters, the starting indices for beta parameters, the bounds, the boolean array indicating TFs without phosphorylation sites, and the number of genes and TFs.</p> <p>Parameters: expression_matrix (np.ndarray): Gene expression matrix. tf_protein_matrix (np.ndarray): TF protein matrix. n_reg (int): Number of regulators. T_use (int): Number of time points used in the expression matrix. psite_labels_arr (list): List of lists containing phosphorylation site labels. num_psites (np.ndarray): Array containing the number of phosphorylation sites for each TF. lb (float): Lower bound for beta parameters. ub (float): Upper bound for beta parameters.</p> <p>Returns: x0 (np.ndarray): Initial guess for the optimization variables. n_alpha (int): Number of alpha parameters. beta_start_indices (np.ndarray): Starting indices for beta parameters. bounds (list): List of tuples specifying the bounds for each optimization variable. no_psite_tf (np.ndarray): Boolean array indicating TFs without phosphorylation sites. n_genes (int): Number of genes. n_TF (int): Number of TFs. num_psites (np.ndarray): Array containing the number of phosphorylation sites for each TF. lin_cons (LinearConstraint): Linear constraints for the optimization problem. T_use (int): Number of time points used in the expression matrix.</p> Source code in <code>tfopt/local/utils/params.py</code> <pre><code>def get_optimization_parameters(expression_matrix, tf_protein_matrix, n_reg, T_use,\n                                psite_labels_arr, num_psites, lb, ub):\n    \"\"\"\n    Prepare the optimization parameters for the optimization problem.\n    This function initializes the alpha and beta parameters, sets up the bounds,\n    and constructs the linear constraints for the optimization problem.\n    It returns the initial guess for the optimization variables, the number of\n    alpha parameters, the starting indices for beta parameters, the bounds,\n    the boolean array indicating TFs without phosphorylation sites, and the\n    number of genes and TFs.\n\n    Parameters:\n    expression_matrix (np.ndarray): Gene expression matrix.\n    tf_protein_matrix (np.ndarray): TF protein matrix.\n    n_reg (int): Number of regulators.\n    T_use (int): Number of time points used in the expression matrix.\n    psite_labels_arr (list): List of lists containing phosphorylation site labels.\n    num_psites (np.ndarray): Array containing the number of phosphorylation sites for each TF.\n    lb (float): Lower bound for beta parameters.\n    ub (float): Upper bound for beta parameters.\n\n    Returns:\n    x0 (np.ndarray): Initial guess for the optimization variables.\n    n_alpha (int): Number of alpha parameters.\n    beta_start_indices (np.ndarray): Starting indices for beta parameters.\n    bounds (list): List of tuples specifying the bounds for each optimization variable.\n    no_psite_tf (np.ndarray): Boolean array indicating TFs without phosphorylation sites.\n    n_genes (int): Number of genes.\n    n_TF (int): Number of TFs.\n    num_psites (np.ndarray): Array containing the number of phosphorylation sites for each TF.\n    lin_cons (LinearConstraint): Linear constraints for the optimization problem.\n    T_use (int): Number of time points used in the expression matrix.\n    \"\"\"\n    n_genes = expression_matrix.shape[0]\n    n_TF = tf_protein_matrix.shape[0]\n    no_psite_tf = np.array([(num_psites[i] == 0) or all(label == \"\" for label in psite_labels_arr[i])\n                            for i in range(n_TF)])\n    beta_start_indices = np.zeros(n_TF, dtype=np.int32)\n    cum = 0\n    for i in range(n_TF):\n        beta_start_indices[i] = cum\n        cum += 1 + num_psites[i]\n    n_alpha = n_genes * n_reg\n    # x0_alpha = np.full(n_alpha, 1.0 / n_reg)\n    # Initialize x0_alpha using uniform random numbers and normalize per gene.\n    x0_alpha = np.empty(n_alpha)\n    for i in range(n_genes):\n        # Sample n_reg values uniformly from [0,1)\n        a = np.random.rand(n_reg)\n        a /= a.sum()  # Normalize so that the regulators for gene i sum to 1.\n        x0_alpha[i * n_reg:(i + 1) * n_reg] = a\n    # Initialize x0_beta by sampling uniformly from [lb, ub] and normalizing per TF.\n    x0_beta_list = []\n    for i in range(n_TF):\n        length = 1 + num_psites[i]\n        if no_psite_tf[i]:\n            # For TFs without any PSite, the beta vector has one element.\n            # The constraint forces that element to be 1.0, so we simply use 1.0.\n            x0_beta_list.extend([1.0])\n        else:\n            sample = np.random.uniform(lb, ub, size=length)\n            sample /= sample.sum()  # Normalize so that this beta vector sums to 1.\n            x0_beta_list.extend(sample.tolist())\n            # x0_beta_list.extend([1.0 / length] * length)\n\n    x0_beta = np.array(x0_beta_list)\n    x0 = np.concatenate([x0_alpha, x0_beta])\n\n    bounds_alpha = [(0.0, 1.0)] * n_alpha\n    bounds_beta = [(lb, ub)] * len(x0_beta)\n    bounds = bounds_alpha + bounds_beta\n\n    lin_cons = build_linear_constraints(n_genes, n_TF, n_reg, n_alpha, beta_start_indices, num_psites, no_psite_tf)\n\n    return x0, n_alpha, beta_start_indices, bounds, no_psite_tf, n_genes, n_TF, num_psites, lin_cons, T_use\n</code></pre>"},{"location":"reference/#tfopt.local.utils.params.postprocess_results","title":"<code>postprocess_results(result, n_alpha, n_genes, n_reg, beta_start_indices, num_psites, reg_map, gene_ids, tf_ids, psite_labels_arr)</code>","text":"<p>Post-process the optimization results to extract the final alpha and beta parameters. This function reshapes the optimization result into the final alpha and beta matrices, and builds the mapping of TFs to mRNAs and phosphorylation sites. It also logs the mappings for debugging purposes.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>OptimizeResult</code> <p>The result of the optimization.</p> required <code>n_alpha</code> <code>int</code> <p>Number of alpha parameters.</p> required <code>n_genes</code> <code>int</code> <p>Number of genes.</p> required <code>n_reg</code> <code>int</code> <p>Number of regulators.</p> required <code>beta_start_indices</code> <code>ndarray</code> <p>Starting indices for beta parameters.</p> required <code>num_psites</code> <code>ndarray</code> <p>Array containing the number of phosphorylation sites for each TF.</p> required <code>reg_map</code> <code>dict</code> <p>Regulation map, mapping gene IDs to their regulators.</p> required <code>gene_ids</code> <code>list</code> <p>List of gene IDs.</p> required <code>tf_ids</code> <code>list</code> <p>List of transcription factor IDs.</p> required <code>psite_labels_arr</code> <code>list</code> <p>List of lists containing phosphorylation site labels.</p> required <p>Returns:</p> Name Type Description <code>final_x</code> <code>ndarray</code> <p>Final optimization result.</p> <code>final_alpha</code> <code>ndarray</code> <p>Final alpha parameters reshaped into a matrix.</p> <code>final_beta</code> <code>ndarray</code> <p>Final beta parameters reshaped into a matrix.</p> Source code in <code>tfopt/local/utils/params.py</code> <pre><code>def postprocess_results(result, n_alpha, n_genes, n_reg, beta_start_indices, num_psites, reg_map, gene_ids, tf_ids,\n                        psite_labels_arr):\n    \"\"\"\n    Post-process the optimization results to extract the final alpha and beta parameters.\n    This function reshapes the optimization result into the final alpha and beta matrices,\n    and builds the mapping of TFs to mRNAs and phosphorylation sites.\n    It also logs the mappings for debugging purposes.\n\n    Args:\n        result (OptimizeResult): The result of the optimization.\n        n_alpha (int): Number of alpha parameters.\n        n_genes (int): Number of genes.\n        n_reg (int): Number of regulators.\n        beta_start_indices (np.ndarray): Starting indices for beta parameters.\n        num_psites (np.ndarray): Array containing the number of phosphorylation sites for each TF.\n        reg_map (dict): Regulation map, mapping gene IDs to their regulators.\n        gene_ids (list): List of gene IDs.\n        tf_ids (list): List of transcription factor IDs.\n        psite_labels_arr (list): List of lists containing phosphorylation site labels.\n\n    Returns:\n        final_x (np.ndarray): Final optimization result.\n        final_alpha (np.ndarray): Final alpha parameters reshaped into a matrix.\n        final_beta (np.ndarray): Final beta parameters reshaped into a matrix.\n    \"\"\"\n    final_x = result.x\n    final_alpha = final_x[:n_alpha].reshape((n_genes, n_reg))\n    final_beta = []\n    for i in range(len(tf_ids)):\n        start = beta_start_indices[i]\n        length = 1 + num_psites[i]\n        final_beta.append(final_x[n_alpha + start: n_alpha + start + length])\n    final_beta = np.array(final_beta, dtype=object)\n\n    # Build and logger.info \u03b1 mapping.\n    alpha_mapping = {}\n    for i, gene in enumerate(gene_ids):\n        actual_tfs = [tf for tf in reg_map[gene] if tf in tf_ids]\n        alpha_mapping[gene] = {}\n        for j, tf in enumerate(actual_tfs):\n            alpha_mapping[gene][tf] = final_alpha[i, j]\n\n    logger.info(\"Mapping of TFs to mRNAs (\u03b1 values):\")\n    for gene, mapping in alpha_mapping.items():\n        logger.info(f\"mRNA {gene}:\")\n        for tf, a_val in mapping.items():\n            logger.info(f\"TF   {tf}: {a_val:.4f}\")\n\n    logger.info(\"Mapping of TFs to \u03b2 parameters:\")\n    for idx, tf in enumerate(tf_ids):\n        beta_vec = final_beta[idx]\n        logger.info(f\"{tf}:\")\n        logger.info(f\"   TF {tf}: {beta_vec[0]:.4f}\")\n        for q in range(1, len(beta_vec)):\n            label = psite_labels_arr[idx][q-1]\n            if label == \"\":\n                label = f\"PSite{q}\"\n            logger.info(f\"   {label}: {beta_vec[q]:.4f}\")\n\n    # Build and logger.info \u03b2 mapping.\n    # beta_mapping = {}\n    # for idx, tf in enumerate(tf_ids):\n    #     beta_mapping[tf] = {}\n    #     beta_vec = final_beta[idx]\n    #     logger.info(f\"{tf}:\")\n    #     beta_mapping[tf][f\"mRNA {tf}\"] = beta_vec[0]\n    #     for q in range(1, len(beta_vec)):\n    #         label = psite_labels_arr[idx][q - 1]\n    #         if label == \"\":\n    #             label = f\"PSite{q}\"\n    #         beta_mapping[tf][label] = beta_vec[q]\n    # logger.info(\"Mapping of phosphorylation sites to TFs (\u03b2 parameters):\")\n    # for tf, mapping in beta_mapping.items():\n    #     logger.info(f\"{tf}:\")\n    #     for label, b_val in mapping.items():\n    #         logger.info(f\"   {label}: {b_val:.4f}\")\n    return final_x, final_alpha, final_beta\n</code></pre>"},{"location":"reference/#utils.display.create_report","title":"<code>create_report(results_dir, output_file='report.html')</code>","text":"<p>Creates a single global report HTML file from all gene folders inside the results directory.</p> <p>For each gene folder (e.g. \"ABL2\"), the report will include:   - All PNG plots and interactive HTML plots displayed in a grid with three plots per row.   - Each plot is confined to a fixed size of 900px by 900px.   - Data tables from XLSX or CSV files in the gene folder are displayed below the plots, one per row.</p> <p>Parameters:</p> Name Type Description Default <code>results_dir</code> <code>str</code> <p>Path to the root results directory.</p> required <code>output_file</code> <code>str</code> <p>Name of the generated global report file (placed inside results_dir).</p> <code>'report.html'</code> Source code in <code>utils/display.py</code> <pre><code>def create_report(results_dir: str, output_file: str = \"report.html\"):\n    \"\"\"\n    Creates a single global report HTML file from all gene folders inside the results directory.\n\n    For each gene folder (e.g. \"ABL2\"), the report will include:\n      - All PNG plots and interactive HTML plots displayed in a grid with three plots per row.\n      - Each plot is confined to a fixed size of 900px by 900px.\n      - Data tables from XLSX or CSV files in the gene folder are displayed below the plots, one per row.\n\n    Args:\n        results_dir (str): Path to the root results directory.\n        output_file (str): Name of the generated global report file (placed inside results_dir).\n    \"\"\"\n    # Gather gene folders (skip \"General\" and \"logs\")\n    gene_folders = [\n        d for d in os.listdir(results_dir)\n        if os.path.isdir(os.path.join(results_dir, d)) and d not in (\"General\", \"logs\")\n    ]\n\n    # Build HTML content with updated CSS for spacing.\n    html_parts = [\n        \"&lt;html&gt;\",\n        \"&lt;head&gt;\",\n        \"&lt;meta charset='UTF-8'&gt;\",\n        \"&lt;title&gt;Estimation Report&lt;/title&gt;\",\n        \"&lt;style&gt;\",\n        \"body { font-family: Arial, sans-serif; margin: 20px; }\",\n        \"h1 { color: #333; }\",\n        \"h2 { color: #555; font-size: 1.8em; border-bottom: 1px solid #ccc; padding-bottom: 5px; }\",\n        \"h3 { color: #666; font-size: 1.4em; margin-top: 10px; margin-bottom: 10px; }\",\n        # /* CSS grid for plots: two per row, fixed size 500px x 500px, extra space between rows */\n        \".plot-container {\",\n        \"  display: grid;\",\n        \"  grid-template-columns: repeat(2, 500px);\",\n        \"  column-gap: 20px;\",\n        \"  row-gap: 40px;\",  #// extra vertical gap\n        \"  justify-content: left;\",\n        \"  margin-bottom: 40px;\",\n        \"}\",\n        \".plot-item {\",\n        \"  width: 500px;\",\n        \"  height: 500px;\",\n        \"}\",\n        \"img, iframe {\",\n        \"  width: 100%;\",\n        \"  height: 100%;\",\n        \"  object-fit: contain;\",\n        \"  border: none;\",\n        \"}\",\n        # /* Data tables: full width, one per row */\n        \".data-table {\",\n        \"  width: 50%;\",\n        \"  margin-bottom: 20px;\",\n        \"}\",\n        \"table {\",\n        \"  border-collapse: collapse;\",\n        \"  width: 100%;\",\n        \"  margin-top: 10px;\",\n        \"}\",\n        \"th, td {\",\n        \"  border: 1px solid #ccc;\",\n        \"  padding: 8px;\",\n        \"  text-align: left;\",\n        \"}\",\n        \"&lt;/style&gt;\",\n        \"&lt;/head&gt;\",\n        \"&lt;body&gt;\",\n        \"&lt;h1&gt;Modelling &amp; Parameter Estimation Report&lt;/h1&gt;\"\n    ]\n\n    # For each gene folder, create a section in the report.\n    for gene in sorted(gene_folders):\n        gene_folder = os.path.join(results_dir, gene)\n        html_parts.append(f\"&lt;h2&gt;Protein Group: {gene}&lt;/h2&gt;\")\n\n        # Create grid container for fixed-size plots.\n        html_parts.append('&lt;div class=\"plot-container\"&gt;')\n        files = sorted(os.listdir(gene_folder))\n        for filename in files:\n            file_path = os.path.join(gene_folder, filename)\n            if os.path.isfile(file_path) and filename.endswith(\".png\"):\n                rel_path = os.path.join(gene, filename)\n                # Remove the extension and split on '_'\n                base_name = os.path.splitext(filename)[0]\n                tokens = [token for token in base_name.split('_') if token]\n                # Remove the gene name if it matches (case-insensitive)\n                if tokens and tokens[0].upper() == gene.upper():\n                    tokens = tokens[1:]\n                # Join remaining tokens with space and convert to upper case\n                title = \" \".join(tokens).upper()\n                html_parts.append(\n                    f'&lt;div class=\"plot-item\"&gt;&lt;h3&gt;{title}&lt;/h3&gt;&lt;img src=\"{rel_path}\" alt=\"{filename}\"&gt;&lt;/div&gt;'\n                )\n        html_parts.append('&lt;/div&gt;')  # End of plot container\n\n        # Data tables: display XLSX or CSV files from the gene folder, one per row.\n        for filename in files:\n            file_path = os.path.join(gene_folder, filename)\n            if os.path.isfile(file_path) and filename.endswith(\".xlsx\"):\n                try:\n                    df = pd.read_excel(file_path)\n                    table_html = df.to_html(index=False, border=0)\n                    # Remove the extension and split on '_'\n                    base_name = os.path.splitext(filename)[0]\n                    tokens = [token for token in base_name.split('_') if token]\n                    # Remove the gene name if it matches (case-insensitive)\n                    if tokens and tokens[0].upper() == gene.upper():\n                        tokens = tokens[1:]\n                    # Join remaining tokens with space and convert to upper case\n                    title = \" \".join(tokens).upper()\n                    html_parts.append(f'&lt;div class=\"data-table\"&gt;&lt;h3&gt;Data Table: {title}&lt;/h3&gt;{table_html}&lt;/div&gt;')\n                except Exception as e:\n                    html_parts.append(\n                        f'&lt;div class=\"data-table\"&gt;&lt;h3&gt;Data Table: {filename}&lt;/h3&gt;&lt;p&gt;Error reading {filename}: {e}&lt;/p&gt;&lt;/div&gt;'\n                    )\n\n    html_parts.append(\"&lt;/body&gt;\")\n    html_parts.append(\"&lt;/html&gt;\")\n\n    # Write the report into the results directory.\n    output_path = os.path.join(results_dir, output_file)\n    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(html_parts))\n</code></pre>"},{"location":"reference/#utils.display.ensure_output_directory","title":"<code>ensure_output_directory(directory)</code>","text":"<p>Ensure the output directory exists. If it doesn't, create it.</p> <p>:param directory: str</p> Source code in <code>utils/display.py</code> <pre><code>def ensure_output_directory(directory):\n    \"\"\"\n    Ensure the output directory exists. If it doesn't, create it.\n\n    :param directory: str\n    \"\"\"\n    os.makedirs(directory, exist_ok=True)\n</code></pre>"},{"location":"reference/#utils.display.format_duration","title":"<code>format_duration(seconds)</code>","text":"<p>Format a duration in seconds into a human-readable string. The function converts seconds into a string representation in the format: - \"X sec\" for seconds - \"X min\" for minutes - \"X hr\" for hours</p> <p>:param seconds: float :return: formatted string</p> Source code in <code>utils/display.py</code> <pre><code>def format_duration(seconds):\n    \"\"\"\n    Format a duration in seconds into a human-readable string.\n    The function converts seconds into a string representation in the format:\n    - \"X sec\" for seconds\n    - \"X min\" for minutes\n    - \"X hr\" for hours\n\n    :param seconds: float\n    :return: formatted string\n    \"\"\"\n    if seconds &lt; 60:\n        return f\"{seconds:.2f} sec\"\n    elif seconds &lt; 3600:\n        return f\"{seconds / 60:.2f} min\"\n    else:\n        return f\"{seconds / 3600:.2f} hr\"\n</code></pre>"},{"location":"reference/#utils.display.load_data","title":"<code>load_data(excel_file, sheet='Estimated Values')</code>","text":"<p>Load data from an Excel file. The default sheet is \"Estimated Values\".</p> <p>:param excel_file: str :param sheet: str :return: DataFrame :rtype: pd.DataFrame</p> Source code in <code>utils/display.py</code> <pre><code>def load_data(excel_file, sheet=\"Estimated Values\"):\n    \"\"\"\n    Load data from an Excel file. The default sheet is \"Estimated Values\".\n\n    :param excel_file: str\n    :param sheet: str\n    :return: DataFrame\n    :rtype: pd.DataFrame\n    \"\"\"\n    return pd.read_excel(excel_file, sheet_name=sheet)\n</code></pre>"},{"location":"reference/#utils.display.organize_output_files","title":"<code>organize_output_files(*directories)</code>","text":"<p>Organize output files into protein-specific folders and a general folder. Files matching the pattern \"protein_name_*.{json,svg,png,html,csv,xlsx}\" will be moved to a folder named after the protein. Remaining files will be moved to a \"General\" folder within the same directory.</p> <p>:param directories: List of directories to organize. :type directories: list</p> Source code in <code>utils/display.py</code> <pre><code>def organize_output_files(*directories):\n    \"\"\"\n    Organize output files into protein-specific folders and a general folder.\n    Files matching the pattern \"protein_name_*.{json,svg,png,html,csv,xlsx}\"\n    will be moved to a folder named after the protein.\n    Remaining files will be moved to a \"General\" folder within the same directory.\n\n    :param directories: List of directories to organize.\n    :type directories: list\n    \"\"\"\n    protein_regex = re.compile(r'([A-Za-z0-9]+)_.*\\.(json|svg|png|html|csv|xlsx)$')\n\n    for directory in directories:\n        if not os.path.isdir(directory):\n            print(f\"Warning: '{directory}' is not a valid directory. Skipping.\")\n            continue\n\n        # Move files matching the protein pattern.\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            if os.path.isfile(file_path):\n                match = protein_regex.search(filename)\n                if match:\n                    protein = match.group(1)\n                    protein_folder = os.path.join(directory, protein)\n                    os.makedirs(protein_folder, exist_ok=True)\n                    destination_path = os.path.join(protein_folder, filename)\n                    shutil.move(file_path, destination_path)\n\n        # After protein files have been moved, move remaining files to a \"General\" folder.\n        general_folder = os.path.join(directory, \"General\")\n        os.makedirs(general_folder, exist_ok=True)\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            if os.path.isfile(file_path):\n                destination_path = os.path.join(general_folder, filename)\n                shutil.move(file_path, destination_path)\n</code></pre>"},{"location":"reference/#utils.display.save_result","title":"<code>save_result(results, excel_filename)</code>","text":"<p>Save the results to an Excel file with multiple sheets. Each sheet corresponds to a different gene and contains: - Sequential Parameter Estimates - Profiled Estimates (if available) - Errors summary The sheet names are prefixed with the gene name, truncated to 25 characters. Args:     results (list): List of dictionaries containing results for each gene.     excel_filename (str): Path to the output Excel file.</p> Source code in <code>utils/display.py</code> <pre><code>def save_result(results, excel_filename):\n    \"\"\"\n    Save the results to an Excel file with multiple sheets.\n    Each sheet corresponds to a different gene and contains:\n    - Sequential Parameter Estimates\n    - Profiled Estimates (if available)\n    - Errors summary\n    The sheet names are prefixed with the gene name, truncated to 25 characters.\n    Args:\n        results (list): List of dictionaries containing results for each gene.\n        excel_filename (str): Path to the output Excel file.\n    \"\"\"\n    with pd.ExcelWriter(excel_filename, engine='xlsxwriter') as writer:\n        for res in results:\n            gene = res[\"gene\"]\n            sheet_prefix = gene[:25]  # Excel sheet names must be \u226431 chars\n\n            # 1. Save Sequential Parameter Estimates\n            param_df = res[\"param_df\"].copy()\n            if \"errors\" in res:\n                param_df[\"MSE\"] = pd.Series(res[\"errors\"][:len(param_df)])\n            param_df.insert(0, \"Gene\", gene)\n            param_df.to_excel(writer, sheet_name=f\"{sheet_prefix}_params\", index=False)\n\n            # 2. Save Profiled Estimates if available\n            if \"profiles_df\" in res and res[\"profiles_df\"] is not None:\n                prof_df = res[\"profiles_df\"].copy()\n                prof_df.insert(0, \"Gene\", gene)\n                prof_df.to_excel(writer, sheet_name=f\"{sheet_prefix}_profiles\", index=False)\n\n            # 4. Save errors summary\n            error_summary = {\n                \"Gene\": gene,\n                \"MSE\": res.get(\"mse\", \"\"),\n                \"MAE\": res.get(\"mae\", \"\")\n            }\n            err_df = pd.DataFrame([error_summary])\n            err_df.to_excel(writer, sheet_name=f\"{sheet_prefix}_errors\", index=False)\n</code></pre>"},{"location":"reference/#utils.tables.generate_tables","title":"<code>generate_tables(xlsx_file_path)</code>","text":"<p>Generate hierarchical tables from the XLSX file containing alpha and beta values. The function reads the alpha and beta values from the specified XLSX file, processes them to create hierarchical tables, and returns a list of these tables. Each table is a DataFrame with a MultiIndex for the columns, representing the alpha and beta values for different kinases and phosphorylation sites. The tables are structured to facilitate easy comparison and analysis of the phosphorylation data.</p> Source code in <code>utils/tables.py</code> <pre><code>def generate_tables(xlsx_file_path):\n    \"\"\"\n    Generate hierarchical tables from the XLSX file containing alpha and beta values.\n    The function reads the alpha and beta values from the specified XLSX file,\n    processes them to create hierarchical tables, and returns a list of these tables.\n    Each table is a DataFrame with a MultiIndex for the columns, representing\n    the alpha and beta values for different kinases and phosphorylation sites.\n    The tables are structured to facilitate easy comparison and analysis of the\n    phosphorylation data.\n    \"\"\"\n    # Load alpha and beta values from the XLSX file\n    alpha_values = pd.read_excel(xlsx_file_path, sheet_name=\"Alpha Values\")\n    beta_values = pd.read_excel(xlsx_file_path, sheet_name=\"Beta Values\")\n\n    # Prepare the tables\n    hierarchical_tables = []\n\n    def format_float(value):\n        \"\"\"\n        Custom formatter to remove trailing zeroes.\n        \"\"\"\n        return f\"{value:.2f}\".rstrip('0').rstrip('.') if pd.notnull(value) else \"\"\n\n    def merge_kinase_columns(alpha_pivot, beta_pivot):\n        \"\"\"\n        Merge columns of kinases without duplicating names.\n        \"\"\"\n        all_kinases = list(alpha_pivot.columns) + list(beta_pivot.columns)\n        unique_kinases = sorted(set(all_kinases), key=all_kinases.index)\n\n        merged_data = pd.DataFrame(index=alpha_pivot.index.union(beta_pivot.index), columns=unique_kinases)\n        for kinase in unique_kinases:\n            if kinase in alpha_pivot.columns:\n                merged_data.loc[alpha_pivot.index, kinase] = alpha_pivot[kinase]\n            if kinase in beta_pivot.columns:\n                merged_data.loc[beta_pivot.columns, kinase] = beta_pivot[kinase].values\n\n        return merged_data\n\n    for protein in alpha_values['Protein'].unique():\n        protein_alpha = alpha_values[alpha_values['Protein'] == protein]\n        protein_beta = beta_values[beta_values['Kinase'].isin(protein_alpha['Kinase'].unique())]\n\n        for psite in protein_alpha['Psite'].unique():\n            # Filter alpha and beta data for this specific psite\n            alpha_data = protein_alpha[protein_alpha['Psite'] == psite]\n            beta_data = protein_beta[protein_beta['Kinase'].isin(alpha_data['Kinase'].unique())]\n\n            # Prepare alpha and beta pivot data\n            alpha_pivot = alpha_data.pivot(index='Psite', columns='Kinase', values='Alpha')\n            beta_pivot = beta_data.pivot(index='Kinase', columns='Psite', values='Beta')\n\n            # Round alpha and beta values to 3 decimal places and format\n            alpha_pivot = alpha_pivot.map(format_float)\n            beta_pivot = beta_pivot.map(format_float)\n\n            # Combine alpha and beta with hierarchical levels: add latex symbol\n            alpha_pivot.columns = MultiIndex.from_product([['$\\\\alpha$'], alpha_pivot.columns], names=['', 'Kinase'])\n            beta_pivot = beta_pivot.T  # Transpose beta for matching structure\n            beta_pivot.columns = MultiIndex.from_product([['$\\\\beta$'], beta_pivot.columns], names=['', 'Kinase'])\n\n            # # Combine alpha and beta with hierarchical levels: DONT add latex symbol\n            # alpha_pivot.columns = MultiIndex.from_product([[''], alpha_pivot.columns], names=['', 'Kinase'])\n            # beta_pivot = beta_pivot.T  # Transpose beta for matching structure\n            # beta_pivot.columns = MultiIndex.from_product([[''], beta_pivot.columns], names=['', 'Kinase'])\n\n            # Concatenate alpha and beta tables\n            hierarchical_table = concat([alpha_pivot, beta_pivot], axis=1)\n            hierarchical_table = hierarchical_table.where(pd.notnull(hierarchical_table),\n                                                          \"\")  # Replace NaN with empty strings\n            # Rename 'Psite' to 'Site' and replace underscores with \\_\n            hierarchical_table.index = hierarchical_table.index.map(lambda x: str(x).replace('_', '\\\\_'))\n            hierarchical_table.index.rename('Site', inplace=True)\n            hierarchical_tables.append(((protein, psite), hierarchical_table))\n\n    return hierarchical_tables\n</code></pre>"},{"location":"reference/#utils.tables.save_master_table","title":"<code>save_master_table(folder='latex', output_file='latex/all_tables.tex')</code>","text":"<p>Save a master LaTeX file that includes all individual LaTeX files from the specified folder. This function generates a LaTeX file that includes all the individual LaTeX files for each protein and phosphorylation site.</p> <p>:param folder: Directory containing the individual LaTeX files. :param output_file: Output LaTeX file name. :type folder: str :type output_file: str</p> Source code in <code>utils/tables.py</code> <pre><code>def save_master_table(folder=\"latex\", output_file=\"latex/all_tables.tex\"):\n    \"\"\"\n    Save a master LaTeX file that includes all individual LaTeX files from the specified folder.\n    This function generates a LaTeX file that includes all the individual LaTeX files\n    for each protein and phosphorylation site.\n\n    :param folder: Directory containing the individual LaTeX files.\n    :param output_file: Output LaTeX file name.\n    :type folder: str\n    :type output_file: str\n    \"\"\"\n    files = sorted([f for f in os.listdir(folder) if f.endswith(\".tex\")])\n\n    # Write a LaTeX file that includes all these files\n    with open(output_file, \"w\") as out:\n        out.write(\"% This file is auto-generated\\n\")\n        for file in files:\n            out.write(f\"\\\\input{{{folder}/{file}}}\\n\")\n\n    print(f\"Generated {output_file} with {len(files)} entries.\")\n</code></pre>"},{"location":"reference/#utils.tables.save_tables","title":"<code>save_tables(tables, output_dir)</code>","text":"<p>Save the generated tables as LaTeX and CSV files. Each table is saved with a filename based on the protein and phosphorylation site. The LaTeX files are formatted for easy inclusion in a larger document, and the CSV files are saved for further analysis.</p> <p>:param tables: List of tuples containing protein, psite, and the corresponding table. :param output_dir: Directory where the tables will be saved. :type output_dir: str</p> Source code in <code>utils/tables.py</code> <pre><code>def save_tables(tables, output_dir):\n    \"\"\"\n    Save the generated tables as LaTeX and CSV files.\n    Each table is saved with a filename based on the protein and phosphorylation site.\n    The LaTeX files are formatted for easy inclusion in a larger document,\n    and the CSV files are saved for further analysis.\n\n    :param tables: List of tuples containing protein, psite, and the corresponding table.\n    :param output_dir: Directory where the tables will be saved.\n    :type output_dir: str\n    \"\"\"\n    for (protein, psite), table in tables:\n        base_filename = f\"{output_dir}/{protein}_{psite.replace(':', '_')}\"\n        # Save as LaTeX\n        with open(f\"{base_filename}.tex\", \"w\") as tex_file:\n            tex_file.write(table.to_latex(multicolumn=True, multirow=True, escape=False))\n        # Save as CSV\n        table.to_csv(f\"{base_filename}.csv\")\n</code></pre>"}]}